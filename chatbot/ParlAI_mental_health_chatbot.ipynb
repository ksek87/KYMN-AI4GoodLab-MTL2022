{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ParlAI_mental_health_chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6zmXBYc0AzK",
        "outputId": "a9f8fe86-9e0c-4a77-f09e-22fbd58d1a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 14 01:02:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU specs\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing parlAI"
      ],
      "metadata": {
        "id": "XZrRwRSg0QjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q parlai\n",
        "!pip install -q subword_nmt # extra requirement we need for this tutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS3TqUa_0aYX",
        "outputId": "9d90c1e8-5857-4e7e-a712-7df354375883"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 208 kB 72.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 95 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 75.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 57.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 248 kB 74.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 26.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 76.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 65.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 547 kB 73.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 346 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 80.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 77.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 175 kB 66.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 76.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 77.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 61.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 72.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 110 kB 71.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 100 kB 12.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 121 kB 77.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 76.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 47.3 MB/s \n",
            "\u001b[?25h  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "J0fY56jC0gzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Interactive script\n",
        "from parlai.scripts.interactive import Interactive\n",
        "\n",
        "# The display_data script is used to show the contents of a particular task.\n",
        "# By default, shows train set\n",
        "from parlai.scripts.display_data import DisplayData\n",
        "\n",
        "# Script for training model\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "# Visualize model prediction\n",
        "from parlai.scripts.display_model import DisplayModel\n"
      ],
      "metadata": {
        "id": "tuIlDEET0khD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nbertagnolli/counsel-chat.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-QQ2Jw0u4BE",
        "outputId": "96c7f38f-6fd4-46c1-8e55-aa1dc16aaa8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'counsel-chat'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 35 (delta 11), reused 25 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data selection"
      ],
      "metadata": {
        "id": "nCg02Fou1823"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DisplayData.main(task='personachat', num_examples=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCbJXU7l2CyC",
        "outputId": "b19d539e-5013-4aa9-9a8c-6c1d859e2f1f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19:21:43 | Opt:\n",
            "19:21:43 |     allow_missing_init_opts: False\n",
            "19:21:43 |     batchsize: 1\n",
            "19:21:43 |     datapath: ./data\n",
            "19:21:43 |     datatype: train:ordered\n",
            "19:21:43 |     dict_class: None\n",
            "19:21:43 |     display_add_fields: \n",
            "19:21:43 |     download_path: None\n",
            "19:21:43 |     dynamic_batching: None\n",
            "19:21:43 |     hide_labels: False\n",
            "19:21:43 |     ignore_agent_reply: True\n",
            "19:21:43 |     image_cropsize: 224\n",
            "19:21:43 |     image_mode: raw\n",
            "19:21:43 |     image_size: 256\n",
            "19:21:43 |     init_model: None\n",
            "19:21:43 |     init_opt: None\n",
            "19:21:43 |     is_debug: False\n",
            "19:21:43 |     loglevel: info\n",
            "19:21:43 |     max_display_len: 1000\n",
            "19:21:43 |     model: None\n",
            "19:21:43 |     model_file: None\n",
            "19:21:43 |     multitask_weights: [1]\n",
            "19:21:43 |     mutators: None\n",
            "19:21:43 |     num_examples: 20\n",
            "19:21:43 |     override: \"{'task': 'personachat', 'num_examples': 20}\"\n",
            "19:21:43 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "19:21:43 |     starttime: Jun13_19-21\n",
            "19:21:43 |     task: personachat\n",
            "19:21:43 |     verbose: False\n",
            "19:21:44 | creating task(s): personachat\n",
            "19:21:44 | loading fbdialog data: ./data/Persona-Chat/personachat/train_self_original.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i like to remodel homes.\n",
            "your persona: i like to go hunting.\n",
            "your persona: i like to shoot a bow.\n",
            "your persona: my favorite holiday is halloween.\n",
            "hi , how are you doing ? i am getting ready to do some cheetah chasing to stay in shape .\u001b[0;0m\n",
            "   \u001b[1;94myou must be very fast . hunting is one of my favorite hobbies .\u001b[0;0m\n",
            "\u001b[0mi am ! for my hobby i like to do canning or some whittling .\u001b[0;0m\n",
            "   \u001b[1;94mi also remodel homes when i am not out bow hunting .\u001b[0;0m\n",
            "\u001b[0mthat is neat . when i was in high school i placed 6th in 100m dash !\u001b[0;0m\n",
            "   \u001b[1;94mthat is awesome . do you have a favorite season or time of year ?\u001b[0;0m\n",
            "\u001b[0mi do not . but i do have a favorite meat since that is all i eat exclusively .\u001b[0;0m\n",
            "   \u001b[1;94mwhat is your favorite meat to eat ?\u001b[0;0m\n",
            "\u001b[0mi would have to say its prime rib . do you have any favorite foods ?\u001b[0;0m\n",
            "   \u001b[1;94mi like chicken or macaroni and cheese .\u001b[0;0m\n",
            "\u001b[0mdo you have anything planned for today ? i think i am going to do some canning .\u001b[0;0m\n",
            "   \u001b[1;94mi am going to watch football . what are you canning ?\u001b[0;0m\n",
            "\u001b[0mi think i will can some jam . do you also play footfall for fun ?\u001b[0;0m\n",
            "   \u001b[1;94mif i have time outside of hunting and remodeling homes . which is not much !\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat - - -\u001b[0;0m\n",
            "\u001b[0myour persona: my mom is my best friend.\n",
            "your persona: i have four sisters.\n",
            "your persona: i believe that mermaids are real.\n",
            "your persona: i love iced tea.\n",
            "hi , how are you doing today ?\u001b[0;0m\n",
            "   \u001b[1;94mi am spending time with my 4 sisters what are you up to\u001b[0;0m\n",
            "\u001b[0mwow , four sisters . just watching game of thrones .\u001b[0;0m\n",
            "   \u001b[1;94mthat is a good show i watch that while drinking iced tea\u001b[0;0m\n",
            "\u001b[0mi agree . what do you do for a living ?\u001b[0;0m\n",
            "   \u001b[1;94mi am a researcher i am researching the fact that mermaids are real\u001b[0;0m\n",
            "\u001b[0minteresting . i am a website designer . pretty much spend all my time on the computer .\u001b[0;0m\n",
            "   \u001b[1;94mthat is cool my mom does the same thing\u001b[0;0m\n",
            "\u001b[0mthat is awesome . i have always had a love for technology .\u001b[0;0m\n",
            "   \u001b[1;94mtell me more about yourself\u001b[0;0m\n",
            "\u001b[0mi really enjoy free diving , how about you , have any hobbies ?\u001b[0;0m\n",
            "   \u001b[1;94mi enjoy hanging with my mother she is my best friend\u001b[0;0m\n",
            "\u001b[0mthat is nice . moms are pretty cool too .\u001b[0;0m\n",
            "   \u001b[1;94mi am also fascinated with mermaids\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i had a gig at local theater last night.\n",
            "your persona: i work as a stand up comedian.\n",
            "your persona: i come from a small town.\n",
            "your persona: my favorite drink is cuba libre.\n",
            "your persona: i did a few small roles in tv series.\n",
            "we all live in a yellow submarine , a yellow submarine . morning !\u001b[0;0m\n",
            "   \u001b[1;94mhi ! that is a great line for my next stand up .\u001b[0;0m\n",
            "\u001b[0mlol . i am shy , anything to break the ice , and i am a beatles fan .\u001b[0;0m\n",
            "   \u001b[1;94mi can tell . i am not , you can see me in some tv shows\u001b[0;0m\n",
            "\u001b[0mreally ? what shows ? i like tv , it makes me forget i do not like my family\u001b[0;0m\n",
            "   \u001b[1;94mwow , i wish i had a big family . i grew up in a very small town .\u001b[0;0m\n",
            "\u001b[0mi did too . i do not get along with mine . they have no class .\u001b[0;0m\n",
            "   \u001b[1;94mjust drink some cola with rum and you will forget about them !\u001b[0;0m\n",
            "\u001b[0mput the lime in the coconut as well . . .\u001b[0;0m\n",
            "   \u001b[1;94mnah , plain cuba libre , that is what we drank yesterday at the theater .\u001b[0;0m\n",
            "\u001b[0mi prefer mojitos . watermelon or cucumber .\u001b[0;0m\n",
            "   \u001b[1;94mthose are really yummy too , but not my favorite .\u001b[0;0m\n",
            "19:21:45 | loaded 8939 episodes with a total of 65719 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection"
      ],
      "metadata": {
        "id": "mp5BTwUr3hle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note that if you want to see model-specific arguments, you must specify a model name\n",
        "print(TrainModel.help(model='transformer/generator'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhIT07oK3jaD",
        "outputId": "c1ae00fc-4dd6-4127-9c53-e9afd672bdff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: TrainModel [-h] [--helpall] [-o INIT_OPT]\n",
            "                  [--allow-missing-init-opts ALLOW_MISSING_INIT_OPTS]\n",
            "                  [-t TASK] [-dt DATATYPE] [-bs BATCHSIZE]\n",
            "                  [-dynb {batchsort,None,full}] [-v] [--debug] [-dp DATAPATH]\n",
            "                  [-m MODEL] [-mf MODEL_FILE] [-im INIT_MODEL] [-et EVALTASK]\n",
            "                  [--final-extra-opt FINAL_EXTRA_OPT]\n",
            "                  [--eval-dynamic-batching {batchsort,off,None,full}]\n",
            "                  [--num-workers NUM_WORKERS] [-eps NUM_EPOCHS]\n",
            "                  [-ttim MAX_TRAIN_TIME] [-tstep MAX_TRAIN_STEPS]\n",
            "                  [-lstep LOG_EVERY_N_STEPS] [-vtim VALIDATION_EVERY_N_SECS]\n",
            "                  [-vstep VALIDATION_EVERY_N_STEPS] [-stim SAVE_EVERY_N_SECS]\n",
            "                  [-sval SAVE_AFTER_VALID] [-veps VALIDATION_EVERY_N_EPOCHS]\n",
            "                  [-vp VALIDATION_PATIENCE] [-vmt VALIDATION_METRIC]\n",
            "                  [-vmm {max,min}] [-mcs METRICS] [-micro AGGREGATE_MICRO]\n",
            "                  [--world-logs WORLD_LOGS]\n",
            "                  [--save-format {conversations,parlai}]\n",
            "                  [--log-keep-fields LOG_KEEP_FIELDS] [-tblog TENSORBOARD_LOG]\n",
            "                  [-tblogdir TENSORBOARD_LOGDIR] [-wblog WANDB_LOG]\n",
            "                  [--wandb-project WANDB_PROJECT]\n",
            "                  [--wandb-entity WANDB_ENTITY] [-esz EMBEDDING_SIZE]\n",
            "                  [-nl N_LAYERS] [-hid FFN_SIZE] [--dropout DROPOUT]\n",
            "                  [--attention-dropout ATTENTION_DROPOUT]\n",
            "                  [--relu-dropout RELU_DROPOUT] [--n-heads N_HEADS]\n",
            "                  [--learn-positional-embeddings LEARN_POSITIONAL_EMBEDDINGS]\n",
            "                  [--embeddings-scale EMBEDDINGS_SCALE]\n",
            "                  [--n-segments N_SEGMENTS]\n",
            "                  [--variant {xlm,prelayernorm,bart,aiayn}]\n",
            "                  [--activation {relu,gelu}] [--output-scaling OUTPUT_SCALING]\n",
            "                  [--share-word-embeddings SHARE_WORD_EMBEDDINGS]\n",
            "                  [-nel N_ENCODER_LAYERS] [-ndl N_DECODER_LAYERS]\n",
            "                  [--model-parallel MODEL_PARALLEL]\n",
            "                  [--checkpoint-activations CHECKPOINT_ACTIVATIONS]\n",
            "                  [--beam-size BEAM_SIZE] [--beam-min-length BEAM_MIN_LENGTH]\n",
            "                  [--beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM]\n",
            "                  [--beam-block-ngram BEAM_BLOCK_NGRAM]\n",
            "                  [--beam-block-full-context BEAM_BLOCK_FULL_CONTEXT]\n",
            "                  [--beam-length-penalty BEAM_LENGTH_PENALTY]\n",
            "                  [--inference {nucleus,delayedbeam,greedy,beam,topk}]\n",
            "                  [--topk TOPK] [--topp TOPP] [--beam-delay BEAM_DELAY]\n",
            "                  [--beam-block-list-filename BEAM_BLOCK_LIST_FILENAME]\n",
            "                  [--temperature TEMPERATURE]\n",
            "                  [--compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU]\n",
            "                  [-i INTERACTIVE_MODE]\n",
            "                  [-emb {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}]\n",
            "                  [-embp EMBEDDING_PROJECTION] [--fp16 FP16]\n",
            "                  [--fp16-impl {safe,mem_efficient}] [-opt OPTIMIZER]\n",
            "                  [-lr LEARNINGRATE] [-clip GRADIENT_CLIP]\n",
            "                  [--adafactor-eps ADAFACTOR_EPS] [-mom MOMENTUM]\n",
            "                  [--nesterov NESTEROV] [-nu NUS] [-beta BETAS]\n",
            "                  [-wdecay WEIGHT_DECAY] [-rc RANK_CANDIDATES] [-tr TRUNCATE]\n",
            "                  [--text-truncate TEXT_TRUNCATE]\n",
            "                  [--label-truncate LABEL_TRUNCATE]\n",
            "                  [--history-reversed HISTORY_REVERSED] [-histsz HISTORY_SIZE]\n",
            "                  [-pt PERSON_TOKENS] [--split-lines SPLIT_LINES]\n",
            "                  [--delimiter DELIMITER] [--special-tok-lst SPECIAL_TOK_LST]\n",
            "                  [-gpu GPU | --no-cuda] [--bpe-vocab BPE_VOCAB]\n",
            "                  [--bpe-merge BPE_MERGE] [--bpe-dropout BPE_DROPOUT]\n",
            "                  [--lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}]\n",
            "                  [--lr-scheduler-patience LR_SCHEDULER_PATIENCE]\n",
            "                  [--lr-scheduler-decay LR_SCHEDULER_DECAY]\n",
            "                  [--invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA]\n",
            "\n",
            "Train a model\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "        show this help message and exit\n",
            "  --helpall\n",
            "        Show usage, including advanced arguments.\n",
            "\n",
            "Main ParlAI Arguments:\n",
            "  -o, --init-opt INIT_OPT\n",
            "        Path to json file of options. Note: Further Command-line arguments\n",
            "        override file-based options. (default: None)\n",
            "  --allow-missing-init-opts ALLOW_MISSING_INIT_OPTS\n",
            "        Warn instead of raising if an argument passed in with --init-opt is\n",
            "        not in the target opt. (default: False)\n",
            "  -t, --task TASK\n",
            "        ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: None)\n",
            "  -dt, --datatype DATATYPE\n",
            "        choose from: train, train:ordered, valid, test. to stream data add\n",
            "        \":stream\" to any option (e.g., train:stream). by default train is\n",
            "        random with replacement, valid is ordered, test is ordered. (default:\n",
            "        train)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "        batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {batchsort,None,full}\n",
            "        Use dynamic batching (default: None)\n",
            "  -v, --verbose\n",
            "        Print all messages\n",
            "  --debug\n",
            "        Enables some debug behavior\n",
            "  -dp, --datapath DATAPATH\n",
            "        path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "\n",
            "ParlAI Model Arguments:\n",
            "  -m, --model MODEL\n",
            "        the model class name. can match parlai/agents/<model> for agents in\n",
            "        that directory, or can provide a fully specified module for `from X\n",
            "        import Y` via `-m X:Y` (e.g. `-m\n",
            "        parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`) (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "        model file name for loading and saving models (default: None)\n",
            "  -im, --init-model INIT_MODEL\n",
            "        Initialize model weights and dict from this file (default: None)\n",
            "\n",
            "Training Loop Arguments:\n",
            "  -et, --evaltask EVALTASK\n",
            "        task to use for valid/test (defaults to the one used for training)\n",
            "        (default: None)\n",
            "  --final-extra-opt FINAL_EXTRA_OPT\n",
            "        A '.opt' file that is used for final eval. Useful for setting skip-\n",
            "        generation to false. 'datatype' must be included as part of the opt.\n",
            "        (default: )\n",
            "  --eval-dynamic-batching {batchsort,off,None,full}\n",
            "        Set dynamic batching at evaluation time. Set to off for train-only\n",
            "        dynamic batching. Set to none (default) to use same setting as\n",
            "        --dynamic-batching. (default: None)\n",
            "  --num-workers NUM_WORKERS\n",
            "        Number of background workers (training only) (default: 0)\n",
            "  -eps, --num-epochs NUM_EPOCHS\n",
            "  -ttim, --max-train-time MAX_TRAIN_TIME\n",
            "  -tstep, --max-train-steps, --max-lr-steps MAX_TRAIN_STEPS\n",
            "        End training after n model updates (default: -1)\n",
            "  -lstep, --log-every-n-steps LOG_EVERY_N_STEPS\n",
            "        Log every n training steps (default: 50)\n",
            "  -vtim, --validation-every-n-secs VALIDATION_EVERY_N_SECS\n",
            "        Validate every n seconds. Saves model to model_file (if set) whenever\n",
            "        best val metric is found (default: -1)\n",
            "  -vstep, --validation-every-n-steps VALIDATION_EVERY_N_STEPS\n",
            "        Validate every n training steps. Saves model to model_file (if set)\n",
            "        whenever best val metric is found (default: -1)\n",
            "  -stim, --save-every-n-secs SAVE_EVERY_N_SECS\n",
            "        Saves the model to model_file.checkpoint after every n seconds\n",
            "        (default -1, never). (default: -1)\n",
            "  -sval, --save-after-valid SAVE_AFTER_VALID\n",
            "        Saves the model to model_file.checkpoint after every validation\n",
            "        (default False).\n",
            "  -veps, --validation-every-n-epochs VALIDATION_EVERY_N_EPOCHS\n",
            "        Validate every n epochs. Saves model to model_file (if set) whenever\n",
            "        best val metric is found (default: -1)\n",
            "  -vp, --validation-patience VALIDATION_PATIENCE\n",
            "        number of iterations of validation where result does not improve\n",
            "        before we stop training (default: 10)\n",
            "  -vmt, --validation-metric VALIDATION_METRIC\n",
            "        key into report table for selecting best validation (default:\n",
            "        accuracy)\n",
            "  -vmm, --validation-metric-mode {max,min}\n",
            "        the direction in which to optimize the validation metric, i.e.\n",
            "        maximize or minimize (default: None)\n",
            "  -mcs, --metrics METRICS\n",
            "        list of metrics to show/compute, e.g. all, default,or give a list\n",
            "        split by , like ppl,f1,accuracy,hits@1,rouge,bleuthe rouge metrics\n",
            "        will be computed as rouge-1, rouge-2 and rouge-l (default: default)\n",
            "  -micro, --aggregate-micro AGGREGATE_MICRO\n",
            "        Report micro-averaged metrics instead of macro averaged metrics.\n",
            "        (default: False)\n",
            "  --world-logs WORLD_LOGS\n",
            "        Saves a jsonl file of the world logs.Set to the empty string to not\n",
            "        save at all. (default: )\n",
            "  --save-format {conversations,parlai}\n",
            "\n",
            "World Logging:\n",
            "  --log-keep-fields LOG_KEEP_FIELDS\n",
            "        Fields to keep when logging. Should be a comma separated list\n",
            "        (default: all)\n",
            "\n",
            "Tensorboard Arguments:\n",
            "  -tblog, --tensorboard-log TENSORBOARD_LOG\n",
            "        Tensorboard logging of metrics (default: False)\n",
            "  -tblogdir, --tensorboard-logdir TENSORBOARD_LOGDIR\n",
            "        Tensorboard logging directory, defaults to model_file.tensorboard\n",
            "        (default: None)\n",
            "\n",
            "WandB Arguments:\n",
            "  -wblog, --wandb-log WANDB_LOG\n",
            "        Enable W&B logging of metrics (default: False)\n",
            "  --wandb-project WANDB_PROJECT\n",
            "        W&B project name. Defaults to timestamp. Usually the name of the\n",
            "        sweep. (default: None)\n",
            "  --wandb-entity WANDB_ENTITY\n",
            "        W&B entity name. (default: None)\n",
            "\n",
            "Transformer Arguments:\n",
            "  -esz, --embedding-size EMBEDDING_SIZE\n",
            "        Size of all embedding layers. Must be a multiple of --n-heads.\n",
            "        (default: 300)\n",
            "  -nl, --n-layers N_LAYERS\n",
            "        Number of transformer layers. (default: 2)\n",
            "  -hid, --ffn-size FFN_SIZE\n",
            "        Hidden size of the FFN layers (default: 300)\n",
            "  --dropout DROPOUT\n",
            "        Dropout used around embeddings and before layer layer normalizations.\n",
            "        This is used in Vaswani 2017 and works well on large datasets.\n",
            "        (default: 0.0)\n",
            "  --attention-dropout ATTENTION_DROPOUT\n",
            "        Dropout used after attention softmax. This is not used in Vaswani\n",
            "        2017. (default: 0.0)\n",
            "  --relu-dropout RELU_DROPOUT\n",
            "        Dropout used after the ReLU in the FFN. Not used in Vaswani 2017, but\n",
            "        used in Tensor2Tensor. (default: 0.0)\n",
            "  --n-heads N_HEADS\n",
            "        Number of multihead attention heads (default: 2)\n",
            "  --learn-positional-embeddings LEARN_POSITIONAL_EMBEDDINGS\n",
            "        If off, sinusoidal embeddings are used. If on, position embeddings are\n",
            "        learned from scratch. (default: False)\n",
            "  --embeddings-scale EMBEDDINGS_SCALE\n",
            "  --n-segments N_SEGMENTS\n",
            "        The number of segments that support the model. If zero no segment and\n",
            "        no langs_embedding. (default: 0)\n",
            "  --variant {xlm,prelayernorm,bart,aiayn}\n",
            "        Chooses locations of layer norms, etc. prelayernorm is used to match\n",
            "        some fairseq models (default: aiayn, recommended: xlm)\n",
            "  --activation {relu,gelu}\n",
            "        Nonlinear activation to use. AIAYN uses relu, but more recent papers\n",
            "        prefer gelu. (default: relu, recommended: gelu)\n",
            "  --output-scaling OUTPUT_SCALING\n",
            "        scale the output of every transformer by this quantity. (default: 1.0)\n",
            "  --share-word-embeddings SHARE_WORD_EMBEDDINGS\n",
            "        Share word embeddings table for candidate and contextin the memory\n",
            "        network (default: True)\n",
            "  -nel, --n-encoder-layers N_ENCODER_LAYERS\n",
            "        This will overidde the n-layers for asymmetrical transformers\n",
            "        (default: -1)\n",
            "  -ndl, --n-decoder-layers N_DECODER_LAYERS\n",
            "        This will overidde the n-layers for asymmetrical transformers\n",
            "        (default: -1)\n",
            "  --model-parallel MODEL_PARALLEL\n",
            "        Shard the layers across multiple GPUs. (default: False)\n",
            "  --checkpoint-activations CHECKPOINT_ACTIVATIONS\n",
            "        Recompute activations on backward pass to conserve memory. (default:\n",
            "        False)\n",
            "\n",
            "Torch Generator Agent:\n",
            "  --beam-size BEAM_SIZE\n",
            "        Beam size, if 1 then greedy search (default: 1)\n",
            "  --beam-min-length BEAM_MIN_LENGTH\n",
            "        Minimum length of prediction to be generated by the beam search\n",
            "        (default: 1)\n",
            "  --beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM\n",
            "        Size n-grams to block in beam search from the context. val <= 0\n",
            "        implies no blocking (default: -1)\n",
            "  --beam-block-ngram BEAM_BLOCK_NGRAM\n",
            "        Size n-grams to block in beam search. val <= 0 implies no blocking\n",
            "        (default: -1)\n",
            "  --beam-block-full-context BEAM_BLOCK_FULL_CONTEXT\n",
            "        Block n-grams from the *full* history context. Specify False to block\n",
            "        up to m tokens in the past, where m is truncation parameter for agent\n",
            "        (default: True)\n",
            "  --beam-length-penalty BEAM_LENGTH_PENALTY\n",
            "        Applies a length penalty. Set to 0 for no penalty. (default: 0.65)\n",
            "  --inference {nucleus,delayedbeam,greedy,beam,topk}\n",
            "        Generation algorithm (default: greedy)\n",
            "  --topk TOPK\n",
            "        K used in Top K sampling (default: 10)\n",
            "  --topp TOPP\n",
            "        p used in nucleus sampling (default: 0.9)\n",
            "  --beam-delay BEAM_DELAY\n",
            "        used in delayedbeam search (default: 30)\n",
            "  --beam-block-list-filename BEAM_BLOCK_LIST_FILENAME\n",
            "        Load a text file of hard blocks for beam search to never say.\n",
            "        (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "        temperature to add during decoding (default: 1.0)\n",
            "  --compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU\n",
            "        if true, compute tokenized bleu scores (default: False)\n",
            "\n",
            "TorchAgent Arguments:\n",
            "  -i, --interactive-mode INTERACTIVE_MODE\n",
            "        Whether in full interactive mode or not, which means generating text\n",
            "        or retrieving from a full set of candidates, which is necessary to\n",
            "        actually do full dialogue. However, during training or quick\n",
            "        validation (e.g. PPL for generation or ranking a few candidates for\n",
            "        ranking models) you might want these set to off. Typically, scripts\n",
            "        can set their preferred default behavior at the start, e.g. eval\n",
            "        scripts. (default: False)\n",
            "  -emb, --embedding-type {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}\n",
            "        Choose between different strategies for initializing word embeddings.\n",
            "        Default is random, but can also preinitialize from Glove or Fasttext.\n",
            "        Preinitialized embeddings can also be fixed so they are not updated\n",
            "        during training. (default: random)\n",
            "  -embp, --embedding-projection EMBEDDING_PROJECTION\n",
            "        If pretrained embeddings have a different dimensionality than your\n",
            "        embedding size, strategy for projecting to the correct size. If the\n",
            "        dimensions are the same, this is ignored unless you append \"-force\" to\n",
            "        your choice. (default: random)\n",
            "  --fp16 FP16\n",
            "        Use fp16 computations. (default: False)\n",
            "  --fp16-impl {safe,mem_efficient}\n",
            "        Implementation of FP16 to use (default: safe)\n",
            "  -rc, --rank-candidates RANK_CANDIDATES\n",
            "        Whether the model should parse candidates for ranking. (default:\n",
            "        False)\n",
            "  -tr, --truncate TRUNCATE\n",
            "        Truncate input lengths to increase speed / use less memory. (default:\n",
            "        -1)\n",
            "  --text-truncate TEXT_TRUNCATE\n",
            "        Text input truncation length: if not specified, this will default to\n",
            "        `truncate` (default: None)\n",
            "  --label-truncate LABEL_TRUNCATE\n",
            "        Label truncation length: if not specified, this will default to\n",
            "        `truncate` (default: None)\n",
            "  --history-reversed HISTORY_REVERSED\n",
            "        Reverse the history (default: False)\n",
            "  -histsz, --history-size HISTORY_SIZE\n",
            "        Number of past dialog utterances to remember. (default: -1)\n",
            "  -pt, --person-tokens PERSON_TOKENS\n",
            "        add person tokens to history. adds __p1__ in front of input text and\n",
            "        __p2__ in front of past labels when available or past utterances\n",
            "        generated by the model. these are added to the dictionary during\n",
            "        initialization. (default: False)\n",
            "  --split-lines SPLIT_LINES\n",
            "        split the dialogue history on newlines and save in separate vectors\n",
            "        (default: False)\n",
            "  --delimiter DELIMITER\n",
            "        Join history lines with this token, defaults to newline (default: )\n",
            "  --special-tok-lst SPECIAL_TOK_LST\n",
            "        Comma separated list of special tokens. In case of ambiguous parses\n",
            "        from special tokens, the ordering provided in this arg sets\n",
            "        precedence. (default: None)\n",
            "  -gpu, --gpu GPU\n",
            "        which GPU to use (default: -1)\n",
            "  --no-cuda\n",
            "        disable GPUs even if available. otherwise, will use GPUs if available\n",
            "        on the device.\n",
            "\n",
            "Optimizer Arguments:\n",
            "  -opt, --optimizer OPTIMIZER\n",
            "        Optimizer choice. Possible values: adadelta, adagrad, adam, adamw,\n",
            "        sparseadam, adamax, asgd, sgd, radam, rprop, rmsprop, optimizer,\n",
            "        nadam, lbfgs, mem_eff_adam, adafactor. (default: sgd)\n",
            "  -lr, --learningrate LEARNINGRATE\n",
            "        Learning rate (default: 1)\n",
            "  -clip, --gradient-clip GRADIENT_CLIP\n",
            "        gradient clipping using l2 norm (default: 0.1)\n",
            "  --adafactor-eps ADAFACTOR_EPS\n",
            "        Epsilon values for adafactor optimizer: regularization constants for\n",
            "        square gradient and parameter scale respectively (default: 1e-30,1e-3)\n",
            "  -mom, --momentum MOMENTUM\n",
            "        if applicable, momentum value for optimizer. (default: 0)\n",
            "  --nesterov NESTEROV\n",
            "        if applicable, whether to use nesterov momentum. (default: True)\n",
            "  -nu, --nus NUS\n",
            "        if applicable, nu value(s) for optimizer. can use a single value like\n",
            "        0.7 or a comma-separated tuple like 0.7,1.0 (default: 0.7)\n",
            "  -beta, --betas BETAS\n",
            "        if applicable, beta value(s) for optimizer. can use a single value\n",
            "        like 0.9 or a comma-separated tuple like 0.9,0.999 (default:\n",
            "        0.9,0.999)\n",
            "  -wdecay, --weight-decay WEIGHT_DECAY\n",
            "        Weight decay on the weights. (default: None)\n",
            "\n",
            "BPEHelper Arguments:\n",
            "  --bpe-vocab BPE_VOCAB\n",
            "        path to pre-trained tokenizer vocab (default: None)\n",
            "  --bpe-merge BPE_MERGE\n",
            "        path to pre-trained tokenizer merge (default: None)\n",
            "  --bpe-dropout BPE_DROPOUT\n",
            "        Use BPE dropout during training. (default: None)\n",
            "\n",
            "Learning Rate Scheduler:\n",
            "  --lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}\n",
            "        Learning rate scheduler. (default: reduceonplateau)\n",
            "  --lr-scheduler-patience LR_SCHEDULER_PATIENCE\n",
            "        LR scheduler patience. In number of validation runs. If using fixed\n",
            "        scheduler, LR is decayed every <patience> validations. (default: 3)\n",
            "  --lr-scheduler-decay LR_SCHEDULER_DECAY\n",
            "        Decay factor for LR scheduler, or how much LR is multiplied by when it\n",
            "        is lowered. (default: 0.5)\n",
            "  --invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA\n",
            "        Constant used only to find the lr multiplier for the invsqrt\n",
            "        scheduler. Must be set for --lr-scheduler invsqrt (default: -1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a model"
      ],
      "metadata": {
        "id": "HzAqYchO2DT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training from scratch"
      ],
      "metadata": {
        "id": "ZjAQ6Dc52MYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data"
      ],
      "metadata": {
        "id": "5fie1gRP7Oa0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll save it in the \"from_scratch_model\" directory\n",
        "!rm -rf from_scratch_model\n",
        "!mkdir -p from_scratch_model"
      ],
      "metadata": {
        "id": "Rmg3CeqI7aRB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from parlai.scripts.train_model import TrainModel\n",
        "TrainModel.main(\n",
        "    \n",
        "    # Main parlai arguments\n",
        "    task='empathetic_dialogues',  # train on blended_skill_talk\n",
        "    datapath = './data',\n",
        "\n",
        "    # Model arguments\n",
        "    model='transformer/generator',     # we specify the model type as seq2seq\n",
        "    model_file='from_scratch_model/model', # we MUST provide a filename\n",
        "   \n",
        "    # Training loop arguments\n",
        "    max_train_time=600,\n",
        "    \n",
        "    # Seq2Seq arguments/hyperparameters\n",
        "    #hiddensize = 128,\n",
        "\n",
        "\n",
        "    # Torchagent argument\n",
        "    embedding_type = 'fasttext',\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frgaXSzx2Ggz",
        "outputId": "50adec3a-8ab3-479e-e316-780ef1c6ceb8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:56:07 | building dictionary first...\n",
            "15:56:07 | Opt:\n",
            "15:56:07 |     activation: relu\n",
            "15:56:07 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "15:56:07 |     adam_eps: 1e-08\n",
            "15:56:07 |     add_p1_after_newln: False\n",
            "15:56:07 |     aggregate_micro: False\n",
            "15:56:07 |     allow_missing_init_opts: False\n",
            "15:56:07 |     attention_dropout: 0.0\n",
            "15:56:07 |     batchsize: 1\n",
            "15:56:07 |     beam_block_full_context: True\n",
            "15:56:07 |     beam_block_list_filename: None\n",
            "15:56:07 |     beam_block_ngram: -1\n",
            "15:56:07 |     beam_context_block_ngram: -1\n",
            "15:56:07 |     beam_delay: 30\n",
            "15:56:07 |     beam_length_penalty: 0.65\n",
            "15:56:07 |     beam_min_length: 1\n",
            "15:56:07 |     beam_size: 1\n",
            "15:56:07 |     betas: '(0.9, 0.999)'\n",
            "15:56:07 |     bpe_add_prefix_space: None\n",
            "15:56:07 |     bpe_debug: False\n",
            "15:56:07 |     bpe_dropout: None\n",
            "15:56:07 |     bpe_merge: None\n",
            "15:56:07 |     bpe_vocab: None\n",
            "15:56:07 |     checkpoint_activations: False\n",
            "15:56:07 |     compute_tokenized_bleu: False\n",
            "15:56:07 |     datapath: ./data\n",
            "15:56:07 |     datatype: train\n",
            "15:56:07 |     delimiter: '\\n'\n",
            "15:56:07 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "15:56:07 |     dict_endtoken: __end__\n",
            "15:56:07 |     dict_file: from_scratch_model/model.dict\n",
            "15:56:07 |     dict_include_test: False\n",
            "15:56:07 |     dict_include_valid: False\n",
            "15:56:07 |     dict_initpath: None\n",
            "15:56:07 |     dict_language: english\n",
            "15:56:07 |     dict_loaded: False\n",
            "15:56:07 |     dict_lower: False\n",
            "15:56:07 |     dict_max_ngram_size: -1\n",
            "15:56:07 |     dict_maxexs: -1\n",
            "15:56:07 |     dict_maxtokens: -1\n",
            "15:56:07 |     dict_minfreq: 0\n",
            "15:56:07 |     dict_nulltoken: __null__\n",
            "15:56:07 |     dict_starttoken: __start__\n",
            "15:56:07 |     dict_textfields: text,labels\n",
            "15:56:07 |     dict_tokenizer: re\n",
            "15:56:07 |     dict_unktoken: __unk__\n",
            "15:56:07 |     display_examples: False\n",
            "15:56:07 |     download_path: None\n",
            "15:56:07 |     dropout: 0.0\n",
            "15:56:07 |     dynamic_batching: None\n",
            "15:56:07 |     embedding_projection: random\n",
            "15:56:07 |     embedding_size: 300\n",
            "15:56:07 |     embedding_type: fasttext\n",
            "15:56:07 |     embeddings_scale: True\n",
            "15:56:07 |     eval_batchsize: None\n",
            "15:56:07 |     eval_dynamic_batching: None\n",
            "15:56:07 |     evaltask: None\n",
            "15:56:07 |     ffn_size: 300\n",
            "15:56:07 |     final_extra_opt: \n",
            "15:56:07 |     force_fp16_tokens: False\n",
            "15:56:07 |     fp16: False\n",
            "15:56:07 |     fp16_impl: safe\n",
            "15:56:07 |     gpu: -1\n",
            "15:56:07 |     gradient_clip: 0.1\n",
            "15:56:07 |     hide_labels: False\n",
            "15:56:07 |     history_add_global_end_token: None\n",
            "15:56:07 |     history_reversed: False\n",
            "15:56:07 |     history_size: -1\n",
            "15:56:07 |     image_cropsize: 224\n",
            "15:56:07 |     image_mode: no_image_model\n",
            "15:56:07 |     image_size: 256\n",
            "15:56:07 |     inference: greedy\n",
            "15:56:07 |     init_model: None\n",
            "15:56:07 |     init_opt: None\n",
            "15:56:07 |     interactive_mode: False\n",
            "15:56:07 |     invsqrt_lr_decay_gamma: -1\n",
            "15:56:07 |     is_debug: False\n",
            "15:56:07 |     label_truncate: None\n",
            "15:56:07 |     learn_positional_embeddings: False\n",
            "15:56:07 |     learningrate: 1\n",
            "15:56:07 |     load_from_checkpoint: True\n",
            "15:56:07 |     log_every_n_secs: -1\n",
            "15:56:07 |     log_every_n_steps: 50\n",
            "15:56:07 |     log_keep_fields: all\n",
            "15:56:07 |     loglevel: info\n",
            "15:56:07 |     lr_scheduler: reduceonplateau\n",
            "15:56:07 |     lr_scheduler_decay: 0.5\n",
            "15:56:07 |     lr_scheduler_patience: 3\n",
            "15:56:07 |     max_train_steps: -1\n",
            "15:56:07 |     max_train_time: 600.0\n",
            "15:56:07 |     metrics: default\n",
            "15:56:07 |     model: transformer/generator\n",
            "15:56:07 |     model_file: from_scratch_model/model\n",
            "15:56:07 |     model_parallel: False\n",
            "15:56:07 |     momentum: 0\n",
            "15:56:07 |     multitask_weights: [1]\n",
            "15:56:07 |     mutators: None\n",
            "15:56:07 |     n_decoder_layers: -1\n",
            "15:56:07 |     n_encoder_layers: -1\n",
            "15:56:07 |     n_heads: 2\n",
            "15:56:07 |     n_layers: 2\n",
            "15:56:07 |     n_positions: None\n",
            "15:56:07 |     n_segments: 0\n",
            "15:56:07 |     nesterov: True\n",
            "15:56:07 |     no_cuda: False\n",
            "15:56:07 |     num_epochs: -1\n",
            "15:56:07 |     num_workers: 0\n",
            "15:56:07 |     nus: (0.7,)\n",
            "15:56:07 |     optimizer: sgd\n",
            "15:56:07 |     output_scaling: 1.0\n",
            "15:56:07 |     override: \"{'task': 'empathetic_dialogues', 'datapath': './data', 'model': 'transformer/generator', 'model_file': 'from_scratch_model/model', 'max_train_time': 600.0, 'embedding_type': 'fasttext'}\"\n",
            "15:56:07 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "15:56:07 |     person_tokens: False\n",
            "15:56:07 |     rank_candidates: False\n",
            "15:56:07 |     relu_dropout: 0.0\n",
            "15:56:07 |     save_after_valid: False\n",
            "15:56:07 |     save_every_n_secs: -1\n",
            "15:56:07 |     save_format: conversations\n",
            "15:56:07 |     share_word_embeddings: True\n",
            "15:56:07 |     short_final_eval: False\n",
            "15:56:07 |     skip_generation: False\n",
            "15:56:07 |     special_tok_lst: None\n",
            "15:56:07 |     split_lines: False\n",
            "15:56:07 |     starttime: Jun12_15-56\n",
            "15:56:07 |     task: empathetic_dialogues\n",
            "15:56:07 |     temperature: 1.0\n",
            "15:56:07 |     tensorboard_log: False\n",
            "15:56:07 |     tensorboard_logdir: None\n",
            "15:56:07 |     text_truncate: None\n",
            "15:56:07 |     topk: 10\n",
            "15:56:07 |     topp: 0.9\n",
            "15:56:07 |     train_experiencer_only: False\n",
            "15:56:07 |     truncate: -1\n",
            "15:56:07 |     update_freq: 1\n",
            "15:56:07 |     use_reply: label\n",
            "15:56:07 |     validation_cutoff: 1.0\n",
            "15:56:07 |     validation_every_n_epochs: -1\n",
            "15:56:07 |     validation_every_n_secs: -1\n",
            "15:56:07 |     validation_every_n_steps: -1\n",
            "15:56:07 |     validation_max_exs: -1\n",
            "15:56:07 |     validation_metric: accuracy\n",
            "15:56:07 |     validation_metric_mode: None\n",
            "15:56:07 |     validation_patience: 10\n",
            "15:56:07 |     validation_share_agent: False\n",
            "15:56:07 |     variant: aiayn\n",
            "15:56:07 |     verbose: False\n",
            "15:56:07 |     wandb_entity: None\n",
            "15:56:07 |     wandb_log: False\n",
            "15:56:07 |     wandb_name: None\n",
            "15:56:07 |     wandb_project: None\n",
            "15:56:07 |     warmup_rate: 0.0001\n",
            "15:56:07 |     warmup_updates: -1\n",
            "15:56:07 |     weight_decay: None\n",
            "15:56:07 |     world_logs: \n",
            "15:56:07 | creating task(s): empathetic_dialogues\n",
            "[building data: ./data/empatheticdialogues]\n",
            "15:56:07 | Downloading http://parl.ai/downloads/empatheticdialogues/empatheticdialogues.tar.gz to ./data/empatheticdialogues/empatheticdialogues.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading empatheticdialogues.tar.gz: 100%|██████████| 28.0M/28.0M [00:00<00:00, 34.0MB/s]\n",
            "Building dictionary: 100%|██████████| 64.6k/64.6k [00:03<00:00, 18.1kex/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:56:14 | Saving dictionary to from_scratch_model/model.dict\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15:56:14 | dictionary built with 22419 tokens in 0.0s\n",
            "15:56:14 | No model with opt yet at: from_scratch_model/model(.opt)\n",
            "15:56:14 | Using CUDA\n",
            "15:56:14 | loading dictionary from from_scratch_model/model.dict\n",
            "15:56:14 | num words = 22419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./data/models/fasttext_vectors/wiki.en.vec: 6.60GB [01:46, 62.2MB/s]                            \n",
            "  0%|          | 0/2519370 [00:00<?, ?it/s]Skipping token b'2519370' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|██████████| 2519370/2519370 [03:50<00:00, 10924.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16:02:49 | Initialized embeddings for 16270 tokens (72.6%) from fasttext.\n",
            "16:02:49 | Total parameters: 10,235,700 (9,621,300 trainable)\n",
            "16:02:49 | Opt:\n",
            "16:02:49 |     activation: relu\n",
            "16:02:49 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "16:02:49 |     adam_eps: 1e-08\n",
            "16:02:49 |     add_p1_after_newln: False\n",
            "16:02:49 |     aggregate_micro: False\n",
            "16:02:49 |     allow_missing_init_opts: False\n",
            "16:02:49 |     attention_dropout: 0.0\n",
            "16:02:49 |     batchsize: 1\n",
            "16:02:49 |     beam_block_full_context: True\n",
            "16:02:49 |     beam_block_list_filename: None\n",
            "16:02:49 |     beam_block_ngram: -1\n",
            "16:02:49 |     beam_context_block_ngram: -1\n",
            "16:02:49 |     beam_delay: 30\n",
            "16:02:49 |     beam_length_penalty: 0.65\n",
            "16:02:49 |     beam_min_length: 1\n",
            "16:02:49 |     beam_size: 1\n",
            "16:02:49 |     betas: '(0.9, 0.999)'\n",
            "16:02:49 |     bpe_add_prefix_space: None\n",
            "16:02:49 |     bpe_debug: False\n",
            "16:02:49 |     bpe_dropout: None\n",
            "16:02:49 |     bpe_merge: None\n",
            "16:02:49 |     bpe_vocab: None\n",
            "16:02:49 |     checkpoint_activations: False\n",
            "16:02:49 |     compute_tokenized_bleu: False\n",
            "16:02:49 |     datapath: ./data\n",
            "16:02:49 |     datatype: train\n",
            "16:02:49 |     delimiter: '\\n'\n",
            "16:02:49 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "16:02:49 |     dict_endtoken: __end__\n",
            "16:02:49 |     dict_file: from_scratch_model/model.dict\n",
            "16:02:49 |     dict_include_test: False\n",
            "16:02:49 |     dict_include_valid: False\n",
            "16:02:49 |     dict_initpath: None\n",
            "16:02:49 |     dict_language: english\n",
            "16:02:49 |     dict_loaded: True\n",
            "16:02:49 |     dict_lower: False\n",
            "16:02:49 |     dict_max_ngram_size: -1\n",
            "16:02:49 |     dict_maxexs: -1\n",
            "16:02:49 |     dict_maxtokens: -1\n",
            "16:02:49 |     dict_minfreq: 0\n",
            "16:02:49 |     dict_nulltoken: __null__\n",
            "16:02:49 |     dict_starttoken: __start__\n",
            "16:02:49 |     dict_textfields: text,labels\n",
            "16:02:49 |     dict_tokenizer: re\n",
            "16:02:49 |     dict_unktoken: __unk__\n",
            "16:02:49 |     display_examples: False\n",
            "16:02:49 |     download_path: None\n",
            "16:02:49 |     dropout: 0.0\n",
            "16:02:49 |     dynamic_batching: None\n",
            "16:02:49 |     embedding_projection: random\n",
            "16:02:49 |     embedding_size: 300\n",
            "16:02:49 |     embedding_type: fasttext\n",
            "16:02:49 |     embeddings_scale: True\n",
            "16:02:49 |     eval_batchsize: None\n",
            "16:02:49 |     eval_dynamic_batching: None\n",
            "16:02:49 |     evaltask: None\n",
            "16:02:49 |     ffn_size: 300\n",
            "16:02:49 |     final_extra_opt: \n",
            "16:02:49 |     force_fp16_tokens: False\n",
            "16:02:49 |     fp16: False\n",
            "16:02:49 |     fp16_impl: safe\n",
            "16:02:49 |     gpu: -1\n",
            "16:02:49 |     gradient_clip: 0.1\n",
            "16:02:49 |     hide_labels: False\n",
            "16:02:49 |     history_add_global_end_token: None\n",
            "16:02:49 |     history_reversed: False\n",
            "16:02:49 |     history_size: -1\n",
            "16:02:49 |     image_cropsize: 224\n",
            "16:02:49 |     image_mode: raw\n",
            "16:02:49 |     image_size: 256\n",
            "16:02:49 |     inference: greedy\n",
            "16:02:49 |     init_model: None\n",
            "16:02:49 |     init_opt: None\n",
            "16:02:49 |     interactive_mode: False\n",
            "16:02:49 |     invsqrt_lr_decay_gamma: -1\n",
            "16:02:49 |     is_debug: False\n",
            "16:02:49 |     label_truncate: None\n",
            "16:02:49 |     learn_positional_embeddings: False\n",
            "16:02:49 |     learningrate: 1\n",
            "16:02:49 |     load_from_checkpoint: True\n",
            "16:02:49 |     log_every_n_secs: -1\n",
            "16:02:49 |     log_every_n_steps: 50\n",
            "16:02:49 |     log_keep_fields: all\n",
            "16:02:49 |     loglevel: info\n",
            "16:02:49 |     lr_scheduler: reduceonplateau\n",
            "16:02:49 |     lr_scheduler_decay: 0.5\n",
            "16:02:49 |     lr_scheduler_patience: 3\n",
            "16:02:49 |     max_train_steps: -1\n",
            "16:02:49 |     max_train_time: 600.0\n",
            "16:02:49 |     metrics: default\n",
            "16:02:49 |     model: transformer/generator\n",
            "16:02:49 |     model_file: from_scratch_model/model\n",
            "16:02:49 |     model_parallel: False\n",
            "16:02:49 |     momentum: 0\n",
            "16:02:49 |     multitask_weights: [1]\n",
            "16:02:49 |     mutators: None\n",
            "16:02:49 |     n_decoder_layers: -1\n",
            "16:02:49 |     n_encoder_layers: -1\n",
            "16:02:49 |     n_heads: 2\n",
            "16:02:49 |     n_layers: 2\n",
            "16:02:49 |     n_positions: None\n",
            "16:02:49 |     n_segments: 0\n",
            "16:02:49 |     nesterov: True\n",
            "16:02:49 |     no_cuda: False\n",
            "16:02:49 |     num_epochs: -1\n",
            "16:02:49 |     num_workers: 0\n",
            "16:02:49 |     nus: (0.7,)\n",
            "16:02:49 |     optimizer: sgd\n",
            "16:02:49 |     output_scaling: 1.0\n",
            "16:02:49 |     override: \"{'task': 'empathetic_dialogues', 'datapath': './data', 'model': 'transformer/generator', 'model_file': 'from_scratch_model/model', 'max_train_time': 600.0, 'embedding_type': 'fasttext'}\"\n",
            "16:02:49 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "16:02:49 |     person_tokens: False\n",
            "16:02:49 |     rank_candidates: False\n",
            "16:02:49 |     relu_dropout: 0.0\n",
            "16:02:49 |     save_after_valid: False\n",
            "16:02:49 |     save_every_n_secs: -1\n",
            "16:02:49 |     save_format: conversations\n",
            "16:02:49 |     share_word_embeddings: True\n",
            "16:02:49 |     short_final_eval: False\n",
            "16:02:49 |     skip_generation: False\n",
            "16:02:49 |     special_tok_lst: None\n",
            "16:02:49 |     split_lines: False\n",
            "16:02:49 |     starttime: Jun12_15-56\n",
            "16:02:49 |     task: empathetic_dialogues\n",
            "16:02:49 |     temperature: 1.0\n",
            "16:02:49 |     tensorboard_log: False\n",
            "16:02:49 |     tensorboard_logdir: None\n",
            "16:02:49 |     text_truncate: None\n",
            "16:02:49 |     topk: 10\n",
            "16:02:49 |     topp: 0.9\n",
            "16:02:49 |     train_experiencer_only: False\n",
            "16:02:49 |     truncate: -1\n",
            "16:02:49 |     update_freq: 1\n",
            "16:02:49 |     use_reply: label\n",
            "16:02:49 |     validation_cutoff: 1.0\n",
            "16:02:49 |     validation_every_n_epochs: -1\n",
            "16:02:49 |     validation_every_n_secs: -1\n",
            "16:02:49 |     validation_every_n_steps: -1\n",
            "16:02:49 |     validation_max_exs: -1\n",
            "16:02:49 |     validation_metric: accuracy\n",
            "16:02:49 |     validation_metric_mode: None\n",
            "16:02:49 |     validation_patience: 10\n",
            "16:02:49 |     validation_share_agent: False\n",
            "16:02:49 |     variant: aiayn\n",
            "16:02:49 |     verbose: False\n",
            "16:02:49 |     wandb_entity: None\n",
            "16:02:49 |     wandb_log: False\n",
            "16:02:49 |     wandb_name: None\n",
            "16:02:49 |     wandb_project: None\n",
            "16:02:49 |     warmup_rate: 0.0001\n",
            "16:02:49 |     warmup_updates: -1\n",
            "16:02:49 |     weight_decay: None\n",
            "16:02:49 |     world_logs: \n",
            "16:02:50 | creating task(s): empathetic_dialogues\n",
            "16:02:51 | training...\n",
            "16:02:52 | time:1s total_exs:50 total_steps:50 epochs:0.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.02     1 28.02  1227       0          0 43.78   50  46.42   .01057 17.92 9.947   1 17.92 784.7       0          0 20899   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .03125         0                   50 45.94 2012 43.81\n",
            "\n",
            "16:02:53 | time:2s total_exs:100 total_steps:100 epochs:0.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    28.5     1  28.5  1599       0          0  56.1   50  25.79   .01062 16.12 7.341   1 16.12 904.4       0          0 1543   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .05335         0                  100 44.62 2503 56.13\n",
            "\n",
            "16:02:54 | time:3s total_exs:150 total_steps:150 epochs:0.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    27.9     1  27.9  1584       0          0 56.77   50  20.86   .01059 14.56 7.034   1 14.56 826.7       0          0 1135   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "       .05907         0                  150 42.46 2411 56.8\n",
            "\n",
            "16:02:55 | time:4s total_exs:200 total_steps:200 epochs:0.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.64     1 30.64  1727       0          0 56.35   50  15.73   .01057 21.14 6.907   1 21.14  1191       0          0 999.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .05393         0                  200 51.78 2918 56.37\n",
            "\n",
            "16:02:56 | time:5s total_exs:250 total_steps:250 epochs:0.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.02     1 34.02  1958       0          0 57.54   50  16.55   .01063 17.32 6.867   1 17.32 996.6       0          0 960.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .07968         0                  250 51.34 2954 57.57\n",
            "\n",
            "16:02:57 | time:6s total_exs:300 total_steps:300 epochs:0.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.54     1 34.54  1928       0          0 55.81   50  19.91   .01076 17.22  6.71   1 17.22 961.1       0          0 820.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .07433         0                  300 51.76 2889 55.84\n",
            "\n",
            "16:02:58 | time:7s total_exs:350 total_steps:350 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   40.22     1 40.22  2296       0          0 57.09   50  16.98   .01064  16.6 6.709   1  16.6 947.8       0          0 820.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .06867         0                  350 56.82 3244 57.13\n",
            "\n",
            "16:02:58 | time:7s total_exs:400 total_steps:400 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    27.4     1  27.4  1522       0          0 55.56   50  14.48   .01059 16.68 6.495   1 16.68 926.8       0          0 661.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .09592         0                  400 44.08 2449 55.59\n",
            "\n",
            "16:02:59 | time:8s total_exs:450 total_steps:450 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.4     1  31.4  1774       0          0  56.5   50  12.21    .0106 16.24 6.323   1 16.24 917.7       0          0 557.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .09236         0                  450 47.64 2692 56.53\n",
            "\n",
            "16:03:00 | time:9s total_exs:500 total_steps:500 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.66     1 31.66  1775       0          0 56.05   50  15.76   .01061  15.6 6.328   1  15.6 874.5       0          0 559.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "       .09615         0                  500 47.26 2649 56.08\n",
            "\n",
            "16:03:01 | time:10s total_exs:550 total_steps:550 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.96     1 33.96  1911       0          0 56.27   50  12.88   .01061 14.02 6.214   1 14.02 788.9       0          0 499.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "       .09986         0                  550 47.98 2700 56.3\n",
            "\n",
            "16:03:02 | time:11s total_exs:600 total_steps:600 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.84     1 30.84  1717       0          0 55.68   50  12.68    .0106 17.56 6.467   1 17.56 977.7       0          0 643.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "       .08998         0                  600 48.4 2695 55.71\n",
            "\n",
            "16:03:03 | time:12s total_exs:650 total_steps:650 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.88     1 27.88  1570       0          0 56.31   50  12.05   .01055 17.48 6.067   1 17.48 984.4       0          0 431.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1133         0                  650 45.36 2555 56.35\n",
            "\n",
            "16:03:04 | time:13s total_exs:700 total_steps:700 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.76     1 28.76  1646       0          0 57.23   50  13.56   .01057 14.56 6.185   1 14.56 833.4       0          0 485.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1126         0                  700 43.32 2480 57.26\n",
            "\n",
            "16:03:05 | time:14s total_exs:750 total_steps:750 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    27.5     1  27.5  1471       0          0  53.5   50  10.28   .01058 17.56 5.971   1 17.56 939.6       0          0 391.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1139         0                  750 45.06 2411 53.53\n",
            "\n",
            "16:03:06 | time:15s total_exs:800 total_steps:800 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.86     1 30.86  1678       0          0 54.36   50  10.41   .01057 16.04 5.866   1 16.04   872       0          0 352.8   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .1147         0                  800 46.9 2550 54.4\n",
            "\n",
            "16:03:07 | time:16s total_exs:850 total_steps:850 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.7     1  32.7  1848       0          0  56.5   50  10.36   .01055 17.24 5.866   1 17.24 974.2       0          0 352.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1288         0                  850 49.94 2822 56.54\n",
            "\n",
            "16:03:08 | time:17s total_exs:900 total_steps:900 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    26.8     1  26.8  1531       0          0 57.11   50  12.32   .01054 14.94 6.031   1 14.94 853.3       0          0  416   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1071         0                  900 41.74 2384 57.14\n",
            "\n",
            "16:03:08 | time:17s total_exs:950 total_steps:950 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   43.42     1 43.42  2442       0          0 56.24   50  10.87   .01087 19.34 6.033   1 19.34  1088       0          0  417   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1251         0                  950 62.76 3530 56.27\n",
            "\n",
            "16:03:09 | time:18s total_exs:1000 total_steps:1000 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.92     1 29.92  1674       0          0 55.96   50  11.31   .01062 15.98 6.015   1 15.98 894.3       0          0 409.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1126         0                 1000 45.9 2569 55.99\n",
            "\n",
            "16:03:10 | time:19s total_exs:1050 total_steps:1050 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.3     1  34.3  1953       0          0 56.92   50  12.02   .01065  16.1 5.983   1  16.1 916.5       0          0 396.6   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1304         0                 1050 50.4 2869 56.95\n",
            "\n",
            "16:03:11 | time:20s total_exs:1100 total_steps:1100 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   30.78     1 30.78  1757       0          0 57.09   50   10.3    .0106 15.54 5.913   1 15.54 887.2       0          0  370   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1429         0                 1100 46.32 2645 57.12\n",
            "\n",
            "16:03:12 | time:21s total_exs:1150 total_steps:1150 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.72     1 32.72  1854       0          0 56.66   50  11.75   .01072 16.24 6.198   1 16.24 920.3       0          0 491.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1010         0                 1150 48.96 2775 56.7\n",
            "\n",
            "16:03:13 | time:22s total_exs:1200 total_steps:1200 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.18     1 35.18  1986       0          0 56.46   50  10.68   .01076 15.86 5.745   1 15.86 895.5       0          0 312.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1148         0                 1200 51.04 2882 56.49\n",
            "\n",
            "16:03:14 | time:23s total_exs:1250 total_steps:1250 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.8     1  25.8  1448       0          0 56.14   50  10.68   .01056 16.62 5.824   1 16.62   933       0          0 338.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1047         0                 1250 42.42 2382 56.17\n",
            "\n",
            "16:03:15 | time:24s total_exs:1300 total_steps:1300 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.16     1 33.16  1884       0          0 56.81   50  11.21   .01059 14.44 5.636   1 14.44 820.4       0          0 280.4   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1274         0                 1300 47.6 2705 56.84\n",
            "\n",
            "16:03:16 | time:25s total_exs:1350 total_steps:1350 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.22     1 32.22  1808       0          0 56.11   50  10.47   .01073 18.72 5.694   1 18.72  1050       0          0 297.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1432         0                 1350 50.94 2858 56.14\n",
            "\n",
            "16:03:17 | time:26s total_exs:1400 total_steps:1400 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.98     1 37.98  2123       0          0 55.88   50  9.896   .01072 19.66 5.844   1 19.66  1099       0          0 345.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1261         0                 1400 57.64 3221 55.92\n",
            "\n",
            "16:03:17 | time:26s total_exs:1450 total_steps:1450 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.72     1 28.72  1624       0          0 56.53   50  11.33   .01058 13.72 5.617   1 13.72 775.7       0          0 275.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1545         0                 1450 42.44 2400 56.57\n",
            "\n",
            "16:03:18 | time:27s total_exs:1500 total_steps:1500 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   24.92     1 24.92  1404       0          0 56.32   50  10.86   .01055 17.18 5.715   1 17.18 967.7       0          0 303.4   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1362         0                 1500 42.1 2372 56.36\n",
            "\n",
            "16:03:19 | time:28s total_exs:1550 total_steps:1550 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.58     1 29.58  1687       0          0 57.02   50  12.53   .01062  12.8  5.56   1  12.8   730       0          0 259.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1391         0                 1550 42.38 2417 57.06\n",
            "\n",
            "16:03:20 | time:29s total_exs:1600 total_steps:1600 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.98     1 37.98  2146       0          0 56.49   50   11.4   .01066 14.86 5.551   1 14.86 839.5       0          0 257.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1480         0                 1600 52.84 2985 56.52\n",
            "\n",
            "16:03:21 | time:30s total_exs:1650 total_steps:1650 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.88     1 35.88  2052       0          0 57.18   50  10.76   .01074 17.28  5.62   1 17.28 988.1       0          0 275.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1354         0                 1650 53.16 3040 57.21\n",
            "\n",
            "16:03:22 | time:31s total_exs:1700 total_steps:1700 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      30     1    30  1716       0          0 57.19   50   10.3    .0106 16.12 5.417   1 16.12   922       0          0 225.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1737         0                 1700 46.12 2638 57.22\n",
            "\n",
            "16:03:23 | time:32s total_exs:1750 total_steps:1750 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   34.64     1 34.64  1958       0          0 56.51   50  10.96   .01077 16.74 6.023   1 16.74 946.1       0          0  413   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1171         0                 1750 51.38 2904 56.54\n",
            "\n",
            "16:03:24 | time:33s total_exs:1800 total_steps:1800 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.8     1  26.8  1542       0          0 57.54   50  11.51   .01057 14.74 5.408   1 14.74 848.2       0          0 223.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1167         0                 1800 41.54 2390 57.57\n",
            "\n",
            "16:03:25 | time:34s total_exs:1850 total_steps:1850 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.32     1 38.32  2141       0          0 55.87   50  10.96   .01068  15.2 5.493   1  15.2 849.3       0          0 243.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1566         0                 1850 53.52 2990 55.9\n",
            "\n",
            "16:03:25 | time:34s total_exs:1900 total_steps:1900 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    41.6     1  41.6  2320       0          0 55.77   50  10.19   .01081 19.72 5.812   1 19.72  1100       0          0 334.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1339         0                 1900 61.32 3420 55.8\n",
            "\n",
            "16:03:26 | time:35s total_exs:1950 total_steps:1950 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.18     1 26.18  1503       0          0  57.4   50  10.14    .0106  14.5 5.465   1  14.5 832.3       0          0 236.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1434         0                 1950 40.68 2335 57.44\n",
            "\n",
            "16:03:27 | time:36s total_exs:2000 total_steps:2000 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.68     1 28.68  1654       0          0 57.66   50  11.74   .01057 14.04 5.758   1 14.04 809.7       0          0 316.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1282         0                 2000 42.72 2464 57.7\n",
            "\n",
            "16:03:28 | time:37s total_exs:2050 total_steps:2050 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.94     1 29.94  1693       0          0 56.53   50  10.06   .01057 18.44 5.776   1 18.44  1042       0          0 322.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1421         0                 2050 48.38 2735 56.56\n",
            "\n",
            "16:03:29 | time:38s total_exs:2100 total_steps:2100 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.96     1 33.96  1943       0          0 57.21   50  10.48    .0106 15.64 5.373   1 15.64 894.8       0          0 215.5   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1522         0                 2100 49.6 2838 57.24\n",
            "\n",
            "16:03:30 | time:39s total_exs:2150 total_steps:2150 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.08     1 28.08  1612       0          0 57.41   50  10.27    .0106 16.98 5.265   1 16.98 974.9       0          0 193.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1378         0                 2150 45.06 2587 57.44\n",
            "\n",
            "16:03:31 | time:40s total_exs:2200 total_steps:2200 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.34     1 25.34  1446       0          0 57.05   50  12.09    .0106 15.58  5.71   1 15.58   889       0          0 301.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1412         0                 2200 40.92 2335 57.09\n",
            "\n",
            "16:03:32 | time:41s total_exs:2250 total_steps:2250 epochs:0.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.32     1 32.32  1856       0          0 57.41   50  11.39   .01062 13.86 5.338   1 13.86 795.7       0          0 208.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1515         0                 2250 46.18 2651 57.44\n",
            "\n",
            "16:03:33 | time:42s total_exs:2300 total_steps:2300 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.54     1 25.54  1461       0          0 57.19   50   10.6   .01055  15.3 5.219   1  15.3 875.1       0          0 184.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1529         0                 2300 40.84 2336 57.22\n",
            "\n",
            "16:03:34 | time:43s total_exs:2350 total_steps:2350 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.12     1 35.12  1875       0          0  53.4   50  11.79   .01066 16.48 5.583   1 16.48   880       0          0 265.8   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1529         0                 2350 51.6 2755 53.43\n",
            "\n",
            "16:03:34 | time:43s total_exs:2400 total_steps:2400 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.66     1 31.66  1675       0          0 52.88   50  11.37    .0106  15.8 5.607   1  15.8 835.6       0          0 272.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1506         0                 2400 47.46 2510 52.92\n",
            "\n",
            "16:03:35 | time:44s total_exs:2450 total_steps:2450 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.12     1 29.12  1600       0          0 54.93   50  11.32    .0106 15.02 5.539   1 15.02 825.2       0          0 254.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1531         0                 2450 44.14 2425 54.97\n",
            "\n",
            "16:03:36 | time:45s total_exs:2500 total_steps:2500 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.56     1 27.56  1548       0          0 56.15   50   11.3   .01054 14.28 5.427   1 14.28 801.9       0          0 227.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1597         0                 2500 41.84 2350 56.18\n",
            "\n",
            "16:03:37 | time:46s total_exs:2550 total_steps:2550 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.76     1 23.76  1350       0          0 56.81   50  10.52   .01065 16.58 5.523   1 16.58   942       0          0 250.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1484         0                 2550 40.34 2292 56.84\n",
            "\n",
            "16:03:38 | time:47s total_exs:2600 total_steps:2600 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.7     1  28.7  1637       0          0 57.02   50  10.48    .0106  17.8 5.561   1  17.8  1015       0          0 260.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1674         0                 2600 46.5 2652 57.05\n",
            "\n",
            "16:03:39 | time:48s total_exs:2650 total_steps:2650 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   29.14     1 29.14  1677       0          0 57.54   50  11.35   .01054 15.68 5.308   1 15.68 902.3       0          0  202   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1480         0                 2650 44.82 2579 57.57\n",
            "\n",
            "16:03:40 | time:49s total_exs:2700 total_steps:2700 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.92     1 27.92  1603       0          0 57.39   50  10.94   .01055 15.72 5.335   1 15.72 902.3       0          0 207.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1527         0                 2700 43.64 2505 57.43\n",
            "\n",
            "16:03:41 | time:50s total_exs:2750 total_steps:2750 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.76     1 26.76  1526       0          0 57.01   50  11.34    .0106 15.56 5.121   1 15.56 887.1       0          0 167.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1761         0                 2750 42.32 2413 57.04\n",
            "\n",
            "16:03:42 | time:51s total_exs:2800 total_steps:2800 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.96     1 28.96  1642       0          0 56.69   50   10.5   .01061 15.84 5.086   1 15.84   898       0          0 161.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1806         0                 2800 44.8 2540 56.72\n",
            "\n",
            "16:03:43 | time:52s total_exs:2850 total_steps:2850 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   35.36     1 35.36  2023       0          0 57.21   50  10.75   .01058  16.1 5.521   1  16.1 921.1       0          0  250   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1466         0                 2850 51.46 2944 57.24\n",
            "\n",
            "16:03:43 | time:52s total_exs:2900 total_steps:2900 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   23.24     1 23.24  1318       0          0 56.72   50  11.03   .01056 14.58 5.537   1 14.58   827       0          0  254   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1509         0                 2900 37.82 2145 56.75\n",
            "\n",
            "16:03:44 | time:53s total_exs:2950 total_steps:2950 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.76     1 31.76  1818       0          0 57.24   50  11.03    .0106 13.12 5.146   1 13.12   751       0          0 171.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1799         0                 2950 44.88 2569 57.27\n",
            "\n",
            "16:03:45 | time:54s total_exs:3000 total_steps:3000 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.06     1 29.06  1659       0          0 57.07   50  10.19   .01061 16.16 5.029   1 16.16 922.3       0          0 152.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1869         0                 3000 45.22 2581 57.1\n",
            "\n",
            "16:03:46 | time:55s total_exs:3050 total_steps:3050 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.24     1 27.24  1540       0          0 56.54   50  10.06   .01054 15.72 5.218   1 15.72 888.9       0          0 184.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1743         0                 3050 42.96 2429 56.57\n",
            "\n",
            "16:03:47 | time:56s total_exs:3100 total_steps:3100 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.42     1 29.42  1677       0          0 56.98   50   11.1   .01055  14.8 5.241   1  14.8 843.4       0          0 188.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1514         0                 3100 44.22 2520 57.01\n",
            "\n",
            "16:03:48 | time:57s total_exs:3150 total_steps:3150 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.48     1 32.48  1851       0          0 56.99   50  10.61   .01064 15.56  5.25   1 15.56 886.8       0          0 190.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1864         0                 3150 48.04 2738 57.02\n",
            "\n",
            "16:03:49 | time:58s total_exs:3200 total_steps:3200 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.64     1 31.64  1843       0          0 58.26   50  12.16   .01066 12.76 5.279   1 12.76 743.4       0          0 196.2   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1693         0                 3200 44.4 2587 58.29\n",
            "\n",
            "16:03:50 | time:59s total_exs:3250 total_steps:3250 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   35.42     1 35.42  1996       0          0 56.35   50  9.606    .0107 18.26 5.455   1 18.26  1029       0          0  234   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1665         0                 3250 53.68 3025 56.38\n",
            "\n",
            "16:03:51 | time:60s total_exs:3300 total_steps:3300 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.46     1 36.46  2080       0          0 57.04   50  10.97   .01069  16.5 5.047   1  16.5 941.3       0          0 155.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1661         0                 3300 52.96 3021 57.07\n",
            "\n",
            "16:03:51 | time:60s total_exs:3350 total_steps:3350 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.28     1 31.28  1768       0          0 56.52   50  10.84   .01063 16.76 5.047   1 16.76 947.3       0          0 155.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1802         0                 3350 48.04 2715 56.55\n",
            "\n",
            "16:03:52 | time:61s total_exs:3400 total_steps:3400 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   40.02     1 40.02  2253       0          0 56.28   50  10.31    .0107  18.7 5.409   1  18.7  1053       0          0 223.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1455         0                 3400 58.72 3305 56.32\n",
            "\n",
            "16:03:54 | time:63s total_exs:3450 total_steps:3450 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.68     1 31.68  1343       0          0 42.32   50  9.757   .01057  16.9  4.83   1  16.9 715.3       0          0 125.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1775         0                 3450 48.58 2060 42.42\n",
            "\n",
            "16:03:55 | time:64s total_exs:3500 total_steps:3500 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.46     1 28.46  1074       0          0 37.72   50  10.13   .01059  15.9 5.323   1  15.9 599.8       0          0  205   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1434         0                 3500 44.36 1674 37.74\n",
            "\n",
            "16:03:56 | time:65s total_exs:3550 total_steps:3550 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      30     1    30  1571       0          0 52.35   50  11.58   .01058 15.86  5.12   1 15.86 830.3       0          0 167.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1690         0                 3550 45.86 2401 52.37\n",
            "\n",
            "16:03:57 | time:66s total_exs:3600 total_steps:3600 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.38     1 26.38  1518       0          0 57.45   50  10.61   .01055 14.14 4.897   1 14.14 813.4       0          0 133.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1740         0                 3600 40.52 2331 57.56\n",
            "\n",
            "16:03:58 | time:67s total_exs:3650 total_steps:3650 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   33.42     1 33.42  1895       0          0 56.69   50  10.01   .01059 16.22  4.97   1 16.22 919.5       0          0  144   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1800         0                 3650 49.64 2814 56.72\n",
            "\n",
            "16:03:59 | time:68s total_exs:3700 total_steps:3700 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    35.9     1  35.9  2029       0          0  56.5   50  9.879   .01063 18.36 5.063   1 18.36  1037       0          0  158   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1885         0                 3700 54.26 3066 56.53\n",
            "\n",
            "16:03:59 | time:68s total_exs:3750 total_steps:3750 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    27.3     1  27.3  1549       0          0 56.73   50  10.97   .01062 16.14 5.321   1 16.14 915.7       0          0 204.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1586         0                 3750 43.44 2465 56.76\n",
            "\n",
            "16:04:00 | time:69s total_exs:3800 total_steps:3800 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.36     1 28.36  1601       0          0 56.46   50  11.44   .01058 14.26 4.966   1 14.26 805.1       0          0 143.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1992         0                 3800 42.62 2406 56.49\n",
            "\n",
            "16:04:01 | time:70s total_exs:3850 total_steps:3850 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.96     1 31.96  1818       0          0 56.87   50  10.68   .01061 13.84 4.868   1 13.84 787.2       0          0 130.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .1908         0                 3850 45.8 2605 56.9\n",
            "\n",
            "16:04:02 | time:71s total_exs:3900 total_steps:3900 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.94     1 34.94  1992       0          0 57.01   50  11.29   .01058 14.88 5.343   1 14.88 848.4       0          0 209.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1559         0                 3900 49.82 2841 57.04\n",
            "\n",
            "16:04:03 | time:72s total_exs:3950 total_steps:3950 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.24     1 34.24  1957       0          0 57.16   50  9.911   .01063 17.76 5.145   1 17.76  1015       0          0 171.5   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1802         0                 3950   52 2973 57.19\n",
            "\n",
            "16:04:04 | time:73s total_exs:4000 total_steps:4000 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.04     1 31.04  1760       0          0 56.69   50  10.63   .01066 15.88 5.374   1 15.88 900.3       0          0 215.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1587         0                 4000 46.92 2660 56.72\n",
            "\n",
            "16:04:05 | time:74s total_exs:4050 total_steps:4050 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.14     1 36.14  1988       0          0 55.01   50  10.39   .01063 18.26 5.065   1 18.26  1005       0          0 158.4   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1709         0                 4050 54.4 2993 55.04\n",
            "\n",
            "16:04:06 | time:75s total_exs:4100 total_steps:4100 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      27     1    27  1514       0          0 56.06   50  10.92   .01055 15.62 5.292   1 15.62 875.7       0          0 198.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1716         0                 4100 42.62 2389 56.09\n",
            "\n",
            "16:04:07 | time:76s total_exs:4150 total_steps:4150 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.64     1 33.64  1891       0          0 56.21   50  11.17   .01059 16.98 5.311   1 16.98 954.5       0          0 202.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1543         0                 4150 50.62 2846 56.24\n",
            "\n",
            "16:04:08 | time:76s total_exs:4200 total_steps:4200 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.38     1 30.38  1724       0          0 56.75   50  10.01   .01056 17.12  4.96   1 17.12 971.6       0          0 142.6   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1998         0                 4200 47.5 2696 56.78\n",
            "\n",
            "16:04:08 | time:77s total_exs:4250 total_steps:4250 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.18     1 34.18  1923       0          0 56.26   50  10.08   .01063 17.16 5.158   1 17.16 965.6       0          0 173.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1713         0                 4250 51.34 2889 56.3\n",
            "\n",
            "16:04:09 | time:78s total_exs:4300 total_steps:4300 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.26     1 25.26  1420       0          0 56.21   50  11.58   .01054 14.64 4.907   1 14.64   823       0          0 135.2   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1981         0                 4300 39.9 2243 56.25\n",
            "\n",
            "16:04:10 | time:79s total_exs:4350 total_steps:4350 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.66     1 35.66  2026       0          0  56.8   50  9.415   .01075 17.98 5.047   1 17.98  1021       0          0 155.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1735         0                 4350 53.64 3047 56.84\n",
            "\n",
            "16:04:11 | time:80s total_exs:4400 total_steps:4400 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.6     1  28.6  1625       0          0 56.82   50  9.769   .01054 16.46 5.172   1 16.46 935.2       0          0 176.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1762         0                 4400 45.06 2560 56.85\n",
            "\n",
            "16:04:12 | time:81s total_exs:4450 total_steps:4450 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.74     1 32.74  1811       0          0  55.3   50  11.67   .01063 12.82 4.883   1 12.82 709.1       0          0 132.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2137         0                 4450 45.56 2520 55.34\n",
            "\n",
            "16:04:13 | time:82s total_exs:4500 total_steps:4500 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.74     1 28.74  1597       0          0 55.56   50  9.567   .01062 17.52 5.209   1 17.52 973.4       0          0  183   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1655         0                 4500 46.26 2570 55.59\n",
            "\n",
            "16:04:14 | time:83s total_exs:4550 total_steps:4550 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.42     1 30.42  1702       0          0 55.93   50  10.14   .01057 15.64 5.034   1 15.64 874.8       0          0 153.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1957         0                 4550 46.06 2576 55.96\n",
            "\n",
            "16:04:15 | time:84s total_exs:4600 total_steps:4600 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    38.8     1  38.8  2203       0          0 56.78   50  10.16   .01088 18.74 5.356   1 18.74  1064       0          0 211.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1633         0                 4600 57.54 3268 56.81\n",
            "\n",
            "16:04:16 | time:85s total_exs:4650 total_steps:4650 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.34     1 28.34  1598       0          0 56.39   50   10.5   .01057 14.66  5.12   1 14.66 826.8       0          0 167.3   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1787         0                 4650   43 2425 56.43\n",
            "\n",
            "16:04:17 | time:86s total_exs:4700 total_steps:4700 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.16     1 28.16  1588       0          0 56.39   50   10.4    .0106 16.56 5.086   1 16.56 933.9       0          0 161.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1763         0                 4700 44.72 2522 56.44\n",
            "\n",
            "16:04:17 | time:86s total_exs:4750 total_steps:4750 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.86     1 28.86  1626       0          0 56.33   50  10.04   .01059 19.12 5.001   1 19.12  1077       0          0 148.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1768         0                 4750 47.98 2703 56.36\n",
            "\n",
            "16:04:18 | time:87s total_exs:4800 total_steps:4800 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.08     1 31.08  1774       0          0 57.06   50  10.15   .01056  17.3 5.046   1  17.3 987.3       0          0 155.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1780         0                 4800 48.38 2761 57.1\n",
            "\n",
            "16:04:19 | time:88s total_exs:4850 total_steps:4850 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.08     1 38.08  2141       0          0 56.23   50   11.3   .01073 17.74 5.073   1 17.74 997.6       0          0 159.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1623         0                 4850 55.82 3139 56.26\n",
            "\n",
            "16:04:20 | time:89s total_exs:4900 total_steps:4900 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.26     1 32.26  1828       0          0 56.67   50  10.51   .01064 16.84 5.128   1 16.84 954.4       0          0 168.6   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .1924         0                 4900 49.1 2783 56.7\n",
            "\n",
            "16:04:21 | time:90s total_exs:4950 total_steps:4950 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.14     1 28.14  1582       0          0 56.22   50  9.886   .01055 16.92 4.876   1 16.92 951.2       0          0 131.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2009         0                 4950 45.06 2533 56.25\n",
            "\n",
            "16:04:22 | time:91s total_exs:5000 total_steps:5000 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.66     1 29.66  1681       0          0 56.66   50  10.09   .01061 16.12 5.035   1 16.12 913.5       0          0 153.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1811         0                 5000 45.78 2594 56.7\n",
            "\n",
            "16:04:23 | time:92s total_exs:5050 total_steps:5050 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.46     1 28.46  1622       0          0 56.98   50  10.84   .01057 15.64 5.163   1 15.64 891.2       0          0 174.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1765         0                 5050 44.1 2513 57.01\n",
            "\n",
            "16:04:24 | time:93s total_exs:5100 total_steps:5100 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.98     1 27.98  1610       0          0 57.53   50  9.774    .0106 18.46 4.994   1 18.46  1062       0          0 147.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1733         0                 5100 46.44 2672 57.57\n",
            "\n",
            "16:04:25 | time:94s total_exs:5150 total_steps:5150 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   29.66     1 29.66  1709       0          0 57.61   50  10.38   .01058 16.62 4.963   1 16.62 957.5       0          0  143   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2094         0                 5150 46.28 2666 57.64\n",
            "\n",
            "16:04:25 | time:94s total_exs:5200 total_steps:5200 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.38     1 27.38  1592       0          0 58.15   50  11.62   .01054  16.1 4.882   1  16.1 936.3       0          0 131.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2261         0                 5200 43.48 2529 58.18\n",
            "\n",
            "16:04:26 | time:95s total_exs:5250 total_steps:5250 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.1     1  28.1  1584       0          0 56.37   50  10.38   .01061 14.64 4.821   1 14.64 825.3       0          0 124.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2254         0                 5250 42.74 2409 56.4\n",
            "\n",
            "16:04:27 | time:96s total_exs:5300 total_steps:5300 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   24.28     1 24.28  1364       0          0 56.19   50  9.898    .0106 15.54 4.936   1 15.54 873.2       0          0 139.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1943         0                 5300 39.82 2238 56.22\n",
            "\n",
            "16:04:28 | time:97s total_exs:5350 total_steps:5350 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.84     1 30.84  1743       0          0 56.51   50  10.46   .01066 17.82 4.925   1 17.82  1007       0          0 137.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2054         0                 5350 48.66 2750 56.56\n",
            "\n",
            "16:04:29 | time:98s total_exs:5400 total_steps:5400 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   27.66     1 27.66  1560       0          0 56.38   50  10.49   .01061 16.54 4.912   1 16.54 932.6       0          0  136   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1814         0                 5400 44.2 2492 56.41\n",
            "\n",
            "16:04:30 | time:99s total_exs:5450 total_steps:5450 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.08     1 31.08  1757       0          0 56.52   50  10.07   .01064 16.72 5.086   1 16.72   945       0          0 161.8   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1782         0                 5450 47.8 2702 56.55\n",
            "\n",
            "16:04:31 | time:100s total_exs:5500 total_steps:5500 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.54     1 32.54  1839       0          0  56.5   50  10.39   .01069 16.34 5.103   1 16.34 923.3       0          0 164.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1873         0                 5500 48.88 2762 56.53\n",
            "\n",
            "16:04:32 | time:101s total_exs:5550 total_steps:5550 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.58     1 29.58  1660       0          0 56.11   50  10.18   .01059  15.5  5.02   1  15.5 869.8       0          0 151.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1987         0                 5550 45.08 2530 56.15\n",
            "\n",
            "16:04:33 | time:102s total_exs:5600 total_steps:5600 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   26.26     1 26.26  1509       0          0 57.48   50  10.24   .01053  14.9 4.745   1  14.9 856.5       0          0  115   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2134         0                 5600 41.16 2366 57.52\n",
            "\n",
            "16:04:34 | time:102s total_exs:5650 total_steps:5650 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.94     1 29.94  1717       0          0 57.33   50  11.41   .01063 14.36 5.038   1 14.36 823.3       0          0 154.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1950         0                 5650 44.3 2540 57.36\n",
            "\n",
            "16:04:34 | time:103s total_exs:5700 total_steps:5700 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.92     1 30.92  1767       0          0 57.13   50  10.28   .01058 15.68 5.203   1 15.68 895.9       0          0 181.9   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1722         0                 5700 46.6 2663 57.16\n",
            "\n",
            "16:04:35 | time:104s total_exs:5750 total_steps:5750 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.1     1  31.1  1775       0          0 57.07   50   9.99   .01063 15.72 5.006   1 15.72 897.2       0          0 149.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1679         0                 5750 46.82 2672 57.1\n",
            "\n",
            "16:04:36 | time:105s total_exs:5800 total_steps:5800 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   27.02     1 27.02  1470       0          0  54.4   50  9.965   .01055  15.9  4.89   1  15.9   865       0          0  133   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1950         0                 5800 42.92 2335 54.43\n",
            "\n",
            "16:04:37 | time:106s total_exs:5850 total_steps:5850 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.64     1 30.64  1734       0          0 56.59   50  9.817    .0106  15.9 4.692   1  15.9 899.8       0          0 109.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2075         0                 5850 46.54 2634 56.62\n",
            "\n",
            "16:04:38 | time:107s total_exs:5900 total_steps:5900 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.06     1 28.06  1594       0          0  56.8   50  9.759   .01056  16.6 5.038   1  16.6 942.9       0          0 154.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2036         0                 5900 44.66 2537 56.83\n",
            "\n",
            "16:04:39 | time:108s total_exs:5950 total_steps:5950 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.72     1 30.72  1744       0          0 56.77   50  10.78   .01059 16.14 4.946   1 16.14 916.3       0          0 140.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1611         0                 5950 46.86 2660 56.8\n",
            "\n",
            "16:04:40 | time:109s total_exs:6000 total_steps:6000 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.1     1  29.1  1648       0          0 56.62   50  9.761   .01055  16.9 4.921   1  16.9 956.9       0          0 137.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1905         0                 6000   46 2605 56.65\n",
            "\n",
            "16:04:41 | time:110s total_exs:6050 total_steps:6050 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.12     1 30.12  1732       0          0  57.5   50  10.14   .01059 17.28 5.074   1 17.28 993.7       0          0 159.8   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1956         0                 6050 47.4 2726 57.54\n",
            "\n",
            "16:04:42 | time:111s total_exs:6100 total_steps:6100 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.78     1 33.78  1885       0          0 55.79   50  10.75   .01063 13.28 4.966   1 13.28 740.9       0          0 143.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1717         0                 6100 47.06 2626 55.82\n",
            "\n",
            "16:04:43 | time:111s total_exs:6150 total_steps:6150 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.36     1 30.36  1738       0          0 57.24   50  10.14   .01058 15.48 4.832   1 15.48 886.1       0          0 125.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1835         0                 6150 45.84 2624 57.27\n",
            "\n",
            "16:04:43 | time:112s total_exs:6200 total_steps:6200 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.14     1 33.14  1897       0          0 57.24   50  9.735   .01065 16.32 4.981   1 16.32 934.2       0          0 145.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1985         0                 6200 49.46 2831 57.27\n",
            "\n",
            "16:04:44 | time:113s total_exs:6250 total_steps:6250 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.88     1 34.88  1953       0          0 55.99   50  10.08    .0106 17.14 4.912   1 17.14 959.8       0          0 135.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1762         0                 6250 52.02 2913 56.02\n",
            "\n",
            "16:04:45 | time:114s total_exs:6300 total_steps:6300 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.06     1 30.06  1705       0          0 56.71   50  10.63   .01057 13.76 4.993   1 13.76 780.3       0          0 147.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1744         0                 6300 43.82 2485 56.74\n",
            "\n",
            "16:04:46 | time:115s total_exs:6350 total_steps:6350 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.88     1 37.88  2147       0          0 56.67   50  9.232   .01065 19.26 4.841   1 19.26  1092       0          0 126.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1963         0                 6350 57.14 3238 56.7\n",
            "\n",
            "16:04:47 | time:116s total_exs:6400 total_steps:6400 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.54     1 23.54  1335       0          0 56.72   50  10.74   .01055  14.6  4.76   1  14.6 828.2       0          0 116.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1959         0                 6400 38.14 2164 56.75\n",
            "\n",
            "16:04:48 | time:117s total_exs:6450 total_steps:6450 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.76     1 26.76  1536       0          0 57.39   50  10.99   .01058 13.88 4.911   1 13.88 796.6       0          0 135.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2075         0                 6450 40.64 2332 57.42\n",
            "\n",
            "16:04:49 | time:118s total_exs:6500 total_steps:6500 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.66     1 34.66  1956       0          0 56.42   50   9.51   .01067 17.66 4.988   1 17.66 996.5       0          0 146.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1937         0                 6500 52.32 2952 56.45\n",
            "\n",
            "16:04:50 | time:119s total_exs:6550 total_steps:6550 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.16     1 33.16  1900       0          0 57.29   50  10.96   .01065 14.96 4.714   1 14.96 857.1       0          0 111.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2045         0                 6550 48.12 2757 57.32\n",
            "\n",
            "16:04:51 | time:119s total_exs:6600 total_steps:6600 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.8     1  31.8  1811       0          0 56.93   50  9.238   .01068 18.26 4.877   1 18.26  1040       0          0 131.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1807         0                 6600 50.06 2850 56.97\n",
            "\n",
            "16:04:51 | time:120s total_exs:6650 total_steps:6650 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.66     1 29.66  1681       0          0 56.67   50  9.549   .01055 17.16 4.813   1 17.16 972.5       0          0 123.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2063         0                 6650 46.82 2653 56.7\n",
            "\n",
            "16:04:52 | time:121s total_exs:6700 total_steps:6700 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.8     1  34.8  1947       0          0 55.94   50  9.875   .01061 16.64 4.845   1 16.64 930.8       0          0 127.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1995         0                 6700 51.44 2878 55.97\n",
            "\n",
            "16:04:53 | time:122s total_exs:6750 total_steps:6750 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.62     1 34.62  1942       0          0 56.09   50  9.894   .01063 16.72 4.805   1 16.72 937.9       0          0 122.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2165         0                 6750 51.34 2880 56.12\n",
            "\n",
            "16:04:54 | time:123s total_exs:6800 total_steps:6800 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.76     1 37.76  2127       0          0 56.31   50  10.51    .0106 17.72 4.666   1 17.72 997.9       0          0 106.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2190         0                 6800 55.48 3125 56.34\n",
            "\n",
            "16:04:55 | time:124s total_exs:6850 total_steps:6850 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.2     1  26.2  1505       0          0 57.44   50   10.3   .01061 17.22 4.916   1 17.22 989.2       0          0 136.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2044         0                 6850 43.42 2494 57.47\n",
            "\n",
            "16:04:56 | time:125s total_exs:6900 total_steps:6900 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.56     1 30.56  1748       0          0 57.18   50  10.07    .0106  15.7  4.93   1  15.7 897.8       0          0 138.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1911         0                 6900 46.26 2645 57.21\n",
            "\n",
            "16:04:57 | time:126s total_exs:6950 total_steps:6950 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.72     1 31.72  1806       0          0 56.94   50  9.656   .01061 17.94 4.946   1 17.94  1022       0          0 140.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1817         0                 6950 49.66 2828 56.98\n",
            "\n",
            "16:04:58 | time:127s total_exs:7000 total_steps:7000 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.9     1  31.9  1836       0          0 57.54   50  10.53    .0106 17.24 4.813   1 17.24   992       0          0 123.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1763         0                 7000 49.14 2828 57.57\n",
            "\n",
            "16:04:59 | time:128s total_exs:7050 total_steps:7050 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.94     1 26.94  1534       0          0 56.92   50   10.8   .01066 14.76 5.097   1 14.76 840.2       0          0 163.5   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1612         0                 7050 41.7 2374 56.95\n",
            "\n",
            "16:04:59 | time:128s total_exs:7100 total_steps:7100 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.86     1 36.86  2073       0          0 56.22   50  10.01   .01066  17.5 4.752   1  17.5 983.9       0          0 115.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1989         0                 7100 54.36 3057 56.25\n",
            "\n",
            "16:05:00 | time:129s total_exs:7150 total_steps:7150 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.6     1  25.6  1444       0          0  56.4   50  10.18   .01054 14.74 4.724   1 14.74 831.4       0          0 112.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2144         0                 7150 40.34 2276 56.44\n",
            "\n",
            "16:05:01 | time:130s total_exs:7200 total_steps:7200 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.88     1 28.88  1620       0          0 56.09   50  11.04   .01055  12.7 4.435   1  12.7 712.4       0          0 84.39   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2520         0                 7200 41.58 2333 56.12\n",
            "\n",
            "16:05:02 | time:131s total_exs:7250 total_steps:7250 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.32     1 28.32  1633       0          0 57.64   50  11.19   .01056 12.56 4.517   1 12.56 724.1       0          0 91.56   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2197         0                 7250 40.88 2357 57.75\n",
            "\n",
            "16:05:03 | time:132s total_exs:7300 total_steps:7300 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   31.62     1 31.62  1804       0          0 57.06   50  9.446   .01059 18.76 4.913   1 18.76  1071       0          0  136   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1876         0                 7300 50.38 2875 57.09\n",
            "\n",
            "16:05:04 | time:133s total_exs:7350 total_steps:7350 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.66     1 29.66  1672       0          0 56.36   50  10.56   .01056 13.96 4.696   1 13.96 786.8       0          0 109.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1977         0                 7350 43.62 2459 56.39\n",
            "\n",
            "16:05:05 | time:134s total_exs:7400 total_steps:7400 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.38     1 27.38  1553       0          0 56.72   50  9.473   .01058 18.46 4.929   1 18.46  1047       0          0 138.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1766         0                 7400 45.84 2601 56.77\n",
            "\n",
            "16:05:06 | time:135s total_exs:7450 total_steps:7450 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   34.58     1 34.58  1927       0          0 55.71   50  9.162   .01059 17.94 4.745   1 17.94 999.5       0          0  115   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2096         0                 7450 52.52 2926 55.74\n",
            "\n",
            "16:05:07 | time:136s total_exs:7500 total_steps:7500 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   26.32     1 26.32  1493       0          0 56.73   50  11.01   .01054 15.44 4.556   1 15.44   876       0          0 95.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2280         0                 7500 41.76 2369 56.76\n",
            "\n",
            "16:05:08 | time:137s total_exs:7550 total_steps:7550 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.48     1 31.48  1749       0          0 55.55   50   10.6    .0106 14.26 4.311   1 14.26 792.2       0          0 74.48   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2581         0                 7550 45.74 2541 55.58\n",
            "\n",
            "16:05:08 | time:137s total_exs:7600 total_steps:7600 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.32     1 23.32  1330       0          0 57.03   50  11.22   .01053 13.48 4.998   1 13.48 768.8       0          0 148.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1855         0                 7600 36.8 2099 57.06\n",
            "\n",
            "16:05:09 | time:138s total_exs:7650 total_steps:7650 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.86     1 31.86  1795       0          0 56.34   50  9.872   .01061 16.02 4.656   1 16.02 902.6       0          0 105.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1973         0                 7650 47.88 2698 56.37\n",
            "\n",
            "16:05:10 | time:139s total_exs:7700 total_steps:7700 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   31.56     1 31.56  1811       0          0 57.37   50  9.106   .01061 17.66 4.718   1 17.66  1013       0          0  112   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2231         0                 7700 49.22 2824 57.4\n",
            "\n",
            "16:05:11 | time:140s total_exs:7750 total_steps:7750 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   24.06     1 24.06  1356       0          0 56.34   50  11.17   .01053 14.06 4.875   1 14.06 792.2       0          0  131   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1849         0                 7750 38.12 2148 56.37\n",
            "\n",
            "16:05:12 | time:141s total_exs:7800 total_steps:7800 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.34     1 26.34  1483       0          0  56.3   50  9.595   .01056  17.4 4.954   1  17.4 979.7       0          0 141.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2115         0                 7800 43.74 2463 56.33\n",
            "\n",
            "16:05:13 | time:142s total_exs:7850 total_steps:7850 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   26.18     1 26.18  1499       0          0 57.18   50  10.07   .01055 15.92 4.654   1 15.92 910.4       0          0  105   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .1985         0                 7850 42.1 2410 57.3\n",
            "\n",
            "16:05:14 | time:143s total_exs:7900 total_steps:7900 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.24     1 31.24  1773       0          0 56.74   50  10.33   .01064  16.2 4.619   1  16.2 919.3       0          0 101.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2222         0                 7900 47.44 2692 56.77\n",
            "\n",
            "16:05:15 | time:144s total_exs:7950 total_steps:7950 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.42     1 34.42  1928       0          0 56.02   50  9.306   .01068 20.36 4.823   1 20.36  1141       0          0 124.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2083         0                 7950 54.78 3069 56.05\n",
            "\n",
            "16:05:16 | time:145s total_exs:8000 total_steps:8000 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   22.28     1 22.28  1273       0          0 57.15   50  10.56   .01054  14.9 4.787   1  14.9 851.5       0          0  120   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1745         0                 8000 37.18 2125 57.18\n",
            "\n",
            "16:05:17 | time:145s total_exs:8050 total_steps:8050 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.44     1 30.44  1750       0          0 57.48   50  9.375    .0106 18.06  4.61   1 18.06  1038       0          0 100.4   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2159         0                 8050 48.5 2788 57.51\n",
            "\n",
            "16:05:17 | time:146s total_exs:8100 total_steps:8100 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.02     1 28.02  1587       0          0 56.64   50  10.33   .01054 16.12 4.893   1 16.12 913.1       0          0 133.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2072         0                 8100 44.14 2500 56.67\n",
            "\n",
            "16:05:18 | time:147s total_exs:8150 total_steps:8150 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.04     1 32.04  1798       0          0 56.11   50  9.749   .01066 18.66 4.725   1 18.66  1047       0          0 112.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2090         0                 8150 50.7 2845 56.15\n",
            "\n",
            "16:05:19 | time:148s total_exs:8200 total_steps:8200 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.14     1 28.14  1606       0          0 57.05   50   9.69    .0106 16.44 4.745   1 16.44   938       0          0  115   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2263         0                 8200 44.58 2544 57.08\n",
            "\n",
            "16:05:20 | time:149s total_exs:8250 total_steps:8250 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      27     1    27  1541       0          0 57.06   50  10.18   .01054 14.78 4.648   1 14.78 843.4       0          0 104.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2043         0                 8250 41.78 2384 57.09\n",
            "\n",
            "16:05:21 | time:150s total_exs:8300 total_steps:8300 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    27.7     1  27.7  1562       0          0  56.4   50  9.954   .01061 14.84 4.838   1 14.84   837       0          0 126.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2089         0                 8300 42.54 2399 56.43\n",
            "\n",
            "16:05:22 | time:151s total_exs:8350 total_steps:8350 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.16     1 28.16  1610       0          0 57.18   50  10.18   .01057 16.66 5.007   1 16.66 952.7       0          0 149.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1945         0                 8350 44.82 2563 57.21\n",
            "\n",
            "16:05:23 | time:152s total_exs:8400 total_steps:8400 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.06     1 28.06  1618       0          0 57.64   50  9.331   .01067 16.72   4.6   1 16.72 963.8       0          0 99.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2189         0                 8400 44.78 2581 57.67\n",
            "\n",
            "16:05:24 | time:153s total_exs:8450 total_steps:8450 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.32     1 26.32  1479       0          0 56.19   50  10.58   .01055 15.28 4.795   1 15.28 858.6       0          0 120.9   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2081         0                 8450 41.6 2338 56.22\n",
            "\n",
            "16:05:25 | time:153s total_exs:8500 total_steps:8500 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.66     1 29.66  1702       0          0 57.38   50  9.911    .0106 18.04 4.899   1 18.04  1035       0          0 134.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1907         0                 8500 47.7 2737 57.41\n",
            "\n",
            "16:05:25 | time:154s total_exs:8550 total_steps:8550 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.5     1  31.5  1798       0          0 57.08   50  9.491   .01057 17.88 4.434   1 17.88  1021       0          0 84.26   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2461         0                 8550 49.38 2819 57.11\n",
            "\n",
            "16:05:26 | time:155s total_exs:8600 total_steps:8600 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.98     1 25.98  1495       0          0 57.55   50   10.2   .01055 15.46  4.61   1 15.46 889.8       0          0 100.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2160         0                 8600 41.44 2385 57.58\n",
            "\n",
            "16:05:27 | time:156s total_exs:8650 total_steps:8650 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.88     1 36.88  2116       0          0 57.36   50  9.273   .01069 22.22 5.088   1 22.22  1275       0          0 162.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1683         0                 8650 59.1 3390 57.39\n",
            "\n",
            "16:05:28 | time:157s total_exs:8700 total_steps:8700 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.38     1 26.38  1508       0          0 57.16   50  9.509   .01054 16.36 4.919   1 16.36 935.3       0          0 136.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2042         0                 8700 42.74 2443 57.19\n",
            "\n",
            "16:05:29 | time:158s total_exs:8750 total_steps:8750 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.54     1 29.54  1709       0          0 57.84   50  10.19   .01066 15.76 4.738   1 15.76 911.7       0          0 114.2   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2132         0                 8750 45.3 2621 57.88\n",
            "\n",
            "16:05:30 | time:159s total_exs:8800 total_steps:8800 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    23.8     1  23.8  1361       0          0 57.17   50  9.603   .01053 14.42 4.448   1 14.42 824.5       0          0 85.46   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2122         0                 8800 38.22 2185 57.2\n",
            "\n",
            "16:05:31 | time:160s total_exs:8850 total_steps:8850 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.32     1 28.32  1620       0          0  57.2   50  10.38   .01059  15.8 4.672   1  15.8 903.8       0          0  107   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2038         0                 8850 44.12 2524 57.23\n",
            "\n",
            "16:05:32 | time:161s total_exs:8900 total_steps:8900 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.06     1 30.06  1706       0          0 56.74   50  9.889   .01064 15.08 4.939   1 15.08 855.7       0          0 139.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1989         0                 8900 45.14 2561 56.77\n",
            "\n",
            "16:05:33 | time:161s total_exs:8950 total_steps:8950 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.12     1 34.12  1928       0          0 56.49   50  9.498   .01063 19.06 4.782   1 19.06  1077       0          0 119.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1973         0                 8950 53.18 3005 56.52\n",
            "\n",
            "16:05:33 | time:162s total_exs:9000 total_steps:9000 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    35.1     1  35.1  1989       0          0 56.65   50  9.819   .01063 15.58 4.708   1 15.58 882.7       0          0 110.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2028         0                 9000 50.68 2871 56.68\n",
            "\n",
            "16:05:34 | time:163s total_exs:9050 total_steps:9050 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.8     1  25.8  1453       0          0 56.31   50  10.29   .01057 17.48 4.864   1 17.48 984.4       0          0 129.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2048         0                 9050 43.28 2437 56.34\n",
            "\n",
            "16:05:35 | time:164s total_exs:9100 total_steps:9100 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   33.48     1 33.48  1894       0          0 56.58   50  10.87    .0106  14.9 4.788   1  14.9 843.1       0          0  120   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1879         0                 9100 48.38 2738 56.61\n",
            "\n",
            "16:05:36 | time:165s total_exs:9150 total_steps:9150 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.04     1 26.04  1435       0          0 55.09   50  10.45    .0106  15.1 4.619   1  15.1 831.9       0          0 101.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2172         0                 9150 41.14 2267 55.12\n",
            "\n",
            "16:05:37 | time:166s total_exs:9200 total_steps:9200 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.72     1 29.72  1678       0          0 56.45   50  8.038   .01065 21.48 4.707   1 21.48  1213       0          0 110.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1937         0                 9200 51.2 2891 56.48\n",
            "\n",
            "16:05:38 | time:167s total_exs:9250 total_steps:9250 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.44     1 26.44  1494       0          0 56.51   50  9.363   .01055 16.22 4.861   1 16.22 916.7       0          0 129.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2022         0                 9250 42.66 2411 56.55\n",
            "\n",
            "16:05:39 | time:168s total_exs:9300 total_steps:9300 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.66     1 27.66  1566       0          0 56.59   50  9.141   .01061 17.54 4.543   1 17.54 992.7       0          0 93.97   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2166         0                 9300 45.2 2558 56.63\n",
            "\n",
            "16:05:40 | time:169s total_exs:9350 total_steps:9350 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.3     1  29.3  1658       0          0 56.57   50  9.857   .01055 14.58 4.606   1 14.58 824.9       0          0 100.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2071         0                 9350 43.88 2483 56.6\n",
            "\n",
            "16:05:41 | time:170s total_exs:9400 total_steps:9400 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.94     1 28.94  1644       0          0 56.79   50  10.18   .01056 17.06 4.764   1 17.06 968.9       0          0 117.2   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2169         0                 9400   46 2613 56.82\n",
            "\n",
            "16:05:42 | time:170s total_exs:9450 total_steps:9450 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.26     1 38.26  2159       0          0 56.43   50  9.372    .0106 15.22 4.476   1 15.22   859       0          0 87.85   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2300         0                 9450 53.48 3018 56.47\n",
            "\n",
            "16:05:42 | time:171s total_exs:9500 total_steps:9500 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.28     1 26.28  1498       0          0    57   50  10.12   .01062 13.38 4.638   1 13.38 762.7       0          0 103.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2182         0                 9500 39.66 2261 57.03\n",
            "\n",
            "16:05:43 | time:172s total_exs:9550 total_steps:9550 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.58     1 25.58  1456       0          0 56.92   50  10.53   .01054 13.94 4.582   1 13.94 793.5       0          0 97.67   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2382         0                 9550 39.52 2250 56.95\n",
            "\n",
            "16:05:44 | time:173s total_exs:9600 total_steps:9600 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.16     1 28.16  1619       0          0 57.47   50  9.606   .01056 15.08 4.575   1 15.08 866.7       0          0 97.03   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2387         0                 9600 43.24 2485 57.5\n",
            "\n",
            "16:05:45 | time:174s total_exs:9650 total_steps:9650 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.72     1 31.72  1808       0          0 56.98   50  9.745   .01061  14.8 4.617   1  14.8 843.4       0          0 101.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2311         0                 9650 46.52 2651 57.02\n",
            "\n",
            "16:05:46 | time:175s total_exs:9700 total_steps:9700 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.32     1 29.32  1701       0          0 58.02   50  9.507   .01064 19.92 4.668   1 19.92  1156       0          0 106.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2269         0                 9700 49.24 2857 58.05\n",
            "\n",
            "16:05:47 | time:176s total_exs:9750 total_steps:9750 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.48     1 32.48  1866       0          0 57.45   50  9.545   .01057 16.94 4.764   1 16.94 973.2       0          0 117.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2385         0                 9750 49.42 2839 57.48\n",
            "\n",
            "16:05:48 | time:177s total_exs:9800 total_steps:9800 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   31.42     1 31.42  1797       0          0 57.17   50  9.806   .01056 16.28 4.324   1 16.28 930.8       0          0 75.5   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2334         0                 9800 47.7 2727 57.21\n",
            "\n",
            "16:05:49 | time:178s total_exs:9850 total_steps:9850 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.38     1 27.38  1560       0          0 56.97   50   9.45   .01056 17.54 4.742   1 17.54 999.4       0          0 114.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2109         0                 9850 44.92 2559   57\n",
            "\n",
            "16:05:50 | time:178s total_exs:9900 total_steps:9900 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.48     1 29.48  1663       0          0 56.41   50  10.44   .01071 13.66 4.513   1 13.66 770.6       0          0 91.17   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2182         0                 9900 43.14 2434 56.45\n",
            "\n",
            "16:05:50 | time:179s total_exs:9950 total_steps:9950 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.66     1 23.66  1354       0          0 57.23   50  10.22   .01053 15.72 4.429   1 15.72 899.7       0          0 83.84   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2354         0                 9950 39.38 2254 57.26\n",
            "\n",
            "16:05:51 | time:180s total_exs:10000 total_steps:10000 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.08     1 30.08  1719       0          0 57.14   50  9.859   .01058 14.98 4.885   1 14.98 856.1       0          0 132.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2043         0                10000 45.06 2575 57.17\n",
            "\n",
            "16:05:52 | time:181s total_exs:10050 total_steps:10050 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.46     1 30.46  1740       0          0 57.11   50  9.559   .01064 16.78 4.687   1 16.78 958.4       0          0 108.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2050         0                10050 47.24 2698 57.14\n",
            "\n",
            "16:05:53 | time:182s total_exs:10100 total_steps:10100 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.32     1 27.32  1565       0          0 57.29   50  9.859   .01055 13.84 4.537   1 13.84 792.9       0          0 93.41   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2298         0                10100 41.16 2358 57.32\n",
            "\n",
            "16:05:54 | time:183s total_exs:10150 total_steps:10150 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.4     1  32.4  1861       0          0 57.45   50  9.685    .0106 16.92 4.622   1 16.92 972.1       0          0 101.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2246         0                10150 49.32 2834 57.48\n",
            "\n",
            "16:05:55 | time:184s total_exs:10200 total_steps:10200 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.84     1 27.84  1598       0          0  57.4   50  9.209   .01057 17.24 4.746   1 17.24 989.7       0          0 115.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2343         0                10200 45.08 2588 57.43\n",
            "\n",
            "16:05:56 | time:185s total_exs:10250 total_steps:10250 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.32     1 31.32  1774       0          0 56.62   50  9.204   .01067 17.88 4.677   1 17.88  1012       0          0 107.4   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2058         0                10250 49.2 2786 56.65\n",
            "\n",
            "16:05:57 | time:186s total_exs:10300 total_steps:10300 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.68     1 30.68  1739       0          0 56.67   50  9.682    .0106 17.48 4.783   1 17.48 990.7       0          0 119.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2220         0                10300 48.16 2730 56.7\n",
            "\n",
            "16:05:58 | time:186s total_exs:10350 total_steps:10350 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.02     1 33.02  1866       0          0  56.5   50  10.73   .01062  14.7 4.593   1  14.7 830.6       0          0 98.78   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2122         0                10350 47.72 2697 56.53\n",
            "\n",
            "16:05:58 | time:187s total_exs:10400 total_steps:10400 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.64     1 32.64  1852       0          0 56.74   50   10.5   .01064 14.78 4.509   1 14.78 838.6       0          0 90.87   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2287         0                10400 47.42 2691 56.77\n",
            "\n",
            "16:05:59 | time:188s total_exs:10450 total_steps:10450 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.96     1 28.96  1635       0          0 56.46   50  8.937    .0106  16.4 4.804   1  16.4   926       0          0  122   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2183         0                10450 45.36 2561 56.49\n",
            "\n",
            "16:06:00 | time:189s total_exs:10500 total_steps:10500 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.04     1 34.04  1955       0          0 57.44   50  10.28   .01076 16.04 4.488   1 16.04 921.3       0          0 88.94   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2469         0                10500 50.08 2877 57.47\n",
            "\n",
            "16:06:01 | time:190s total_exs:10550 total_steps:10550 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.6     1  26.6  1504       0          0 56.53   50  10.01   .01054 15.34  4.88   1 15.34 867.2       0          0 131.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1969         0                10550 41.94 2371 56.56\n",
            "\n",
            "16:06:02 | time:191s total_exs:10600 total_steps:10600 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.4     1  28.4  1573       0          0 55.38   50  9.856    .0106 16.68 4.641   1 16.68 923.9       0          0 103.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2362         0                10600 45.08 2497 55.41\n",
            "\n",
            "16:06:03 | time:192s total_exs:10650 total_steps:10650 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.26     1 31.26  1778       0          0 56.89   50    8.9   .01059 17.14 4.457   1 17.14 975.1       0          0 86.26   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2439         0                10650 48.4 2753 56.92\n",
            "\n",
            "16:06:04 | time:193s total_exs:10700 total_steps:10700 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.76     1 30.76  1744       0          0  56.7   50  10.36   .01062 16.48 4.661   1 16.48 934.5       0          0 105.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1930         0                10700 47.24 2679 56.73\n",
            "\n",
            "16:06:05 | time:194s total_exs:10750 total_steps:10750 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.04     1 30.04  1682       0          0 55.99   50  10.66   .01059 13.62 4.605   1 13.62 762.6       0          0 99.95   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2261         0                10750 43.66 2445 56.02\n",
            "\n",
            "16:06:06 | time:195s total_exs:10800 total_steps:10800 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.88     1 31.88  1804       0          0 56.58   50  9.445   .01063 16.54 4.863   1 16.54 935.9       0          0 129.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2177         0                10800 48.42 2740 56.61\n",
            "\n",
            "16:06:07 | time:195s total_exs:10850 total_steps:10850 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    30.8     1  30.8  1715       0          0 55.68   50  10.09   .01056 14.18 4.646   1 14.18 789.7       0          0 104.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2370         0                10850 44.98 2505 55.71\n",
            "\n",
            "16:06:07 | time:196s total_exs:10900 total_steps:10900 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.68     1 28.68  1621       0          0  56.5   50  10.51    .0106 15.34 5.027   1 15.34 866.8       0          0 152.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1669         0                10900 44.02 2487 56.53\n",
            "\n",
            "16:06:08 | time:197s total_exs:10950 total_steps:10950 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.82     1 33.82  1947       0          0 57.55   50  10.45   .01063 15.94 4.981   1 15.94 917.5       0          0 145.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1870         0                10950 49.76 2864 57.59\n",
            "\n",
            "16:06:09 | time:198s total_exs:11000 total_steps:11000 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   24.78     1 24.78  1421       0          0 57.33   50  9.867    .0106 15.44 4.567   1 15.44 885.3       0          0 96.21   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2098         0                11000 40.22 2306 57.36\n",
            "\n",
            "16:06:10 | time:199s total_exs:11050 total_steps:11050 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.62     1 29.62  1659       0          0    56   50  9.373   .01055  16.3 4.568   1  16.3 912.9       0          0 96.32   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2307         0                11050 45.92 2572 56.03\n",
            "\n",
            "16:06:11 | time:200s total_exs:11100 total_steps:11100 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.68     1 29.68  1644       0          0 55.39   50   10.3   .01056 13.56 4.549   1 13.56 751.1       0          0 94.52   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2493         0                11100 43.24 2395 55.42\n",
            "\n",
            "16:06:12 | time:201s total_exs:11150 total_steps:11150 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.54     1 29.54  1591       0          0 53.85   50  9.347   .01067 18.82 4.713   1 18.82  1014       0          0 111.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2189         0                11150 48.36 2605 53.88\n",
            "\n",
            "16:06:13 | time:202s total_exs:11200 total_steps:11200 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.22     1 32.22  1817       0          0  56.4   50  10.18   .01066  16.2 4.916   1  16.2 913.7       0          0 136.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1901         0                11200 48.42 2731 56.43\n",
            "\n",
            "16:06:14 | time:203s total_exs:11250 total_steps:11250 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.32     1 31.32  1771       0          0 56.54   50    9.7   .01065 17.34 4.598   1 17.34 980.5       0          0 99.28   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2203         0                11250 48.66 2752 56.58\n",
            "\n",
            "16:06:15 | time:204s total_exs:11300 total_steps:11300 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.76     1 27.76  1572       0          0 56.62   50  8.953   .01061 18.78 4.599   1 18.78  1063       0          0 99.42   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2023         0                11300 46.54 2635 56.65\n",
            "\n",
            "16:06:16 | time:205s total_exs:11350 total_steps:11350 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    30.6     1  30.6  1700       0          0 55.57   50   9.53   .01063 17.02 4.852   1 17.02 945.8       0          0  128   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2068         0                11350 47.62 2646 55.59\n",
            "\n",
            "16:06:16 | time:205s total_exs:11400 total_steps:11400 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.2     1  28.2  1601       0          0 56.76   50  9.663   .01059 15.08 4.468   1 15.08   856       0          0 87.16   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2056         0                11400 43.28 2457 56.79\n",
            "\n",
            "16:06:17 | time:206s total_exs:11450 total_steps:11450 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.72     1 30.72  1737       0          0 56.52   50  9.107   .01071 17.98 4.624   1 17.98  1016       0          0 101.9   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2102         0                11450 48.7 2753 56.55\n",
            "\n",
            "16:06:18 | time:207s total_exs:11500 total_steps:11500 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.9     1  28.9  1634       0          0 56.54   50  10.99    .0106  13.4 4.895   1  13.4 757.7       0          0 133.6   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2224         0                11500 42.3 2392 56.58\n",
            "\n",
            "16:06:19 | time:208s total_exs:11550 total_steps:11550 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.58     1 30.58  1749       0          0  57.2   50  9.848   .01059 16.36 4.246   1 16.36 935.9       0          0 69.85   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2531         0                11550 46.94 2685 57.25\n",
            "\n",
            "16:06:20 | time:209s total_exs:11600 total_steps:11600 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.92     1 30.92  1758       0          0 56.86   50  9.619   .01063 16.22 4.738   1 16.22 922.3       0          0 114.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2170         0                11600 47.14 2680 56.89\n",
            "\n",
            "16:06:21 | time:210s total_exs:11650 total_steps:11650 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.76     1 28.76  1580       0          0 54.92   50  11.35   .01056 12.34 4.286   1 12.34 677.8       0          0 72.65   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2350         0                11650 41.1 2258 54.95\n",
            "\n",
            "16:06:22 | time:211s total_exs:11700 total_steps:11700 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.68     1 25.68  1475       0          0 57.44   50  9.828   .01054 13.62  4.55   1 13.62 782.4       0          0 94.68   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2467         0                11700 39.3 2258 57.48\n",
            "\n",
            "16:06:23 | time:212s total_exs:11750 total_steps:11750 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   32.62     1 32.62  1854       0          0 56.81   50  9.255   .01066 17.82 4.568   1 17.82  1013       0          0 96.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2391         0                11750 50.44 2866 56.85\n",
            "\n",
            "16:06:24 | time:213s total_exs:11800 total_steps:11800 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.04     1 28.04  1593       0          0  56.8   50  8.733   .01058 18.76 4.754   1 18.76  1066       0          0  116   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1994         0                11800 46.8 2658 56.83\n",
            "\n",
            "16:06:25 | time:213s total_exs:11850 total_steps:11850 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.62     1 32.62  1857       0          0 56.93   50  9.343    .0106 18.36 4.734   1 18.36  1045       0          0 113.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2092         0                11850 50.98 2903 56.97\n",
            "\n",
            "16:06:25 | time:214s total_exs:11900 total_steps:11900 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.54     1 29.54  1667       0          0 56.41   50   10.6   .01064 16.02 4.568   1 16.02 903.8       0          0 96.35   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2147         0                11900 45.56 2570 56.45\n",
            "\n",
            "16:06:26 | time:215s total_exs:11950 total_steps:11950 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.2     1  33.2  1851       0          0 55.74   50  9.095   .01063 19.48 4.838   1 19.48  1086       0          0 126.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1992         0                11950 52.68 2937 55.77\n",
            "\n",
            "16:06:27 | time:216s total_exs:12000 total_steps:12000 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.6     1  32.6  1833       0          0 56.23   50  9.841    .0106 16.76  4.73   1 16.76 942.5       0          0 113.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2088         0                12000 49.36 2776 56.26\n",
            "\n",
            "16:06:28 | time:217s total_exs:12050 total_steps:12050 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.88     1 27.88  1579       0          0 56.63   50  9.383   .01056 16.08 4.614   1 16.08 910.7       0          0 100.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2239         0                12050 43.96 2490 56.66\n",
            "\n",
            "16:06:29 | time:218s total_exs:12100 total_steps:12100 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.46     1 28.46  1623       0          0 57.02   50  9.596   .01062 15.62  4.52   1 15.62 890.8       0          0 91.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2164         0                12100 44.08 2514 57.05\n",
            "\n",
            "16:06:30 | time:219s total_exs:12150 total_steps:12150 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.06     1 31.06  1775       0          0 57.15   50  9.958   .01064 15.04 4.168   1 15.04 859.6       0          0 64.57   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2500         0                12150 46.1 2635 57.18\n",
            "\n",
            "16:06:31 | time:220s total_exs:12200 total_steps:12200 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   40.98     1 40.98  2381       0          0 58.09   50  9.407   .01074 19.28 4.822   1 19.28  1120       0          0 124.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2002         0                12200 60.26 3501 58.12\n",
            "\n",
            "16:06:32 | time:221s total_exs:12250 total_steps:12250 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.44     1 30.44  1739       0          0 57.13   50  10.12    .0106 13.48 4.469   1 13.48 770.1       0          0 87.29   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2374         0                12250 43.92 2509 57.16\n",
            "\n",
            "16:06:33 | time:222s total_exs:12300 total_steps:12300 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.24     1 28.24  1614       0          0 57.16   50  9.964   .01056 16.14 4.458   1 16.14 922.7       0          0 86.28   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2429         0                12300 44.38 2537 57.19\n",
            "\n",
            "16:06:33 | time:222s total_exs:12350 total_steps:12350 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.92     1 29.92  1690       0          0 56.47   50  9.419    .0106 16.12 4.675   1 16.12 910.3       0          0 107.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1960         0                12350 46.04 2600 56.5\n",
            "\n",
            "16:06:34 | time:223s total_exs:12400 total_steps:12400 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.8     1  25.8  1444       0          0 55.95   50   10.3   .01056 15.08 4.681   1 15.08 843.8       0          0 107.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2241         0                12400 40.88 2287 55.98\n",
            "\n",
            "16:06:35 | time:224s total_exs:12450 total_steps:12450 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.62     1 30.62  1719       0          0 56.14   50  9.481   .01062 16.78 4.495   1 16.78   942       0          0 89.58   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2014         0                12450 47.4 2661 56.17\n",
            "\n",
            "16:06:36 | time:225s total_exs:12500 total_steps:12500 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.04     1 30.04  1681       0          0 55.97   50  8.745   .01061 19.38 4.769   1 19.38  1085       0          0 117.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .1961         0                12500 49.42 2766   56\n",
            "\n",
            "16:06:37 | time:226s total_exs:12550 total_steps:12550 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   35.34     1 35.34  1994       0          0 56.42   50  10.18   .01061 14.24  4.71   1 14.24 803.5       0          0  111   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2107         0                12550 49.58 2798 56.45\n",
            "\n",
            "16:06:38 | time:227s total_exs:12600 total_steps:12600 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.38     1 30.38  1734       0          0 57.06   50  10.25   .01058  15.5  4.39   1  15.5 884.5       0          0 80.61   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2555         0                12600 45.88 2618 57.1\n",
            "\n",
            "16:06:39 | time:228s total_exs:12650 total_steps:12650 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.88     1 28.88  1650       0          0 57.11   50  10.21   .01061  13.6 4.582   1  13.6 776.8       0          0 97.72   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2132         0                12650 42.48 2426 57.14\n",
            "\n",
            "16:06:40 | time:229s total_exs:12700 total_steps:12700 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.22     1 32.22  1817       0          0 56.39   50    9.5    .0106 16.52 4.558   1 16.52 931.7       0          0 95.37   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1973         0                12700 48.74 2749 56.42\n",
            "\n",
            "16:06:41 | time:230s total_exs:12750 total_steps:12750 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.12     1 33.12  1889       0          0 57.02   50  10.42   .01057  13.6 4.462   1  13.6 775.5       0          0 86.68   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2588         0                12750 46.72 2664 57.05\n",
            "\n",
            "16:06:42 | time:231s total_exs:12800 total_steps:12800 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.66     1 23.66  1303       0          0 55.09   50  10.14   .01052 13.14 4.415   1 13.14 723.9       0          0 82.68   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2527         0                12800 36.8 2027 55.12\n",
            "\n",
            "16:06:42 | time:231s total_exs:12850 total_steps:12850 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.84     1 32.84  1848       0          0 56.28   50   10.7    .0107 15.54 4.697   1 15.54 874.6       0          0 109.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1918         0                12850 48.38 2723 56.31\n",
            "\n",
            "16:06:43 | time:232s total_exs:12900 total_steps:12900 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.42     1 35.42  1957       0          0 55.26   50  8.623    .0106 16.44 4.747   1 16.44 908.5       0          0 115.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2214         0                12900 51.86 2866 55.29\n",
            "\n",
            "16:06:44 | time:233s total_exs:12950 total_steps:12950 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.34     1 29.34  1665       0          0 56.73   50  9.771   .01057  16.6 4.623   1  16.6 941.8       0          0 101.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2048         0                12950 45.94 2607 56.77\n",
            "\n",
            "16:06:45 | time:234s total_exs:13000 total_steps:13000 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   22.42     1 22.42  1263       0          0 56.34   50  9.417   .01056 15.74 4.976   1 15.74 886.8       0          0 144.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2173         0                13000 38.16 2150 56.37\n",
            "\n",
            "16:06:46 | time:235s total_exs:13050 total_steps:13050 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.06     1 28.06  1595       0          0 56.82   50  9.647   .01057 17.72 4.904   1 17.72  1007       0          0 134.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2190         0                13050 45.78 2602 56.85\n",
            "\n",
            "16:06:47 | time:236s total_exs:13100 total_steps:13100 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.72     1 25.72  1477       0          0 57.41   50  8.534   .01059 19.22 4.592   1 19.22  1103       0          0 98.69   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2477         0                13100 44.94 2580 57.44\n",
            "\n",
            "16:06:48 | time:237s total_exs:13150 total_steps:13150 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.54     1 30.54  1748       0          0 57.23   50  8.906   .01057 16.34 4.574   1 16.34 935.3       0          0 96.97   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2240         0                13150 46.88 2683 57.26\n",
            "\n",
            "16:06:49 | time:238s total_exs:13200 total_steps:13200 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.92     1 31.92  1801       0          0 56.41   50  9.506   .01059  16.9 4.496   1  16.9 953.3       0          0 89.68   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2095         0                13200 48.82 2754 56.44\n",
            "\n",
            "16:06:50 | time:239s total_exs:13250 total_steps:13250 epochs:0.20\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.36     1 30.36  1729       0          0 56.93   50  10.03   .01056 14.96 4.347   1 14.96 851.7       0          0 77.24   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2366         0                13250 45.32 2580 56.96\n",
            "\n",
            "16:06:51 | time:239s total_exs:13300 total_steps:13300 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.6     1  34.6  1928       0          0 55.72   50  9.363   .01063  16.7 5.048   1  16.7 930.5       0          0 155.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1844         0                13300 51.3 2859 55.75\n",
            "\n",
            "16:06:51 | time:240s total_exs:13350 total_steps:13350 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.7     1  26.7  1477       0          0  55.3   50  9.657   .01054 15.24 4.556   1 15.24 842.9       0          0 95.22   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2415         0                13350 41.94 2320 55.34\n",
            "\n",
            "16:06:52 | time:241s total_exs:13400 total_steps:13400 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.94     1 30.94  1751       0          0 56.59   50  9.211    .0106 15.72 4.471   1 15.72 889.7       0          0 87.46   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2443         0                13400 46.66 2641 56.63\n",
            "\n",
            "16:06:53 | time:242s total_exs:13450 total_steps:13450 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.16     1 33.16  1853       0          0 55.88   50  9.318   .01062 17.36  4.57   1 17.36 970.2       0          0 96.51   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2385         0                13450 50.52 2824 55.92\n",
            "\n",
            "16:06:54 | time:243s total_exs:13500 total_steps:13500 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    35.4     1  35.4  1987       0          0 56.11   50  9.263   .01067 16.02  4.45   1 16.02   899       0          0 85.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2647         0                13500 51.42 2886 56.14\n",
            "\n",
            "16:06:55 | time:244s total_exs:13550 total_steps:13550 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.44     1 33.44  1874       0          0 56.04   50  9.284   .01068 16.36 4.514   1 16.36 916.9       0          0 91.26   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2127         0                13550 49.8 2791 56.07\n",
            "\n",
            "16:06:56 | time:245s total_exs:13600 total_steps:13600 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.82     1 29.82  1690       0          0 56.66   50  10.26   .01061 14.52 4.614   1 14.52 822.7       0          0 100.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2245         0                13600 44.34 2512 56.69\n",
            "\n",
            "16:06:57 | time:246s total_exs:13650 total_steps:13650 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.56     1 28.56  1605       0          0  56.2   50  9.239   .01055 15.06 4.395   1 15.06 846.4       0          0 81.05   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2643         0                13650 43.62 2452 56.23\n",
            "\n",
            "16:06:58 | time:247s total_exs:13700 total_steps:13700 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   39.88     1 39.88  2255       0          0 56.53   50  8.695   .01066 17.66 4.408   1 17.66 998.4       0          0 82.11   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2616         0                13700 57.54 3253 56.57\n",
            "\n",
            "16:06:59 | time:248s total_exs:13750 total_steps:13750 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    27.2     1  27.2  1522       0          0 55.94   50  9.394   .01057  15.3 4.555   1  15.3 855.9       0          0 95.09   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2118         0                13750 42.5 2378 55.97\n",
            "\n",
            "16:07:00 | time:249s total_exs:13800 total_steps:13800 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.6     1  28.6  1534       0          0 53.64   50  9.753   .01066 16.04 4.388   1 16.04 860.4       0          0 80.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2431         0                13800 44.64 2395 53.67\n",
            "\n",
            "16:07:01 | time:250s total_exs:13850 total_steps:13850 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.58     1 31.58  1635       0          0 51.76   50  9.725   .01069 18.64  4.64   1 18.64 964.9       0          0 103.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2242         0                13850 50.22 2600 51.79\n",
            "\n",
            "16:07:02 | time:250s total_exs:13900 total_steps:13900 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.02     1 32.02  1744       0          0 54.46   50  10.03   .01062 16.02  4.64   1 16.02 872.5       0          0 103.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2122         0                13900 48.04 2616 54.49\n",
            "\n",
            "16:07:02 | time:251s total_exs:13950 total_steps:13950 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.4     1  29.4  1601       0          0 54.43   50  9.052   .01066 17.14 4.279   1 17.14 933.1       0          0 72.18   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2334         0                13950 46.54 2534 54.46\n",
            "\n",
            "16:07:03 | time:252s total_exs:14000 total_steps:14000 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.1     1  32.1  1853       0          0 57.73   50  8.275   .01064 20.34 4.491   1 20.34  1174       0          0 89.21   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2114         0                14000 52.44 3028 57.76\n",
            "\n",
            "16:07:04 | time:253s total_exs:14050 total_steps:14050 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.52     1 30.52  1719       0          0 56.31   50  8.234   .01058 19.52 4.626   1 19.52  1099       0          0 102.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2305         0                14050 50.04 2818 56.34\n",
            "\n",
            "16:07:05 | time:254s total_exs:14100 total_steps:14100 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.94     1 29.94  1691       0          0 56.49   50  9.817   .01056 14.46 4.359   1 14.46 816.8       0          0 78.21   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2420         0                14100 44.4 2508 56.51\n",
            "\n",
            "16:07:06 | time:255s total_exs:14150 total_steps:14150 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.92     1 27.92  1587       0          0 56.83   50  9.116    .0106 17.34 4.647   1 17.34 985.5       0          0 104.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2226         0                14150 45.26 2572 56.86\n",
            "\n",
            "16:07:07 | time:256s total_exs:14200 total_steps:14200 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.5     1  25.5  1443       0          0 56.59   50  10.38   .01055 15.12 4.511   1 15.12 855.7       0          0 90.99   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2249         0                14200 40.62 2299 56.62\n",
            "\n",
            "16:07:08 | time:257s total_exs:14250 total_steps:14250 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   29.64     1 29.64  1681       0          0  56.7   50  8.779   .01061 15.28 4.593   1 15.28 866.4       0          0 98.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2212         0                14250 44.92 2547 56.73\n",
            "\n",
            "16:07:09 | time:258s total_exs:14300 total_steps:14300 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.28     1 33.28  1892       0          0 56.84   50   9.15   .01063 18.54 4.643   1 18.54  1054       0          0 103.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2168         0                14300 51.82 2946 56.87\n",
            "\n",
            "16:07:10 | time:259s total_exs:14350 total_steps:14350 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.72     1 30.72  1740       0          0 56.64   50  9.791    .0106 15.72 4.829   1 15.72 890.4       0          0 125.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2087         0                14350 46.44 2631 56.67\n",
            "\n",
            "16:07:10 | time:259s total_exs:14400 total_steps:14400 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.6     1  31.6  1801       0          0 56.98   50  9.165   .01074 16.24 4.685   1 16.24 925.5       0          0 108.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2032         0                14400 47.84 2726 57.01\n",
            "\n",
            "16:07:11 | time:260s total_exs:14450 total_steps:14450 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.64     1 26.64  1511       0          0 56.71   50  9.365   .01058 15.72 4.587   1 15.72 891.5       0          0 98.24   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2354         0                14450 42.36 2402 56.74\n",
            "\n",
            "16:07:12 | time:261s total_exs:14500 total_steps:14500 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.94     1 34.94  1939       0          0 55.49   50  8.989   .01066  16.2 4.621   1  16.2   899       0          0 101.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2235         0                14500 51.14 2838 55.52\n",
            "\n",
            "16:07:13 | time:262s total_exs:14550 total_steps:14550 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.64     1 32.64  1862       0          0 57.04   50  9.376   .01061 17.22 4.899   1 17.22 982.3       0          0 134.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1951         0                14550 49.86 2844 57.07\n",
            "\n",
            "16:07:14 | time:263s total_exs:14600 total_steps:14600 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.9     1  33.9  1918       0          0 56.59   50  9.441   .01068 16.42 4.595   1 16.42 929.2       0          0 98.98   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2375         0                14600 50.32 2848 56.62\n",
            "\n",
            "16:07:15 | time:264s total_exs:14650 total_steps:14650 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.62     1 31.62  1802       0          0 56.99   50  9.523   .01061  16.2 4.466   1  16.2 923.4       0          0 87.04   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2346         0                14650 47.82 2726 57.02\n",
            "\n",
            "16:07:16 | time:265s total_exs:14700 total_steps:14700 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.28     1 28.28  1602       0          0 56.64   50  9.729   .01056 16.24 4.541   1 16.24   920       0          0 93.83   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2229         0                14700 44.52 2522 56.67\n",
            "\n",
            "16:07:17 | time:266s total_exs:14750 total_steps:14750 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   24.12     1 24.12  1355       0          0 56.16   50   9.38   .01056 16.54 4.332   1 16.54   929       0          0 76.12   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2370         0                14750 40.66 2284 56.19\n",
            "\n",
            "16:07:18 | time:267s total_exs:14800 total_steps:14800 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.88     1 27.88  1593       0          0 57.14   50  10.55    .0106  14.2 4.382   1  14.2 811.4       0          0 79.97   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2324         0                14800 42.08 2405 57.17\n",
            "\n",
            "16:07:19 | time:268s total_exs:14850 total_steps:14850 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.28     1 32.28  1849       0          0 57.29   50  9.271   .01059 15.72 4.589   1 15.72 900.6       0          0 98.36   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2150         0                14850   48 2750 57.32\n",
            "\n",
            "16:07:19 | time:268s total_exs:14900 total_steps:14900 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.54     1 28.54  1623       0          0 56.85   50  9.359   .01061 16.06 4.425   1 16.06 913.1       0          0 83.54   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2179         0                14900 44.6 2536 56.88\n",
            "\n",
            "16:07:20 | time:269s total_exs:14950 total_steps:14950 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.68     1 26.68  1512       0          0 56.68   50  9.676   .01059 16.66 4.524   1 16.66 944.4       0          0 92.22   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2233         0                14950 43.34 2457 56.76\n",
            "\n",
            "16:07:21 | time:270s total_exs:15000 total_steps:15000 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.56     1 32.56  1828       0          0 56.13   50  9.149   .01056 15.58 4.631   1 15.58 874.5       0          0 102.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2067         0                15000 48.14 2702 56.16\n",
            "\n",
            "16:07:22 | time:271s total_exs:15050 total_steps:15050 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.2     1  33.2  1875       0          0 56.48   50  9.002   .01068 17.24 4.556   1 17.24 973.7       0          0 95.23   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2169         0                15050 50.44 2849 56.51\n",
            "\n",
            "16:07:23 | time:272s total_exs:15100 total_steps:15100 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.14     1 32.14  1843       0          0 57.32   50  9.443   .01061 16.78 4.275   1 16.78 961.9       0          0 71.92   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2193         0                15100 48.92 2805 57.36\n",
            "\n",
            "16:07:24 | time:273s total_exs:15150 total_steps:15150 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.98     1 35.98  2041       0          0 56.71   50  8.883   .01064 18.78 4.618   1 18.78  1065       0          0 101.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2098         0                15150 54.76 3106 56.74\n",
            "\n",
            "16:07:25 | time:274s total_exs:15200 total_steps:15200 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.62     1 30.62  1719       0          0 56.13   50  8.933   .01062 17.28 4.384   1 17.28   970       0          0 80.17   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2269         0                15200 47.9 2689 56.16\n",
            "\n",
            "16:07:26 | time:275s total_exs:15250 total_steps:15250 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    26.8     1  26.8  1540       0          0 57.46   50  9.852   .01057 14.54 4.264   1 14.54 835.5       0          0 71.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2476         0                15250 41.34 2376 57.5\n",
            "\n",
            "16:07:27 | time:276s total_exs:15300 total_steps:15300 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.58     1 28.58  1629       0          0 56.98   50  8.701   .01055 18.16 4.579   1 18.16  1035       0          0 97.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2313         0                15300 46.74 2664 57.01\n",
            "\n",
            "16:07:27 | time:276s total_exs:15350 total_steps:15350 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.94     1 26.94  1542       0          0 57.24   50  10.91   .01057  14.7 4.389   1  14.7 841.6       0          0 80.57   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2381         0                15350 41.64 2384 57.28\n",
            "\n",
            "16:07:28 | time:277s total_exs:15400 total_steps:15400 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.44     1 32.44  1847       0          0 56.93   50  8.993   .01059 18.12  4.46   1 18.12  1032       0          0 86.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2318         0                15400 50.56 2879 56.96\n",
            "\n",
            "16:07:29 | time:278s total_exs:15450 total_steps:15450 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.14     1 30.14  1725       0          0 57.22   50  10.05   .01057 14.84 4.631   1 14.84 849.3       0          0 102.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1954         0                15450 44.98 2574 57.26\n",
            "\n",
            "16:07:30 | time:279s total_exs:15500 total_steps:15500 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    38.9     1  38.9  2243       0          0 57.66   50  8.946   .01062 18.08 4.398   1 18.08  1043       0          0 81.26   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2334         0                15500 56.98 3286 57.69\n",
            "\n",
            "16:07:31 | time:280s total_exs:15550 total_steps:15550 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.16     1 33.16  1898       0          0 57.22   50  9.848   .01067 16.34 4.616   1 16.34 935.1       0          0 101.1   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2191         0                15550 49.5 2833 57.26\n",
            "\n",
            "16:07:32 | time:281s total_exs:15600 total_steps:15600 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   29.16     1 29.16  1674       0          0  57.4   50    9.1   .01058 17.12 4.362   1 17.12 982.7       0          0 78.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2477         0                15600 46.28 2657 57.43\n",
            "\n",
            "16:07:33 | time:282s total_exs:15650 total_steps:15650 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.98     1 29.98  1729       0          0 57.67   50  9.838    .0106 15.96 4.224   1 15.96 920.4       0          0 68.32   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2381         0                15650 45.94 2649 57.7\n",
            "\n",
            "16:07:34 | time:283s total_exs:15700 total_steps:15700 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   29.44     1 29.44  1673       0          0 56.81   50  10.28   .01074  14.2 4.692   1  14.2 806.8       0          0  109   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2155         0                15700 43.64 2479 56.84\n",
            "\n",
            "16:07:35 | time:284s total_exs:15750 total_steps:15750 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.06     1 34.06  1926       0          0 56.54   50  8.888   .01072 17.28 4.177   1 17.28 977.1       0          0 65.14   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2650         0                15750 51.34 2903 56.57\n",
            "\n",
            "16:07:35 | time:284s total_exs:15800 total_steps:15800 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   34.56     1 34.56  1980       0          0 57.28   50  9.357   .01059 16.36 4.406   1 16.36 937.2       0          0 81.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2213         0                15800 50.92 2917 57.31\n",
            "\n",
            "16:07:36 | time:285s total_exs:15850 total_steps:15850 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.82     1 27.82  1582       0          0 56.85   50  9.537   .01054  16.2 4.458   1  16.2 921.1       0          0 86.34   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2284         0                15850 44.02 2503 56.89\n",
            "\n",
            "16:07:37 | time:286s total_exs:15900 total_steps:15900 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.62     1 27.62  1575       0          0 57.02   50  9.559   .01058 15.06 4.288   1 15.06 858.8       0          0 72.84   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2576         0                15900 42.68 2434 57.05\n",
            "\n",
            "16:07:38 | time:287s total_exs:15950 total_steps:15950 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.14     1 34.14  1940       0          0 56.83   50  9.619    .0107  17.1 4.322   1  17.1 971.8       0          0 75.32   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2620         0                15950 51.24 2912 56.86\n",
            "\n",
            "16:07:39 | time:288s total_exs:16000 total_steps:16000 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.96     1 23.96  1359       0          0 56.73   50  9.419   .01054 16.02   4.4   1 16.02 908.8       0          0 81.43   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2422         0                16000 39.98 2268 56.76\n",
            "\n",
            "16:07:40 | time:289s total_exs:16050 total_steps:16050 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.76     1 29.76  1715       0          0 57.64   50  10.02   .01059 13.86 4.353   1 13.86 798.9       0          0 77.72   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2511         0                16050 43.62 2514 57.67\n",
            "\n",
            "16:07:41 | time:290s total_exs:16100 total_steps:16100 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.58     1 32.58  1842       0          0 56.53   50  9.163   .01062 18.38 4.675   1 18.38  1039       0          0 107.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1948         0                16100 50.96 2881 56.56\n",
            "\n",
            "16:07:42 | time:291s total_exs:16150 total_steps:16150 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.92     1 31.92  1825       0          0 57.17   50  9.122   .01062 14.74 4.472   1 14.74 842.7       0          0 87.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2198         0                16150 46.66 2668 57.2\n",
            "\n",
            "16:07:43 | time:292s total_exs:16200 total_steps:16200 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.14     1 31.14  1787       0          0 57.38   50  10.18   .01064 14.62 4.536   1 14.62   839       0          0 93.27   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2189         0                16200 45.76 2626 57.42\n",
            "\n",
            "16:07:43 | time:292s total_exs:16250 total_steps:16250 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      34     1    34  1943       0          0 57.15   50  9.062    .0107 17.22 4.711   1 17.22 984.2       0          0 111.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2184         0                16250 51.22 2928 57.18\n",
            "\n",
            "16:07:44 | time:293s total_exs:16300 total_steps:16300 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    24.8     1  24.8  1426       0          0 57.51   50  8.992   .01057  17.9 4.524   1  17.9  1030       0          0 92.24   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2201         0                16300 42.7 2456 57.55\n",
            "\n",
            "16:07:45 | time:294s total_exs:16350 total_steps:16350 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.5     1  33.5  1934       0          0 57.74   50  10.23   .01057 13.98 4.355   1 13.98 807.2       0          0 77.84   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2203         0                16350 47.48 2742 57.77\n",
            "\n",
            "16:07:46 | time:295s total_exs:16400 total_steps:16400 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.28     1 28.28  1598       0          0 56.51   50  9.291   .01056 15.96 4.575   1 15.96 901.9       0          0 97.06   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2356         0                16400 44.24 2500 56.54\n",
            "\n",
            "16:07:47 | time:296s total_exs:16450 total_steps:16450 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   32.04     1 32.04  1834       0          0 57.24   50  11.03   .01061 14.38 4.366   1 14.38 823.2       0          0 78.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2197         0                16450 46.42 2658 57.28\n",
            "\n",
            "16:07:48 | time:297s total_exs:16500 total_steps:16500 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.04     1 28.04  1593       0          0 56.82   50  9.831   .01057 17.18 4.566   1 17.18 976.3       0          0 96.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2270         0                16500 45.22 2570 56.85\n",
            "\n",
            "16:07:49 | time:298s total_exs:16550 total_steps:16550 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.68     1 31.68  1812       0          0 57.21   50  9.308   .01057 15.06  4.14   1 15.06 861.6       0          0 62.78   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2523         0                16550 46.74 2674 57.24\n",
            "\n",
            "16:07:50 | time:299s total_exs:16600 total_steps:16600 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   30.78     1 30.78  1772       0          0 57.58   50  9.609   .01059 15.22 4.419   1 15.22 876.4       0          0   83   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2208         0                16600   46 2649 57.61\n",
            "\n",
            "16:07:51 | time:300s total_exs:16650 total_steps:16650 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.6     1  34.6  1989       0          0 57.49   50  9.046   .01066 17.38 4.475   1 17.38 999.2       0          0 87.81   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2117         0                16650 51.98 2989 57.52\n",
            "\n",
            "16:07:51 | time:300s total_exs:16700 total_steps:16700 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.32     1 26.32  1479       0          0 56.17   50  9.485   .01054 15.26 4.504   1 15.26 857.2       0          0 90.39   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2359         0                16700 41.58 2336 56.2\n",
            "\n",
            "16:07:52 | time:301s total_exs:16750 total_steps:16750 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.02     1 32.02  1816       0          0  56.7   50    9.2   .01062 16.38 4.199   1 16.38 928.9       0          0 66.61   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2479         0                16750 48.4 2745 56.73\n",
            "\n",
            "16:07:53 | time:302s total_exs:16800 total_steps:16800 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   44.92     1 44.92  2583       0          0  57.5   50  8.723   .01071 18.46 4.386   1 18.46  1062       0          0 80.36   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2384         0                16800 63.38 3645 57.53\n",
            "\n",
            "16:07:54 | time:303s total_exs:16850 total_steps:16850 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.2     1  31.2  1780       0          0 57.04   50  9.153   .01059 17.58 4.499   1 17.58  1003       0          0 89.93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2093         0                16850 48.78 2783 57.07\n",
            "\n",
            "16:07:55 | time:304s total_exs:16900 total_steps:16900 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.22     1 25.22  1441       0          0 57.12   50  9.252   .01055    16 4.564   1    16 913.9       0          0 95.93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2125         0                16900 41.22 2355 57.15\n",
            "\n",
            "16:07:56 | time:305s total_exs:16950 total_steps:16950 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.12     1 32.12  1805       0          0 56.21   50  8.969   .01057  16.8 4.371   1  16.8 944.3       0          0 79.12   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2488         0                16950 48.92 2750 56.24\n",
            "\n",
            "16:07:57 | time:306s total_exs:17000 total_steps:17000 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.88     1 32.88  1848       0          0  56.2   50  8.619   .01062 18.34 4.554   1 18.34  1031       0          0 94.97   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2039         0                17000 51.22 2879 56.24\n",
            "\n",
            "16:07:58 | time:307s total_exs:17050 total_steps:17050 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.86     1 30.86  1748       0          0 56.65   50  9.014    .0107 16.22 4.173   1 16.22 918.9       0          0 64.93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2614         0                17050 47.08 2667 56.68\n",
            "\n",
            "16:07:59 | time:308s total_exs:17100 total_steps:17100 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.06     1 30.06  1711       0          0 56.89   50  8.581   .01058 18.06 4.645   1 18.06  1028       0          0 104.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2016         0                17100 48.12 2739 57.02\n",
            "\n",
            "16:08:00 | time:308s total_exs:17150 total_steps:17150 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.58     1 36.58  2085       0          0 56.99   50  8.958    .0106 15.84 4.507   1 15.84 902.9       0          0 90.63   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2462         0                17150 52.42 2988 57.03\n",
            "\n",
            "16:08:00 | time:309s total_exs:17200 total_steps:17200 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.96     1 33.96  1936       0          0 56.99   50  9.415    .0106  16.7 4.584   1  16.7 951.8       0          0 97.89   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2275         0                17200 50.66 2887 57.03\n",
            "\n",
            "16:08:01 | time:310s total_exs:17250 total_steps:17250 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.78     1 31.78  1834       0          0 57.71   50    9.8    .0106 16.58 4.427   1 16.58 956.8       0          0 83.67   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2171         0                17250 48.36 2791 57.74\n",
            "\n",
            "16:08:02 | time:311s total_exs:17300 total_steps:17300 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    35.6     1  35.6  2023       0          0 56.82   50  9.829   .01075 16.66   4.7   1 16.66 946.7       0          0  110   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2065         0                17300 52.26 2970 56.85\n",
            "\n",
            "16:08:03 | time:312s total_exs:17350 total_steps:17350 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.72     1 28.72  1636       0          0 56.95   50  9.266   .01054 15.52 4.342   1 15.52 883.9       0          0 76.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2577         0                17350 44.24 2520 56.98\n",
            "\n",
            "16:08:04 | time:313s total_exs:17400 total_steps:17400 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.62     1 30.62  1745       0          0 56.99   50  9.365   .01064 15.16 4.434   1 15.16 864.1       0          0 84.26   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2230         0                17400 45.78 2609 57.03\n",
            "\n",
            "16:08:05 | time:314s total_exs:17450 total_steps:17450 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.8     1  29.8  1683       0          0 56.49   50  9.873   .01056 14.88 4.417   1 14.88 840.6       0          0 82.82   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2231         0                17450 44.68 2524 56.52\n",
            "\n",
            "16:08:06 | time:315s total_exs:17500 total_steps:17500 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    31.5     1  31.5  1802       0          0  57.2   50  9.234   .01061 15.94 4.533   1 15.94 911.9       0          0   93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2183         0                17500 47.44 2714 57.23\n",
            "\n",
            "16:08:07 | time:316s total_exs:17550 total_steps:17550 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.5     1  28.5  1577       0          0 55.31   50  8.482   .01058 16.98 4.679   1 16.98 939.4       0          0 107.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2049         0                17550 45.48 2516 55.37\n",
            "\n",
            "16:08:08 | time:317s total_exs:17600 total_steps:17600 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.88     1 26.88  1539       0          0 57.25   50  10.19   .01056  17.8 4.511   1  17.8  1019       0          0 91.02   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2258         0                17600 44.68 2558 57.29\n",
            "\n",
            "16:08:08 | time:317s total_exs:17650 total_steps:17650 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.14     1 27.14  1564       0          0 57.64   50  10.28   .01057 15.84 4.286   1 15.84 913.1       0          0 72.67   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2323         0                17650 42.98 2478 57.67\n",
            "\n",
            "16:08:09 | time:318s total_exs:17700 total_steps:17700 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.78     1 29.78  1700       0          0  57.1   50  9.984   .01057 16.32 4.741   1 16.32 931.8       0          0 114.6   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1973         0                17700 46.1 2632 57.12\n",
            "\n",
            "16:08:10 | time:319s total_exs:17750 total_steps:17750 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.06     1 31.06  1764       0          0 56.77   50  9.066   .01064 17.82 4.676   1 17.82  1012       0          0 107.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1987         0                17750 48.88 2775 56.81\n",
            "\n",
            "16:08:11 | time:320s total_exs:17800 total_steps:17800 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.94     1 26.94  1522       0          0 56.51   50  9.136   .01063 15.16 4.077   1 15.16 856.7       0          0 58.98   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2889     .0200                17800 42.1 2379 56.54\n",
            "\n",
            "16:08:12 | time:321s total_exs:17850 total_steps:17850 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.44     1 26.44  1493       0          0 56.45   50  9.798   .01058 16.16  4.14   1 16.16 912.3       0          0 62.83   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2748         0                17850 42.6 2405 56.48\n",
            "\n",
            "16:08:13 | time:322s total_exs:17900 total_steps:17900 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.02     1 34.02  1947       0          0 57.22   50  9.557   .01066 16.76 4.571   1 16.76 959.1       0          0 96.66   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2100         0                17900 50.78 2906 57.25\n",
            "\n",
            "16:08:14 | time:323s total_exs:17950 total_steps:17950 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.74     1 32.74  1836       0          0 56.08   50  10.34    .0106 13.32  4.25   1 13.32   747       0          0 70.09   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2492         0                17950 46.06 2583 56.11\n",
            "\n",
            "16:08:15 | time:324s total_exs:18000 total_steps:18000 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.08     1 31.08  1764       0          0 56.76   50   9.58   .01057 15.88 4.505   1 15.88 901.4       0          0 90.44   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2305         0                18000 46.96 2666 56.79\n",
            "\n",
            "16:08:16 | time:325s total_exs:18050 total_steps:18050 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.08     1 27.08  1550       0          0 57.23   50  9.597   .01054 15.28 4.319   1 15.28 874.6       0          0 75.11   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2644         0                18050 42.36 2425 57.26\n",
            "\n",
            "16:08:17 | time:326s total_exs:18100 total_steps:18100 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.68     1 34.68  1394       0          0 40.18   50  9.462   .01066 16.88 4.259   1 16.88 678.3       0          0 70.74   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2512         0                18100 51.56 2072 40.2\n",
            "\n",
            "16:08:18 | time:327s total_exs:18150 total_steps:18150 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.58     1 25.58  1183       0          0 46.24   50  10.19   .01054 14.48 4.336   1 14.48 669.6       0          0 76.38   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2624         0                18150 40.06 1853 46.26\n",
            "\n",
            "16:08:19 | time:328s total_exs:18200 total_steps:18200 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    30.1     1  30.1  1673       0          0 55.56   50     10   .01058 16.32 4.466   1 16.32 906.9       0          0 86.98   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2108         0                18200 46.42 2580 55.59\n",
            "\n",
            "16:08:20 | time:329s total_exs:18250 total_steps:18250 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.28     1 33.28  1907       0          0  57.3   50  9.135    .0106  17.4 4.482   1  17.4 997.1       0          0 88.44   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2241         0                18250 50.68 2904 57.33\n",
            "\n",
            "16:08:21 | time:330s total_exs:18300 total_steps:18300 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.16     1 28.16  1603       0          0 56.91   50  8.632   .01061 17.84 4.519   1 17.84  1015       0          0 91.71   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2220         0                18300   46 2618 56.94\n",
            "\n",
            "16:08:22 | time:331s total_exs:18350 total_steps:18350 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.56     1 26.56  1495       0          0 56.28   50  10.49    .0106 14.04 4.558   1 14.04 790.2       0          0 95.38   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2308         0                18350 40.6 2285 56.31\n",
            "\n",
            "16:08:22 | time:331s total_exs:18400 total_steps:18400 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.56     1 30.56  1732       0          0 56.67   50  9.315   .01064  15.5 4.494   1  15.5 878.5       0          0 89.45   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2361         0                18400 46.06 2611 56.71\n",
            "\n",
            "16:08:23 | time:332s total_exs:18450 total_steps:18450 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.86     1 26.86  1512       0          0 56.28   50  9.222   .01061  16.2 4.423   1  16.2 911.9       0          0 83.37   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2160         0                18450 43.06 2424 56.32\n",
            "\n",
            "16:08:24 | time:333s total_exs:18500 total_steps:18500 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.42     1 32.42  1838       0          0 56.67   50  9.235   .01065 15.34  4.28   1 15.34 869.4       0          0 72.25   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2542         0                18500 47.76 2707 56.7\n",
            "\n",
            "16:08:25 | time:334s total_exs:18550 total_steps:18550 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    30.8     1  30.8  1749       0          0 56.77   50  10.55   .01058  13.1 4.199   1  13.1 743.8       0          0 66.65   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2458         0                18550 43.9 2493 56.8\n",
            "\n",
            "16:08:26 | time:335s total_exs:18600 total_steps:18600 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.14     1 31.14  1759       0          0 56.48   50  9.679   .01056 15.06 4.286   1 15.06 850.6       0          0 72.66   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2470         0                18600 46.2 2610 56.51\n",
            "\n",
            "16:08:27 | time:336s total_exs:18650 total_steps:18650 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.96     1 28.96  1646       0          0 56.82   50  10.41   .01055 13.32 4.483   1 13.32 756.9       0          0 88.52   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2222         0                18650 42.28 2403 56.85\n",
            "\n",
            "16:08:28 | time:337s total_exs:18700 total_steps:18700 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.28     1 32.28  1847       0          0 57.22   50  10.71   .01056 13.02 4.399   1 13.02 745.1       0          0 81.41   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2243         0                18700 45.3 2593 57.26\n",
            "\n",
            "16:08:29 | time:338s total_exs:18750 total_steps:18750 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.8     1  29.8  1686       0          0 56.58   50  9.287   .01075 15.44 4.693   1 15.44 873.7       0          0 109.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2448         0                18750 45.24 2560 56.61\n",
            "\n",
            "16:08:30 | time:339s total_exs:18800 total_steps:18800 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.66     1 27.66  1576       0          0 56.99   50  8.867   .01058 16.32 4.546   1 16.32 930.1       0          0 94.27   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2230         0                18800 43.98 2507 57.02\n",
            "\n",
            "16:08:30 | time:339s total_exs:18850 total_steps:18850 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.38     1 29.38  1699       0          0 57.82   50  9.053   .01068 20.86 4.281   1 20.86  1206       0          0 72.35   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2234         0                18850 50.24 2905 57.85\n",
            "\n",
            "16:08:31 | time:340s total_exs:18900 total_steps:18900 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    26.3     1  26.3  1475       0          0 56.06   50  9.414   .01058  16.4  4.77   1  16.4 919.5       0          0  118   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1841         0                18900 42.7 2394 56.09\n",
            "\n",
            "16:08:32 | time:341s total_exs:18950 total_steps:18950 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    35.3     1  35.3  2018       0          0 57.15   50  8.408   .01059 21.58 4.554   1 21.58  1233       0          0 95.01   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2187         0                18950 56.88 3251 57.19\n",
            "\n",
            "16:08:33 | time:342s total_exs:19000 total_steps:19000 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.58     1 28.58  1609       0          0 56.29   50  9.355   .01058 16.52 4.406   1 16.52   930       0          0 81.97   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2446         0                19000 45.1 2539 56.32\n",
            "\n",
            "16:08:34 | time:343s total_exs:19050 total_steps:19050 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.38     1 28.38  1619       0          0 57.05   50  9.783   .01058  14.9 4.761   1  14.9 850.1       0          0 116.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2228         0                19050 43.28 2469 57.08\n",
            "\n",
            "16:08:35 | time:344s total_exs:19100 total_steps:19100 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.02     1 28.02  1622       0          0 57.88   50  8.627   .01058 16.84 4.606   1 16.84 974.7       0          0 100.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2019         0                19100 44.86 2597 57.91\n",
            "\n",
            "16:08:36 | time:345s total_exs:19150 total_steps:19150 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.58     1 31.58  1817       0          0 57.53   50   9.12   .01059 16.92 4.328   1 16.92 973.5       0          0 75.81   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2151         0                19150 48.5 2791 57.56\n",
            "\n",
            "16:08:37 | time:346s total_exs:19200 total_steps:19200 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.34     1 29.34  1652       0          0 56.29   50  9.233   .01057 16.24 4.336   1 16.24 914.1       0          0 76.44   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2131         0                19200 45.58 2566 56.32\n",
            "\n",
            "16:08:38 | time:347s total_exs:19250 total_steps:19250 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.72     1 34.72  1970       0          0 56.73   50  9.296   .01061 16.34 4.429   1 16.34 926.9       0          0 83.88   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2497         0                19250 51.06 2897 56.76\n",
            "\n",
            "16:08:38 | time:347s total_exs:19300 total_steps:19300 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.66     1 37.66  2148       0          0 57.04   50  10.18   .01066 14.18  4.49   1 14.18 808.8       0          0 89.13   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2370         0                19300 51.84 2957 57.07\n",
            "\n",
            "16:08:39 | time:348s total_exs:19350 total_steps:19350 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   31.34     1 31.34  1781       0          0 56.81   50  10.45   .01063 14.24 4.251   1 14.24 809.1       0          0 70.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2514         0                19350 45.58 2590 56.85\n",
            "\n",
            "16:08:40 | time:349s total_exs:19400 total_steps:19400 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.2     1  28.2  1584       0          0 56.17   50  9.622   .01067  16.2 4.628   1  16.2   910       0          0 102.3   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2198         0                19400 44.4 2494 56.2\n",
            "\n",
            "16:08:41 | time:350s total_exs:19450 total_steps:19450 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.94     1 29.94  1700       0          0 56.79   50  9.356   .01057 17.78 4.764   1 17.78  1010       0          0 117.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2227         0                19450 47.72 2710 56.82\n",
            "\n",
            "16:08:42 | time:351s total_exs:19500 total_steps:19500 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.26     1 37.26  2127       0          0 57.07   50  9.787   .01067 13.96 4.441   1 13.96 796.7       0          0 84.86   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2364         0                19500 51.22 2923 57.1\n",
            "\n",
            "16:08:43 | time:352s total_exs:19550 total_steps:19550 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.48     1 36.48  2061       0          0 56.48   50  9.723   .01068  16.3 4.464   1  16.3 920.7       0          0 86.82   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2466         0                19550 52.78 2982 56.51\n",
            "\n",
            "16:08:44 | time:353s total_exs:19600 total_steps:19600 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.76     1 32.76  1851       0          0  56.5   50  9.571   .01066  15.9 3.977   1  15.9 898.4       0          0 53.38   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2616         0                19600 48.66 2750 56.53\n",
            "\n",
            "16:08:45 | time:354s total_exs:19650 total_steps:19650 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.92     1 28.92  1663       0          0 57.51   50  9.466   .01056  16.5 4.486   1  16.5   949       0          0 88.77   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2073         0                19650 45.42 2612 57.54\n",
            "\n",
            "16:08:46 | time:355s total_exs:19700 total_steps:19700 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.68     1 32.68  1878       0          0 57.47   50  9.402   .01057  15.8 4.487   1  15.8 908.1       0          0 88.88   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2316         0                19700 48.48 2787 57.5\n",
            "\n",
            "16:08:47 | time:356s total_exs:19750 total_steps:19750 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.04     1 33.04  1862       0          0 56.35   50   9.13    .0106 17.92 4.715   1 17.92  1010       0          0 111.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2277         0                19750 50.96 2872 56.38\n",
            "\n",
            "16:08:47 | time:356s total_exs:19800 total_steps:19800 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.42     1 33.42  1901       0          0 56.88   50  9.494   .01057 15.04 4.453   1 15.04 855.6       0          0 85.86   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2460         0                19800 48.46 2757 56.91\n",
            "\n",
            "16:08:48 | time:357s total_exs:19850 total_steps:19850 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.86     1 26.86  1506       0          0 56.07   50  9.017   .01056 17.54 4.429   1 17.54 983.5       0          0 83.88   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2360         0                19850 44.4 2490 56.1\n",
            "\n",
            "16:08:49 | time:358s total_exs:19900 total_steps:19900 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.12     1 26.12  1493       0          0 57.14   50  9.527   .01055 15.34 4.429   1 15.34   877       0          0 83.81   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2438         0                19900 41.46 2370 57.2\n",
            "\n",
            "16:08:50 | time:359s total_exs:19950 total_steps:19950 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.4     1  31.4  1784       0          0 56.81   50  8.497    .0106 16.74 4.461   1 16.74   951       0          0 86.53   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2270         0                19950 48.14 2735 56.84\n",
            "\n",
            "16:08:51 | time:360s total_exs:20000 total_steps:20000 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.14     1 32.14  1838       0          0 57.18   50  8.442   .01063  17.9 4.465   1  17.9  1024       0          0 86.88   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2145         0                20000 50.04 2862 57.21\n",
            "\n",
            "16:08:52 | time:361s total_exs:20050 total_steps:20050 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.5     1  29.5  1679       0          0 56.91   50  9.556   .01058 13.12 4.356   1 13.12 746.8       0          0 77.94   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2500         0                20050 42.62 2426 56.95\n",
            "\n",
            "16:08:53 | time:362s total_exs:20100 total_steps:20100 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.98     1 29.98  1708       0          0 56.98   50  9.212    .0106 15.26 4.325   1 15.26 869.6       0          0 75.54   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2359         0                20100 45.24 2578 57.01\n",
            "\n",
            "16:08:54 | time:363s total_exs:20150 total_steps:20150 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.1     1  31.1  1749       0          0 56.22   50  10.25   .01065  15.1 4.433   1  15.1 848.9       0          0 84.19   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2278         0                20150 46.2 2597 56.25\n",
            "\n",
            "16:08:55 | time:364s total_exs:20200 total_steps:20200 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.94     1 29.94  1692       0          0 56.52   50   9.08   .01064  17.6  4.47   1  17.6 994.8       0          0 87.33   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2466         0                20200 47.54 2687 56.55\n",
            "\n",
            "16:08:55 | time:364s total_exs:20250 total_steps:20250 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.54     1 31.54  1797       0          0 56.98   50  9.037   .01059 18.98 4.418   1 18.98  1081       0          0 82.97   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2202         0                20250 50.52 2879 57.01\n",
            "\n",
            "16:08:56 | time:365s total_exs:20300 total_steps:20300 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.76     1 29.76  1714       0          0 57.58   50  9.128   .01061 18.14 4.527   1 18.14  1045       0          0 92.49   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2073         0                20300 47.9 2758 57.61\n",
            "\n",
            "16:08:57 | time:366s total_exs:20350 total_steps:20350 epochs:0.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.88     1 27.88  1597       0          0 57.29   50  9.215   .01055 15.82 4.401   1 15.82 906.4       0          0 81.57   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2212         0                20350 43.7 2504 57.32\n",
            "\n",
            "16:08:58 | time:367s total_exs:20400 total_steps:20400 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.48     1 35.48  2005       0          0 56.51   50  7.959   .01076 20.16 4.414   1 20.16  1139       0          0 82.63   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2331         0                20400 55.64 3144 56.54\n",
            "\n",
            "16:08:59 | time:368s total_exs:20450 total_steps:20450 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.54     1 33.54  1905       0          0 56.79   50  9.359   .01071 15.88 4.414   1 15.88 901.8       0          0 82.56   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2355         0                20450 49.42 2807 56.82\n",
            "\n",
            "16:09:00 | time:369s total_exs:20500 total_steps:20500 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.96     1 32.96  1855       0          0 56.28   50  9.005   .01075 16.32   4.2   1 16.32 918.6       0          0 66.69   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2659         0                20500 49.28 2774 56.31\n",
            "\n",
            "16:09:01 | time:370s total_exs:20550 total_steps:20550 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.58     1 32.58  1883       0          0  57.8   50  9.344    .0106 16.64 4.345   1 16.64 961.9       0          0 77.09   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2200         0                20550 49.22 2845 57.84\n",
            "\n",
            "16:09:02 | time:371s total_exs:20600 total_steps:20600 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    39.5     1  39.5  2260       0          0 57.21   50  8.886   .01069 20.16 4.678   1 20.16  1153       0          0 107.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2163         0                20600 59.66 3414 57.24\n",
            "\n",
            "16:09:03 | time:372s total_exs:20650 total_steps:20650 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   26.64     1 26.64  1519       0          0 57.02   50  9.773   .01057 14.42 4.548   1 14.42 822.3       0          0 94.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2261         0                20650 41.06 2342 57.06\n",
            "\n",
            "16:09:03 | time:372s total_exs:20700 total_steps:20700 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.84     1 28.84  1666       0          0 57.77   50  9.465   .01059 16.14 4.281   1 16.14 932.5       0          0 72.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2255         0                20700 44.98 2599 57.8\n",
            "\n",
            "16:09:04 | time:373s total_exs:20750 total_steps:20750 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.62     1 25.62  1454       0          0 56.75   50  10.31   .01056 15.52 4.457   1 15.52 880.7       0          0 86.23   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2152         0                20750 41.14 2335 56.78\n",
            "\n",
            "16:09:05 | time:374s total_exs:20800 total_steps:20800 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.08     1 25.08  1416       0          0 56.45   50  9.481   .01055 15.08 4.149   1 15.08 851.3       0          0 63.39   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2626         0                20800 40.16 2267 56.48\n",
            "\n",
            "16:09:06 | time:375s total_exs:20850 total_steps:20850 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.96     1 29.96  1697       0          0 56.63   50  9.316   .01055 15.94 4.203   1 15.94 902.7       0          0 66.85   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2622         0                20850 45.9 2600 56.66\n",
            "\n",
            "16:09:07 | time:376s total_exs:20900 total_steps:20900 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.7     1  29.7  1700       0          0 57.24   50  9.483   .01061 17.42 4.425   1 17.42 997.1       0          0 83.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2124         0                20900 47.12 2697 57.27\n",
            "\n",
            "16:09:08 | time:377s total_exs:20950 total_steps:20950 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.74     1 31.74  1815       0          0 57.19   50  9.154   .01064 19.28  4.41   1 19.28  1103       0          0 82.23   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2313         0                20950 51.02 2918 57.22\n",
            "\n",
            "16:09:09 | time:378s total_exs:21000 total_steps:21000 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.96     1 31.96  1836       0          0 57.43   50  9.326   .01059 17.46 4.274   1 17.46  1003       0          0 71.82   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2405         0                21000 49.42 2839 57.46\n",
            "\n",
            "16:09:10 | time:379s total_exs:21050 total_steps:21050 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.04     1 36.04  2073       0          0 57.51   50   9.74   .01066  15.4 4.051   1  15.4 885.7       0          0 57.46   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2494         0                21050 51.44 2958 57.54\n",
            "\n",
            "16:09:11 | time:380s total_exs:21100 total_steps:21100 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   27.04     1 27.04  1570       0          0 58.06   50  8.732   .01057 18.64 4.545   1 18.64  1082       0          0 94.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2232         0                21100 45.68 2653 58.1\n",
            "\n",
            "16:09:11 | time:380s total_exs:21150 total_steps:21150 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.38     1 27.38  1562       0          0 57.05   50  9.665   .01062 14.16 4.425   1 14.16 807.9       0          0 83.54   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2373         0                21150 41.54 2370 57.08\n",
            "\n",
            "16:09:12 | time:381s total_exs:21200 total_steps:21200 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.7     1  29.7  1670       0          0 56.21   50  9.772   .01064 18.38 4.494   1 18.38  1033       0          0 89.44   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2122         0                21200 48.08 2703 56.24\n",
            "\n",
            "16:09:13 | time:382s total_exs:21250 total_steps:21250 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.44     1 31.44  1781       0          0 56.65   50  8.179   .01059 20.98 4.597   1 20.98  1189       0          0 99.18   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2021         0                21250 52.42 2970 56.68\n",
            "\n",
            "16:09:14 | time:383s total_exs:21300 total_steps:21300 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.22     1 30.22  1734       0          0 57.37   50  8.351   .01057 18.38 4.397   1 18.38  1055       0          0 81.24   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2644         0                21300 48.6 2789 57.4\n",
            "\n",
            "16:09:15 | time:384s total_exs:21350 total_steps:21350 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.98     1 27.98  1612       0          0 57.59   50  9.435   .01054  14.3 4.215   1  14.3 823.6       0          0 67.67   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2434         0                21350 42.28 2435 57.62\n",
            "\n",
            "16:09:16 | time:385s total_exs:21400 total_steps:21400 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.08     1 25.08  1421       0          0 56.64   50  10.39   .01056  14.8 4.425   1  14.8 838.4       0          0 83.51   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2189         0                21400 39.88 2259 56.68\n",
            "\n",
            "16:09:17 | time:386s total_exs:21450 total_steps:21450 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.18     1 29.18  1679       0          0 57.53   50  9.662   .01058 14.22 4.259   1 14.22 818.1       0          0 70.71   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2630         0                21450 43.4 2497 57.56\n",
            "\n",
            "16:09:18 | time:387s total_exs:21500 total_steps:21500 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   29.94     1 29.94  1739       0          0 58.09   50  9.605   .01057 13.94 4.354   1 13.94 809.8       0          0 77.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2597         0                21500 43.88 2549 58.12\n",
            "\n",
            "16:09:19 | time:388s total_exs:21550 total_steps:21550 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.7     1  28.7  1647       0          0 57.39   50  10.44   .01065 16.66 4.518   1 16.66 956.2       0          0 91.66   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2161         0                21550 45.36 2604 57.43\n",
            "\n",
            "16:09:19 | time:388s total_exs:21600 total_steps:21600 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.04     1 25.04  1429       0          0 57.06   50  9.475   .01061 13.36  4.09   1 13.36 762.4       0          0 59.77   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2620         0                21600 38.4 2191 57.09\n",
            "\n",
            "16:09:20 | time:389s total_exs:21650 total_steps:21650 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.98     1 25.98  1460       0          0 56.18   50  9.435   .01054  15.2 4.087   1  15.2 853.9       0          0 59.55   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2447         0                21650 41.18 2314 56.21\n",
            "\n",
            "16:09:21 | time:390s total_exs:21700 total_steps:21700 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.46     1 29.46  1661       0          0 56.37   50  9.164    .0106 16.46 4.594   1 16.46 927.9       0          0 98.89   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2163         0                21700 45.92 2589 56.4\n",
            "\n",
            "16:09:22 | time:391s total_exs:21750 total_steps:21750 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.78     1 26.78  1530       0          0 57.14   50  9.301   .01053 15.76 4.281   1 15.76 900.6       0          0 72.33   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2614         0                21750 42.54 2431 57.17\n",
            "\n",
            "16:09:23 | time:392s total_exs:21800 total_steps:21800 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.88     1 32.88  1885       0          0 57.32   50  9.769   .01061 14.84 4.454   1 14.84 850.8       0          0 85.95   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2237         0                21800 47.72 2736 57.36\n",
            "\n",
            "16:09:24 | time:393s total_exs:21850 total_steps:21850 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.68     1 32.68  1873       0          0 57.32   50  10.66   .01057  13.8 4.184   1  13.8   791       0          0 65.62   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2551         0                21850 46.48 2664 57.36\n",
            "\n",
            "16:09:25 | time:394s total_exs:21900 total_steps:21900 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.9     1  29.9  1734       0          0    58   50  9.585    .0106 15.82 4.568   1 15.82 917.7       0          0 96.36   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2187         0                21900 45.72 2652 58.04\n",
            "\n",
            "16:09:26 | time:395s total_exs:21950 total_steps:21950 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.38     1 31.38  1818       0          0 57.92   50  8.605   .01066 16.66 4.479   1 16.66   965       0          0 88.11   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2449         0                21950 48.04 2783 57.95\n",
            "\n",
            "16:09:27 | time:396s total_exs:22000 total_steps:22000 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.8     1  25.8  1477       0          0 57.26   50   9.01   .01056  15.7 4.521   1  15.7   899       0          0 91.97   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2127         0                22000 41.5 2376 57.29\n",
            "\n",
            "16:09:27 | time:396s total_exs:22050 total_steps:22050 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.64     1 23.64  1352       0          0 57.19   50  9.539   .01055 15.56 4.435   1 15.56 889.9       0          0 84.37   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2224         0                22050 39.2 2242 57.22\n",
            "\n",
            "16:09:28 | time:397s total_exs:22100 total_steps:22100 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.06     1 34.06  1948       0          0  57.2   50  9.396   .01084 16.66 4.333   1 16.66   953       0          0 76.19   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2485         0                22100 50.72 2901 57.23\n",
            "\n",
            "16:09:29 | time:398s total_exs:22150 total_steps:22150 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.2     1  31.2  1795       0          0 57.52   50  8.913   .01057 16.64 4.229   1 16.64 957.1       0          0 68.65   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2572         0                22150 47.84 2752 57.55\n",
            "\n",
            "16:09:30 | time:399s total_exs:22200 total_steps:22200 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.64     1 33.64  1944       0          0 57.78   50  9.314   .01062 16.34 4.641   1 16.34 944.3       0          0 103.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2399         0                22200 49.98 2888 57.82\n",
            "\n",
            "16:09:31 | time:400s total_exs:22250 total_steps:22250 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.26     1 28.26  1635       0          0 57.87   50  9.438   .01062 16.94 4.449   1 16.94 980.3       0          0 85.52   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2326         0                22250 45.2 2616 57.9\n",
            "\n",
            "16:09:32 | time:401s total_exs:22300 total_steps:22300 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.16     1 27.16  1538       0          0 56.62   50  9.387   .01059 14.22 4.329   1 14.22 805.1       0          0 75.88   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2475         0                22300 41.38 2343 56.65\n",
            "\n",
            "16:09:33 | time:402s total_exs:22350 total_steps:22350 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   34.14     1 34.14  1989       0          0 58.24   50   8.54   .01065 16.76 4.566   1 16.76 976.2       0          0 96.2   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2196         0                22350 50.9 2965 58.27\n",
            "\n",
            "16:09:34 | time:403s total_exs:22400 total_steps:22400 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   32.14     1 32.14  1865       0          0 58.02   50  8.352   .01083 17.28 4.461   1 17.28  1003       0          0 86.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2222         0                22400 49.42 2868 58.05\n",
            "\n",
            "16:09:34 | time:403s total_exs:22450 total_steps:22450 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.42     1 30.42  1725       0          0 56.68   50  8.067   .01063 17.92 4.364   1 17.92  1016       0          0 78.57   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2333         0                22450 48.34 2741 56.73\n",
            "\n",
            "16:09:35 | time:404s total_exs:22500 total_steps:22500 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.68     1 32.68  1868       0          0 57.16   50  8.779   .01073 16.82 4.247   1 16.82 961.5       0          0 69.91   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2342         0                22500 49.5 2830 57.19\n",
            "\n",
            "16:09:36 | time:405s total_exs:22550 total_steps:22550 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.5     1  33.5  1877       0          0 56.03   50  9.998   .01057 14.94 4.482   1 14.94 837.2       0          0 88.43   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2329         0                22550 48.44 2715 56.07\n",
            "\n",
            "16:09:37 | time:406s total_exs:22600 total_steps:22600 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.66     1 33.66  1896       0          0 56.33   50  8.603   .01065 17.06 4.258   1 17.06   961       0          0 70.65   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2532         0                22600 50.72 2857 56.36\n",
            "\n",
            "16:09:38 | time:407s total_exs:22650 total_steps:22650 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.84     1 34.84  2012       0          0 57.74   50  9.757   .01073 17.02 4.513   1 17.02 982.9       0          0 91.21   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2033         0                22650 51.86 2995 57.78\n",
            "\n",
            "16:09:39 | time:408s total_exs:22700 total_steps:22700 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.52     1 27.52  1557       0          0 56.58   50  9.817   .01055 14.32 4.034   1 14.32 810.3       0          0 56.48   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2668         0                22700 41.84 2368 56.61\n",
            "\n",
            "16:09:40 | time:409s total_exs:22750 total_steps:22750 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.06     1 29.06  1653       0          0 56.88   50  9.682    .0106 15.62 4.253   1 15.62 888.5       0          0 70.33   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2535         0                22750 44.68 2541 56.9\n",
            "\n",
            "16:09:41 | time:410s total_exs:22800 total_steps:22800 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.92     1 29.92  1696       0          0 56.69   50  8.975   .01062  16.8 4.216   1  16.8 952.5       0          0 67.73   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2548         0                22800 46.72 2649 56.73\n",
            "\n",
            "16:09:42 | time:411s total_exs:22850 total_steps:22850 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.36     1 34.36  1953       0          0 56.82   50  9.571   .01063 15.72  4.31   1 15.72 893.3       0          0 74.45   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2252         0                22850 50.08 2846 56.85\n",
            "\n",
            "16:09:43 | time:412s total_exs:22900 total_steps:22900 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.22     1 34.22  1926       0          0 56.27   50  10.07   .01068 16.92 4.412   1 16.92 952.2       0          0 82.41   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2352         0                22900 51.14 2878 56.3\n",
            "\n",
            "16:09:43 | time:412s total_exs:22950 total_steps:22950 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.32     1 23.32  1328       0          0 56.96   50  8.514   .01055 16.72 4.421   1 16.72 952.4       0          0 83.15   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2225         0                22950 40.04 2281 56.99\n",
            "\n",
            "16:09:44 | time:413s total_exs:23000 total_steps:23000 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.64     1 26.64  1504       0          0 56.46   50  9.059   .01057  16.7 4.541   1  16.7 942.9       0          0 93.78   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2299         0                23000 43.34 2447 56.49\n",
            "\n",
            "16:09:45 | time:414s total_exs:23050 total_steps:23050 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.18     1 36.18  2082       0          0 57.54   50   9.27   .01063  15.9 4.306   1  15.9   915       0          0 74.12   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2327         0                23050 52.08 2997 57.57\n",
            "\n",
            "16:09:46 | time:415s total_exs:23100 total_steps:23100 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.22     1 29.22  1672       0          0  57.2   50  9.092   .01059 16.12 3.885   1 16.12 922.1       0          0 48.65   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2953         0                23100 45.34 2594 57.23\n",
            "\n",
            "16:09:47 | time:416s total_exs:23150 total_steps:23150 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.16     1 29.16  1684       0          0 57.75   50    9.7   .01064 15.36 4.318   1 15.36 887.1       0          0 75.02   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2435         0                23150 44.52 2571 57.78\n",
            "\n",
            "16:09:48 | time:417s total_exs:23200 total_steps:23200 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    25.5     1  25.5  1477       0          0 57.93   50  8.804   .01062 17.02  4.26   1 17.02   986       0          0 70.84   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2573         0                23200 42.52 2463 57.96\n",
            "\n",
            "16:09:49 | time:418s total_exs:23250 total_steps:23250 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.4     1  34.4  1969       0          0 57.24   50  9.255   .01063 15.42 4.374   1 15.42 882.7       0          0 79.33   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2374         0                23250 49.82 2852 57.27\n",
            "\n",
            "16:09:50 | time:419s total_exs:23300 total_steps:23300 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.26     1 26.26  1502       0          0  57.2   50  9.593   .01055 14.94 4.301   1 14.94 854.7       0          0 73.74   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2503         0                23300 41.2 2357 57.24\n",
            "\n",
            "16:09:51 | time:419s total_exs:23350 total_steps:23350 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.66     1 32.66  1851       0          0 56.67   50  9.255   .01058 14.38 4.267   1 14.38   815       0          0 71.32   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2392         0                23350 47.04 2666 56.7\n",
            "\n",
            "16:09:51 | time:420s total_exs:23400 total_steps:23400 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.02     1 29.02  1608       0          0  55.4   50  9.249   .01063 16.78 4.177   1 16.78 929.7       0          0 65.15   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2384         0                23400 45.8 2538 55.43\n",
            "\n",
            "16:09:52 | time:421s total_exs:23450 total_steps:23450 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.18     1 34.18  1991       0          0 58.25   50  8.637   .01065  18.9 4.344   1  18.9  1101       0          0 76.99   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2402         0                23450 53.08 3092 58.28\n",
            "\n",
            "16:09:53 | time:422s total_exs:23500 total_steps:23500 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.44     1 30.44  1734       0          0 56.95   50  9.148   .01056 17.66 4.513   1 17.66  1006       0          0 91.15   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2140         0                23500 48.1 2740 56.99\n",
            "\n",
            "16:09:54 | time:423s total_exs:23550 total_steps:23550 epochs:0.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.72     1 31.72  1825       0          0 57.54   50  9.606   .01067  14.1  4.13   1  14.1 811.4       0          0 62.16   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2482         0                23550 45.82 2637 57.57\n",
            "\n",
            "16:09:55 | time:424s total_exs:23600 total_steps:23600 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    29.6     1  29.6  1716       0          0 57.96   50  9.064   .01077 18.26 4.402   1 18.26  1058       0          0 81.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2541         0                23600 47.86 2774 57.99\n",
            "\n",
            "16:09:56 | time:425s total_exs:23650 total_steps:23650 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.68     1 34.68  1981       0          0 57.12   50  8.938    .0106 15.74 4.383   1 15.74 899.1       0          0 80.07   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2478         0                23650 50.42 2880 57.15\n",
            "\n",
            "16:09:57 | time:426s total_exs:23700 total_steps:23700 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.3     1  26.3  1479       0          0 56.24   50  9.457   .01053 13.36 4.325   1 13.36 751.4       0          0 75.58   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2485         0                23700 39.66 2231 56.27\n",
            "\n",
            "16:09:58 | time:427s total_exs:23750 total_steps:23750 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.46     1 28.46  1630       0          0 57.28   50  8.673   .01054  17.2 4.348   1  17.2 985.3       0          0 77.29   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2384         0                23750 45.66 2616 57.31\n",
            "\n",
            "16:09:59 | time:428s total_exs:23800 total_steps:23800 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.56     1 33.56  1892       0          0 56.37   50  8.555   .01063  18.1 4.397   1  18.1  1020       0          0 81.24   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2320         0                23800 51.66 2912 56.4\n",
            "\n",
            "16:09:59 | time:428s total_exs:23850 total_steps:23850 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.4     1  31.4  1809       0          0  57.6   50  9.337   .01057 14.88 4.401   1 14.88 857.2       0          0 81.52   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2030         0                23850 46.28 2666 57.63\n",
            "\n",
            "16:10:00 | time:429s total_exs:23900 total_steps:23900 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.94     1 34.94  1993       0          0 57.02   50  9.416   .01062  16.3 4.167   1  16.3 929.5       0          0 64.51   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2429         0                23900 51.24 2922 57.05\n",
            "\n",
            "16:10:01 | time:430s total_exs:23950 total_steps:23950 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   40.36     1 40.36  2294       0          0 56.84   50  9.319   .01093 17.44 4.471   1 17.44 991.4       0          0 87.41   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2408         0                23950 57.8 3286 56.87\n",
            "\n",
            "16:10:02 | time:431s total_exs:24000 total_steps:24000 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.64     1 38.64  2222       0          0 57.49   50  8.778   .01072 23.96 4.661   1 23.96  1378       0          0 105.7   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .1928         0                24000 62.6 3599 57.52\n",
            "\n",
            "16:10:03 | time:432s total_exs:24050 total_steps:24050 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.88     1 34.88  2013       0          0  57.7   50  7.898   .01071 18.46 4.267   1 18.46  1065       0          0 71.29   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2535         0                24050 53.34 3078 57.73\n",
            "\n",
            "16:10:04 | time:433s total_exs:24100 total_steps:24100 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.1     1  32.1  1827       0          0  56.9   50  8.925    .0106  14.9 4.501   1  14.9 847.9       0          0 90.08   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2644         0                24100   47 2675 56.93\n",
            "\n",
            "16:10:05 | time:434s total_exs:24150 total_steps:24150 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.88     1 32.88  1837       0          0 55.86   50  8.967   .01061 16.58 4.199   1 16.58 926.2       0          0 66.61   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2437         0                24150 49.46 2763 55.89\n",
            "\n",
            "16:10:06 | time:435s total_exs:24200 total_steps:24200 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.44     1 30.44  1732       0          0 56.89   50  8.834   .01063 17.86 4.302   1 17.86  1016       0          0 73.84   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2352         0                24200 48.3 2748 56.92\n",
            "\n",
            "16:10:07 | time:435s total_exs:24250 total_steps:24250 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.04     1 35.04  2020       0          0 57.63   50  10.07    .0106 12.72 4.123   1 12.72 733.1       0          0 61.75   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2531         0                24250 47.76 2753 57.66\n",
            "\n",
            "16:10:07 | time:436s total_exs:24300 total_steps:24300 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.68     1 28.68  1631       0          0 56.86   50  8.579   .01062    17 4.368   1    17 966.7       0          0 78.87   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2200         0                24300 45.68 2598 56.9\n",
            "\n",
            "16:10:08 | time:437s total_exs:24350 total_steps:24350 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.38     1 25.38  1443       0          0 56.85   50  8.861   .01057 17.34 4.668   1 17.34 985.8       0          0 106.5   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2307         0                24350 42.72 2429 56.88\n",
            "\n",
            "16:10:09 | time:438s total_exs:24400 total_steps:24400 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.28     1 27.28  1572       0          0 57.62   50  8.631   .01064  16.9 4.273   1  16.9 973.9       0          0 71.74   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2604         0                24400 44.18 2546 57.65\n",
            "\n",
            "16:10:10 | time:439s total_exs:24450 total_steps:24450 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.24     1 27.24  1548       0          0 56.82   50  9.368   .01058 14.04 4.474   1 14.04 797.9       0          0 87.73   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2151         0                24450 41.28 2346 56.85\n",
            "\n",
            "16:10:11 | time:440s total_exs:24500 total_steps:24500 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.52     1 27.52  1583       0          0 57.53   50  9.025   .01055 16.94 4.206   1 16.94 974.7       0          0 67.07   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2538         0                24500 44.46 2558 57.56\n",
            "\n",
            "16:10:12 | time:441s total_exs:24550 total_steps:24550 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.98     1 26.98  1553       0          0 57.56   50   9.27   .01053  15.8 4.511   1  15.8 909.5       0          0 91.02   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2316         0                24550 42.78 2463 57.59\n",
            "\n",
            "16:10:13 | time:442s total_exs:24600 total_steps:24600 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   36.28     1 36.28  2089       0          0 57.56   50  10.06   .01079 14.84 4.088   1 14.84 854.3       0          0 59.6   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2736         0                24600 51.12 2943 57.59\n",
            "\n",
            "16:10:14 | time:443s total_exs:24650 total_steps:24650 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   43.82     1 43.82  2529       0          0 57.71   50   8.55   .01087  19.3 4.673   1  19.3  1114       0          0  107   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1876         0                24650 63.12 3643 57.75\n",
            "\n",
            "16:10:15 | time:443s total_exs:24700 total_steps:24700 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.62     1 28.62  1625       0          0 56.78   50  8.828   .01056 17.68 4.567   1 17.68  1004       0          0 96.27   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2296         0                24700 46.3 2629 56.81\n",
            "\n",
            "16:10:15 | time:444s total_exs:24750 total_steps:24750 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   30.06     1 30.06  1707       0          0 56.78   50  9.625   .01068 14.58 4.393   1 14.58 827.9       0          0 80.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2606         0                24750 44.64 2535 56.81\n",
            "\n",
            "16:10:16 | time:445s total_exs:24800 total_steps:24800 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   23.64     1 23.64  1341       0          0 56.72   50  9.217   .01055 16.32 4.056   1 16.32 925.7       0          0 57.71   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2451         0                24800 39.96 2267 56.75\n",
            "\n",
            "16:10:17 | time:446s total_exs:24850 total_steps:24850 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   42.34     1 42.34  2447       0          0 57.79   50   9.61   .01073 15.54 4.583   1 15.54 898.2       0          0 97.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2342         0                24850 57.88 3346 57.83\n",
            "\n",
            "16:10:18 | time:447s total_exs:24900 total_steps:24900 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.32     1 28.32  1607       0          0 56.76   50  8.947   .01059 16.44 4.287   1 16.44 933.1       0          0 72.75   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2470         0                24900 44.76 2541 56.79\n",
            "\n",
            "16:10:19 | time:448s total_exs:24950 total_steps:24950 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   33.22     1 33.22  1901       0          0 57.21   50  8.589   .01069  17.3 4.307   1  17.3 989.9       0          0 74.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2289         0                24950 50.52 2891 57.25\n",
            "\n",
            "16:10:20 | time:449s total_exs:25000 total_steps:25000 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.72     1 28.72  1676       0          0 58.34   50  9.662   .01061  14.8 4.373   1  14.8 863.5       0          0 79.25   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2500     .0200                25000 43.52 2539 58.38\n",
            "\n",
            "16:10:21 | time:450s total_exs:25050 total_steps:25050 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.04     1 29.04  1676       0          0 57.71   50  8.801   .01056  18.7 4.288   1  18.7  1079       0          0 72.82   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2417         0                25050 47.74 2755 57.75\n",
            "\n",
            "16:10:22 | time:451s total_exs:25100 total_steps:25100 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.18     1 31.18  1786       0          0 57.27   50   9.56   .01061    14 4.012   1    14 801.8       0          0 55.28   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2900         0                25100 45.18 2588 57.31\n",
            "\n",
            "16:10:23 | time:451s total_exs:25150 total_steps:25150 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   22.54     1 22.54  1261       0          0 55.95   50  9.265   .01053  13.9 4.132   1  13.9 777.8       0          0 62.27   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2590         0                25150 36.44 2039 55.99\n",
            "\n",
            "16:10:23 | time:452s total_exs:25200 total_steps:25200 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.38     1 27.38  1546       0          0 56.45   50  8.958   .01056 17.52 4.429   1 17.52 989.2       0          0 83.84   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2477         0                25200 44.9 2535 56.49\n",
            "\n",
            "16:10:24 | time:453s total_exs:25250 total_steps:25250 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.62     1 28.62  1634       0          0 57.08   50  9.691   .01056 16.88 4.195   1 16.88 963.6       0          0 66.33   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2618         0                25250 45.5 2597 57.11\n",
            "\n",
            "16:10:25 | time:454s total_exs:25300 total_steps:25300 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.86     1 28.86  1643       0          0 56.93   50  9.351   .01062  15.9  4.46   1  15.9 905.3       0          0 86.48   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2189         0                25300 44.76 2549 56.96\n",
            "\n",
            "16:10:26 | time:455s total_exs:25350 total_steps:25350 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      32     1    32  1833       0          0 57.26   50  9.326   .01059 15.12 4.375   1 15.12 865.8       0          0 79.47   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2487         0                25350 47.12 2698 57.29\n",
            "\n",
            "16:10:27 | time:456s total_exs:25400 total_steps:25400 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.36     1 29.36  1705       0          0 58.07   50  9.405   .01058 13.24 4.231   1 13.24 768.9       0          0 68.75   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2613         0                25400 42.6 2474 58.1\n",
            "\n",
            "16:10:28 | time:457s total_exs:25450 total_steps:25450 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.28     1 33.28  1920       0          0 57.69   50   10.1   .01062  15.5 4.509   1  15.5 894.2       0          0 90.87   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2103         0                25450 48.78 2814 57.72\n",
            "\n",
            "16:10:29 | time:458s total_exs:25500 total_steps:25500 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.56     1 33.56  1929       0          0 57.48   50  8.896   .01061 17.62 4.506   1 17.62  1013       0          0 90.54   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2406         0                25500 51.18 2942 57.51\n",
            "\n",
            "16:10:30 | time:459s total_exs:25550 total_steps:25550 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    28.3     1  28.3  1612       0          0 56.94   50  9.153   .01055  16.3 4.439   1  16.3 928.2       0          0 84.69   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2393         0                25550 44.6 2540 56.97\n",
            "\n",
            "16:10:30 | time:459s total_exs:25600 total_steps:25600 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    39.6     1  39.6  2269       0          0 57.29   50  9.081   .01081 15.62 4.582   1 15.62   895       0          0 97.69   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2318         0                25600 55.22 3164 57.32\n",
            "\n",
            "16:10:31 | time:460s total_exs:25650 total_steps:25650 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.34     1 33.34  1913       0          0 57.36   50  8.856   .01067 16.28 4.593   1 16.28 933.9       0          0 98.82   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2543         0                25650 49.62 2847 57.39\n",
            "\n",
            "16:10:32 | time:461s total_exs:25700 total_steps:25700 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   30.16     1 30.16  1723       0          0 57.11   50  9.199   .01065 16.68 4.062   1 16.68 952.6       0          0 58.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2746         0                25700 46.84 2675 57.14\n",
            "\n",
            "16:10:33 | time:462s total_exs:25750 total_steps:25750 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.2     1  29.2  1678       0          0 57.46   50   10.4   .01056  12.2 3.957   1  12.2   701       0          0 52.28   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2885         0                25750 41.4 2379 57.49\n",
            "\n",
            "16:10:34 | time:463s total_exs:25800 total_steps:25800 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.48     1 31.48  1831       0          0 58.17   50  9.326   .01058 15.28 4.114   1 15.28 888.9       0          0 61.22   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2657         0                25800 46.76 2720 58.2\n",
            "\n",
            "16:10:35 | time:464s total_exs:25850 total_steps:25850 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.66     1 28.66  1636       0          0 57.06   50  9.434   .01061 16.42 4.517   1 16.42   937       0          0 91.59   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2241         0                25850 45.08 2573 57.09\n",
            "\n",
            "16:10:36 | time:465s total_exs:25900 total_steps:25900 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.26     1 31.26  1800       0          0 57.57   50  9.058    .0106 16.32 4.535   1 16.32 939.6       0          0 93.25   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2292         0                25900 47.58 2740 57.6\n",
            "\n",
            "16:10:37 | time:466s total_exs:25950 total_steps:25950 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.58     1 31.58  1791       0          0 56.72   50   8.67   .01065  13.8 4.263   1  13.8 782.8       0          0 71.03   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2333         0                25950 45.38 2574 56.75\n",
            "\n",
            "16:10:38 | time:467s total_exs:26000 total_steps:26000 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.94     1 27.94  1598       0          0  57.2   50  9.013   .01058 14.68 3.939   1 14.68 839.8       0          0 51.36   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2711         0                26000 42.62 2438 57.23\n",
            "\n",
            "16:10:38 | time:467s total_exs:26050 total_steps:26050 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   42.08     1 42.08  2385       0          0 56.67   50   9.17   .01076  17.7 4.545   1  17.7  1003       0          0 94.11   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2226         0                26050 59.78 3388 56.7\n",
            "\n",
            "16:10:39 | time:468s total_exs:26100 total_steps:26100 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.76     1 32.76  1901       0          0 58.04   50  9.248   .01064 16.26 4.331   1 16.26 943.7       0          0 75.98   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2288         0                26100 49.02 2845 58.07\n",
            "\n",
            "16:10:40 | time:469s total_exs:26150 total_steps:26150 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.56     1 30.56  1787       0          0 58.46   50  8.267   .01059 17.82 4.242   1 17.82  1042       0          0 69.52   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2334         0                26150 48.38 2829 58.5\n",
            "\n",
            "16:10:41 | time:470s total_exs:26200 total_steps:26200 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.06     1 30.06  1736       0          0 57.76   50  8.658   .01057 17.14 4.048   1 17.14   990       0          0 57.29   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2637         0                26200 47.2 2726 57.79\n",
            "\n",
            "16:10:42 | time:471s total_exs:26250 total_steps:26250 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.76     1 31.76  1817       0          0  57.2   50  9.113   .01064 15.54 4.481   1 15.54   889       0          0 88.36   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2394         0                26250 47.3 2706 57.24\n",
            "\n",
            "16:10:43 | time:472s total_exs:26300 total_steps:26300 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.94     1 28.94  1650       0          0 57.01   50  9.376   .01056 16.28 4.375   1 16.28 928.2       0          0 79.44   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2469         0                26300 45.22 2578 57.04\n",
            "\n",
            "16:10:44 | time:473s total_exs:26350 total_steps:26350 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.66     1 31.66  1812       0          0 57.23   50  9.279   .01064  15.5 4.248   1  15.5 887.1       0          0 69.94   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2516         0                26350 47.16 2699 57.26\n",
            "\n",
            "16:10:45 | time:474s total_exs:26400 total_steps:26400 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.5     1  31.5  1800       0          0 57.13   50  9.637   .01058    17 4.175   1    17 971.2       0          0 65.07   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2482         0                26400 48.5 2771 57.15\n",
            "\n",
            "16:10:46 | time:474s total_exs:26450 total_steps:26450 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.28     1 32.28  1851       0          0 57.33   50  9.588   .01068 14.36 4.179   1 14.36 823.3       0          0 65.28   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2354         0                26450 46.64 2674 57.36\n",
            "\n",
            "16:10:46 | time:475s total_exs:26500 total_steps:26500 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.92     1 29.92  1707       0          0 57.04   50  10.24   .01056  12.6 4.169   1  12.6 718.8       0          0 64.64   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2286         0                26500 42.52 2426 57.07\n",
            "\n",
            "16:10:47 | time:476s total_exs:26550 total_steps:26550 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.26     1 28.26  1643       0          0 58.12   50  9.642   .01057 16.28  4.29   1 16.28 946.2       0          0 72.94   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2457         0                26550 44.54 2589 58.15\n",
            "\n",
            "16:10:48 | time:477s total_exs:26600 total_steps:26600 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.2     1  34.2  1964       0          0 57.43   50  9.164   .01064 17.04 4.306   1 17.04 978.8       0          0 74.11   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2324         0                26600 51.24 2943 57.47\n",
            "\n",
            "16:10:49 | time:478s total_exs:26650 total_steps:26650 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.16     1 26.16  1500       0          0 57.35   50  9.514   .01054  15.7  4.15   1  15.7 900.4       0          0 63.45   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2688         0                26650 41.86 2401 57.38\n",
            "\n",
            "16:10:50 | time:479s total_exs:26700 total_steps:26700 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.92     1 31.92  1832       0          0 57.38   50  8.535   .01058 17.04 4.069   1 17.04 977.8       0          0 58.47   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2676         0                26700 48.96 2810 57.41\n",
            "\n",
            "16:10:51 | time:480s total_exs:26750 total_steps:26750 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   40.08     1 40.08  2298       0          0 57.33   50  7.893   .01088 24.14 4.637   1 24.14  1384       0          0 103.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2088         0                26750 64.22 3682 57.36\n",
            "\n",
            "16:10:52 | time:481s total_exs:26800 total_steps:26800 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.58     1 25.58  1444       0          0 56.43   50   9.92   .01055  16.2 4.154   1  16.2 914.3       0          0 63.69   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2691         0                26800 41.78 2358 56.46\n",
            "\n",
            "16:10:53 | time:482s total_exs:26850 total_steps:26850 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.22     1 29.22  1673       0          0 57.24   50  10.16   .01059  15.1 4.232   1  15.1 864.4       0          0 68.88   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2238         0                26850 44.32 2537 57.27\n",
            "\n",
            "16:10:53 | time:482s total_exs:26900 total_steps:26900 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.16     1 31.16  1802       0          0 57.81   50  8.736   .01057 16.34 4.047   1 16.34 944.7       0          0 57.23   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2570         0                26900 47.5 2746 57.84\n",
            "\n",
            "16:10:54 | time:483s total_exs:26950 total_steps:26950 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.72     1 33.72  1901       0          0 56.36   50  9.649   .01061 15.58  4.25   1 15.58 878.2       0          0 70.08   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2644         0                26950 49.3 2779 56.39\n",
            "\n",
            "16:10:55 | time:484s total_exs:27000 total_steps:27000 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.68     1 31.68  1817       0          0 57.35   50  9.118   .01062 15.44 4.295   1 15.44 885.6       0          0 73.34   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2422         0                27000 47.12 2703 57.39\n",
            "\n",
            "16:10:56 | time:485s total_exs:27050 total_steps:27050 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   31.48     1 31.48  1786       0          0 56.71   50  8.284   .01067 17.38 4.233   1 17.38 985.8       0          0 68.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2520         0                27050 48.86 2771 56.75\n",
            "\n",
            "16:10:57 | time:486s total_exs:27100 total_steps:27100 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.26     1 28.26  1600       0          0 56.61   50  8.585   .01067  18.1 4.278   1  18.1  1025       0          0 72.06   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2431         0                27100 46.36 2625 56.64\n",
            "\n",
            "16:10:58 | time:487s total_exs:27150 total_steps:27150 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    30.7     1  30.7  1748       0          0 56.92   50  9.754   .01058 14.56 4.107   1 14.56 828.8       0          0 60.75   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2734         0                27150 45.26 2576 56.95\n",
            "\n",
            "16:10:59 | time:488s total_exs:27200 total_steps:27200 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.38     1 32.38  1830       0          0  56.5   50   9.58   .01065 16.34  4.44   1 16.34 923.3       0          0 84.76   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2032         0                27200 48.72 2753 56.53\n",
            "\n",
            "16:11:00 | time:489s total_exs:27250 total_steps:27250 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.62     1 26.62  1520       0          0  57.1   50  9.022   .01057 16.78  4.38   1 16.78 958.2       0          0 79.84   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2563         0                27250 43.4 2478 57.13\n",
            "\n",
            "16:11:01 | time:490s total_exs:27300 total_steps:27300 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.44     1 33.44  1908       0          0 57.06   50  8.937    .0106 14.48 3.904   1 14.48 826.3       0          0 49.58   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2707         0                27300 47.92 2735 57.09\n",
            "\n",
            "16:11:02 | time:491s total_exs:27350 total_steps:27350 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.72     1 30.72  1717       0          0  55.9   50  9.455   .01062 16.18 4.265   1 16.18 904.4       0          0 71.14   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2534         0                27350 46.9 2622 55.93\n",
            "\n",
            "16:11:02 | time:491s total_exs:27400 total_steps:27400 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.46     1 33.46  1901       0          0 56.81   50  9.094   .01068 15.36  4.58   1 15.36 872.7       0          0 97.54   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2122         0                27400 48.82 2774 56.84\n",
            "\n",
            "16:11:03 | time:492s total_exs:27450 total_steps:27450 epochs:0.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   31.96     1 31.96  1830       0          0 57.25   50   9.52   .01058 15.82 4.251   1 15.82 905.8       0          0 70.2   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2541         0                27450 47.78 2736 57.28\n",
            "\n",
            "16:11:04 | time:493s total_exs:27500 total_steps:27500 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.76     1 31.76  1804       0          0 56.81   50  8.999   .01058 14.88 4.069   1 14.88 845.4       0          0 58.52   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2661         0                27500 46.64 2650 56.84\n",
            "\n",
            "16:11:05 | time:494s total_exs:27550 total_steps:27550 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    27.6     1  27.6  1543       0          0 55.89   50  8.725   .01055 16.76 4.277   1 16.76 936.8       0          0 72.04   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2351         0                27550 44.36 2480 55.92\n",
            "\n",
            "16:11:06 | time:495s total_exs:27600 total_steps:27600 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.54     1 28.54  1645       0          0 57.62   50  9.597    .0106  17.1 4.424   1  17.1 985.4       0          0 83.4   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2281         0                27600 45.64 2630 57.65\n",
            "\n",
            "16:11:07 | time:496s total_exs:27650 total_steps:27650 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.12     1 32.12  1806       0          0 56.21   50  8.103   .01056 18.62 4.224   1 18.62  1047       0          0 68.32   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2449         0                27650 50.74 2852 56.24\n",
            "\n",
            "16:11:08 | time:497s total_exs:27700 total_steps:27700 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    31.7     1  31.7  1834       0          0 57.86   50  8.717   .01062 17.46 4.608   1 17.46  1010       0          0 100.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2016         0                27700 49.16 2845 57.89\n",
            "\n",
            "16:11:09 | time:498s total_exs:27750 total_steps:27750 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.3     1  29.3  1694       0          0 57.82   50  8.525   .01061 16.26 4.411   1 16.26 940.3       0          0 82.35   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2263         0                27750 45.56 2635 57.85\n",
            "\n",
            "16:11:10 | time:499s total_exs:27800 total_steps:27800 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      32     1    32  1833       0          0 57.28   50  8.382   .01063 18.38 4.342   1 18.38  1053       0          0 76.86   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2329         0                27800 50.38 2886 57.31\n",
            "\n",
            "16:11:10 | time:499s total_exs:27850 total_steps:27850 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.18     1 25.18  1455       0          0 57.78   50  9.383   .01056 14.84 4.298   1 14.84 857.5       0          0 73.53   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2520         0                27850 40.02 2313 57.81\n",
            "\n",
            "16:11:11 | time:500s total_exs:27900 total_steps:27900 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.22     1 31.22  1801       0          0 57.68   50  8.525    .0106  16.5 4.451   1  16.5 951.9       0          0 85.72   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2291         0                27900 47.72 2753 57.72\n",
            "\n",
            "16:11:12 | time:501s total_exs:27950 total_steps:27950 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.36     1 31.36  1776       0          0 56.63   50  9.584   .01057 15.68 4.391   1 15.68 888.1       0          0 80.71   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2372         0                27950 47.04 2664 56.67\n",
            "\n",
            "16:11:13 | time:502s total_exs:28000 total_steps:28000 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.78     1 37.78  2160       0          0 57.17   50  9.578   .01071 16.22 4.485   1 16.22 927.4       0          0 88.68   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2281         0                28000   54 3088 57.2\n",
            "\n",
            "16:11:14 | time:503s total_exs:28050 total_steps:28050 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.3     1  33.3  1912       0          0  57.4   50  9.228   .01063 18.66 4.447   1 18.66  1071       0          0 85.37   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2272         0                28050 51.96 2983 57.43\n",
            "\n",
            "16:11:15 | time:504s total_exs:28100 total_steps:28100 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.76     1 34.76  2022       0          0 58.17   50  8.601   .01061 16.42 4.271   1 16.42 955.3       0          0 71.57   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2473         0                28100 51.18 2978 58.2\n",
            "\n",
            "16:11:16 | time:505s total_exs:28150 total_steps:28150 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.26     1 38.26  2234       0          0 58.39   50  8.363   .01087 21.04 4.466   1 21.04  1229       0          0 87.02   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2120         0                28150 59.3 3463 58.43\n",
            "\n",
            "16:11:17 | time:506s total_exs:28200 total_steps:28200 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.3     1  29.3  1670       0          0 56.99   50  9.442   .01058  13.9 4.091   1  13.9 792.2       0          0 59.78   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2619         0                28200 43.2 2462 57.02\n",
            "\n",
            "16:11:18 | time:506s total_exs:28250 total_steps:28250 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.92     1 28.92  1650       0          0 57.06   50  9.579   .01061 14.32 4.286   1 14.32 817.2       0          0 72.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2346         0                28250 43.24 2468 57.09\n",
            "\n",
            "16:11:18 | time:507s total_exs:28300 total_steps:28300 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    30.5     1  30.5  1731       0          0 56.76   50  9.332   .01066 17.78 4.201   1 17.78  1009       0          0 66.78   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2565         0                28300 48.28 2741 56.8\n",
            "\n",
            "16:11:19 | time:508s total_exs:28350 total_steps:28350 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.12     1 27.12  1534       0          0 56.56   50  9.483   .01065 16.14 4.268   1 16.14 912.9       0          0 71.35   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2243         0                28350 43.26 2447 56.59\n",
            "\n",
            "16:11:20 | time:509s total_exs:28400 total_steps:28400 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    38.6     1  38.6  2219       0          0 57.49   50  8.513   .01064  17.8 4.606   1  17.8  1023       0          0  100   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2157         0                28400 56.4 3243 57.52\n",
            "\n",
            "16:11:21 | time:510s total_exs:28450 total_steps:28450 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.46     1 35.46  1904       0          0 53.68   50  8.847   .01071    16  4.08   1    16 858.9       0          0 59.15   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2537         0                28450 51.46 2763 53.71\n",
            "\n",
            "16:11:22 | time:511s total_exs:28500 total_steps:28500 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.36     1 28.36  1602       0          0 56.49   50  9.338    .0106 14.66 3.969   1 14.66 828.2       0          0 52.93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2524         0                28500 43.02 2430 56.52\n",
            "\n",
            "16:11:23 | time:512s total_exs:28550 total_steps:28550 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.62     1 35.62  2026       0          0 56.87   50  9.342   .01061 15.58 4.432   1 15.58 886.1       0          0 84.09   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps  ups  \n",
            "        .2285         0                28550 51.2 2912 56.9\n",
            "\n",
            "16:11:24 | time:513s total_exs:28600 total_steps:28600 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.82     1 29.82  1680       0          0 56.33   50  9.018    .0106 14.72 4.058   1 14.72 829.2       0          0 57.89   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2527         0                28600 44.54 2509 56.36\n",
            "\n",
            "16:11:25 | time:514s total_exs:28650 total_steps:28650 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    48.3     1  48.3  2756       0          0 57.04   50  10.59   .01104 16.84 4.484   1 16.84 960.7       0          0 88.55   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2150         0                28650 65.14 3716 57.08\n",
            "\n",
            "16:11:26 | time:515s total_exs:28700 total_steps:28700 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.48     1 26.48  1472       0          0 55.59   50  9.395   .01053 14.96 4.304   1 14.96 831.7       0          0 74.02   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2246         0                28700 41.44 2304 55.62\n",
            "\n",
            "16:11:27 | time:515s total_exs:28750 total_steps:28750 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.62     1 29.62  1665       0          0  56.2   50  8.547   .01055  16.9 4.226   1  16.9 949.9       0          0 68.44   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2355         0                28750 46.52 2615 56.24\n",
            "\n",
            "16:11:27 | time:516s total_exs:28800 total_steps:28800 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.34     1 29.34  1669       0          0 56.89   50  10.13   .01058 13.54 4.331   1 13.54 770.3       0          0 76.05   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2112         0                28800 42.88 2440 56.92\n",
            "\n",
            "16:11:28 | time:517s total_exs:28850 total_steps:28850 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.52     1 29.52  1702       0          0 57.66   50  8.941   .01057 15.44 4.262   1 15.44 890.3       0          0 70.96   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2591         0                28850 44.96 2593 57.69\n",
            "\n",
            "16:11:29 | time:518s total_exs:28900 total_steps:28900 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.06     1 30.06  1716       0          0 57.09   50  9.534   .01059  15.2 4.005   1  15.2 867.8       0          0 54.85   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2526         0                28900 45.26 2584 57.12\n",
            "\n",
            "16:11:30 | time:519s total_exs:28950 total_steps:28950 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   24.06     1 24.06  1393       0          0 57.88   50  8.676   .01055 18.52 4.191   1 18.52  1072       0          0 66.06   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2484         0                28950 42.58 2465 57.92\n",
            "\n",
            "16:11:31 | time:520s total_exs:29000 total_steps:29000 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.48     1 26.48  1474       0          0 55.66   50  9.333   .01055 18.14 4.286   1 18.14  1010       0          0 72.66   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2326         0                29000 44.62 2484 55.69\n",
            "\n",
            "16:11:32 | time:521s total_exs:29050 total_steps:29050 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.42     1 30.42  1726       0          0 56.74   50   9.16   .01069 15.42 4.203   1 15.42 875.1       0          0 66.86   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2490         0                29050 45.84 2601 56.77\n",
            "\n",
            "16:11:33 | time:522s total_exs:29100 total_steps:29100 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.12     1 38.12  2163       0          0 56.73   50  8.231   .01073  16.8 4.164   1  16.8 953.1       0          0 64.34   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2405         0                29100 54.92 3116 56.76\n",
            "\n",
            "16:11:34 | time:523s total_exs:29150 total_steps:29150 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.74     1 33.74  1919       0          0 56.87   50  8.229    .0106 16.86 4.123   1 16.86 958.8       0          0 61.77   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2539         0                29150 50.6 2878 56.89\n",
            "\n",
            "16:11:35 | time:523s total_exs:29200 total_steps:29200 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.74     1 36.74  2096       0          0 57.03   50   8.51   .01064 18.66 4.577   1 18.66  1064       0          0 97.23   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2015         0                29200 55.4 3160 57.06\n",
            "\n",
            "16:11:35 | time:524s total_exs:29250 total_steps:29250 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    24.8     1  24.8  1404       0          0 56.59   50  9.113   .01056 16.28  4.22   1 16.28 921.3       0          0 68.03   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2568         0                29250 41.08 2325 56.62\n",
            "\n",
            "16:11:36 | time:525s total_exs:29300 total_steps:29300 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.24     1 26.24  1477       0          0  56.3   50  9.127   .01055  16.1 4.399   1  16.1 906.4       0          0 81.39   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2385         0                29300 42.34 2384 56.33\n",
            "\n",
            "16:11:37 | time:526s total_exs:29350 total_steps:29350 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    29.4     1  29.4  1676       0          0 56.99   50  8.784   .01058  18.4 4.425   1  18.4  1049       0          0 83.55   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2272         0                29350 47.8 2725 57.02\n",
            "\n",
            "16:11:38 | time:527s total_exs:29400 total_steps:29400 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.66     1 28.66  1637       0          0 57.11   50  8.645   .01056 17.06 4.359   1 17.06 974.3       0          0 78.16   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2274         0                29400 45.72 2611 57.14\n",
            "\n",
            "16:11:39 | time:528s total_exs:29450 total_steps:29450 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.64     1 31.64  1778       0          0 56.19   50  9.122    .0106 16.52 4.397   1 16.52 928.3       0          0 81.17   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2276         0                29450 48.16 2706 56.22\n",
            "\n",
            "16:11:40 | time:529s total_exs:29500 total_steps:29500 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.98     1 28.98  1675       0          0  57.8   50  7.981   .01058 17.16 4.337   1 17.16 991.9       0          0 76.51   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2483         0                29500 46.14 2667 57.83\n",
            "\n",
            "16:11:41 | time:530s total_exs:29550 total_steps:29550 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.88     1 32.88  1889       0          0 57.46   50  9.219   .01061 17.52 4.325   1 17.52  1007       0          0 75.57   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2409         0                29550 50.4 2896 57.49\n",
            "\n",
            "16:11:42 | time:531s total_exs:29600 total_steps:29600 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.2     1  32.2  1826       0          0 56.71   50  8.901   .01059  16.6 4.138   1  16.6 941.5       0          0 62.69   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2120         0                29600 48.8 2768 56.74\n",
            "\n",
            "16:11:43 | time:532s total_exs:29650 total_steps:29650 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.76     1 29.76  1711       0          0 57.49   50   8.91   .01059  16.7 4.008   1  16.7 960.2       0          0 55.05   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2766         0                29650 46.46 2671 57.52\n",
            "\n",
            "16:11:43 | time:532s total_exs:29700 total_steps:29700 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.16     1 30.16  1745       0          0 57.85   50  9.725   .01061 14.56 4.007   1 14.56 842.3       0          0 54.98   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2871         0                29700 44.72 2587 57.88\n",
            "\n",
            "16:11:44 | time:533s total_exs:29750 total_steps:29750 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.94     1 32.94  1898       0          0 57.63   50   8.25   .01062 17.94 4.206   1 17.94  1034       0          0 67.08   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2508         0                29750 50.88 2932 57.66\n",
            "\n",
            "16:11:45 | time:534s total_exs:29800 total_steps:29800 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   30.14     1 30.14  1723       0          0 57.16   50  8.351    .0106  17.9 4.236   1  17.9  1023       0          0 69.1   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2503         0                29800 48.04 2746 57.2\n",
            "\n",
            "16:11:46 | time:535s total_exs:29850 total_steps:29850 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      29     1    29  1651       0          0 56.93   50  9.112   .01055  16.1 4.194   1  16.1 916.7       0          0 66.27   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2571         0                29850 45.1 2568 56.97\n",
            "\n",
            "16:11:47 | time:536s total_exs:29900 total_steps:29900 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.36     1 34.36  1962       0          0  57.1   50  8.699   .01065 19.04 4.261   1 19.04  1087       0          0 70.91   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2269         0                29900 53.4 3050 57.14\n",
            "\n",
            "16:11:48 | time:537s total_exs:29950 total_steps:29950 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.14     1 31.14  1780       0          0 57.16   50  9.227   .01061 15.18 4.197   1 15.18 867.8       0          0 66.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2490         0                29950 46.32 2648 57.19\n",
            "\n",
            "16:11:49 | time:538s total_exs:30000 total_steps:30000 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.96     1 28.96  1637       0          0 56.51   50  8.935   .01059  16.4 4.111   1  16.4 926.8       0          0 60.98   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2549         0                30000 45.36 2564 56.54\n",
            "\n",
            "16:11:50 | time:539s total_exs:30050 total_steps:30050 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.64     1 33.64  1915       0          0 56.92   50  9.228   .01063 15.26 4.205   1 15.26 868.7       0          0 66.99   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2438         0                30050 48.9 2784 56.95\n",
            "\n",
            "16:11:51 | time:539s total_exs:30100 total_steps:30100 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.6     1  26.6  1528       0          0 57.43   50  8.369   .01055 19.88 4.573   1 19.88  1142       0          0 96.81   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2163         0                30100 46.48 2669 57.46\n",
            "\n",
            "16:11:51 | time:540s total_exs:30150 total_steps:30150 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    30.6     1  30.6  1756       0          0 57.38   50  9.225   .01061 16.44 4.365   1 16.44 943.4       0          0 78.61   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2092         0                30150 47.04 2700 57.41\n",
            "\n",
            "16:11:52 | time:541s total_exs:30200 total_steps:30200 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.9     1  32.9  1909       0          0 58.02   50  8.576   .01062  18.1 4.161   1  18.1  1050       0          0 64.16   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2497         0                30200   51 2959 58.05\n",
            "\n",
            "16:11:53 | time:542s total_exs:30250 total_steps:30250 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.24     1 31.24  1805       0          0 57.79   50  9.026   .01067 15.68   4.3   1 15.68 906.1       0          0 73.73   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2258         0                30250 46.92 2712 57.82\n",
            "\n",
            "16:11:54 | time:543s total_exs:30300 total_steps:30300 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.46     1 36.46  2097       0          0  57.5   50  8.658   .01061 18.18 4.604   1 18.18  1045       0          0 99.92   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2068         0                30300 54.64 3142 57.53\n",
            "\n",
            "16:11:55 | time:544s total_exs:30350 total_steps:30350 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    33.8     1  33.8  1926       0          0 56.99   50   9.04   .01061 17.14 4.419   1 17.14 976.8       0          0   83   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2205         0                30350 50.94 2903 57.02\n",
            "\n",
            "16:11:56 | time:545s total_exs:30400 total_steps:30400 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   24.38     1 24.38  1393       0          0 57.14   50  8.941   .01056 15.24 4.231   1 15.24 870.9       0          0 68.81   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2612         0                30400 39.62 2264 57.17\n",
            "\n",
            "16:11:57 | time:546s total_exs:30450 total_steps:30450 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.5     1  34.5  1947       0          0 56.42   50  8.898   .01077 18.32 4.341   1 18.32  1034       0          0 76.75   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2424         0                30450 52.82 2981 56.46\n",
            "\n",
            "16:11:58 | time:547s total_exs:30500 total_steps:30500 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.62     1 28.62  1661       0          0 58.03   50  8.872   .01073  15.9 4.211   1  15.9 922.7       0          0 67.45   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2503         0                30500 44.52 2584 58.06\n",
            "\n",
            "16:11:58 | time:547s total_exs:30550 total_steps:30550 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.32     1 34.32  1977       0          0  57.6   50  9.206   .01066 15.78 4.059   1 15.78 908.9       0          0 57.91   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2307         0                30550 50.1 2886 57.63\n",
            "\n",
            "16:11:59 | time:548s total_exs:30600 total_steps:30600 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.02     1 28.02  1598       0          0 57.02   50  9.491   .01059  14.4 4.107   1  14.4 821.2       0          0 60.74   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2514         0                30600 42.42 2419 57.05\n",
            "\n",
            "16:12:00 | time:549s total_exs:30650 total_steps:30650 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "    33.5     1  33.5  1935       0          0 57.75   50  9.063   .01066 17.48  4.51   1 17.48  1009       0          0 90.9   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2265         0                30650 50.98 2944 57.78\n",
            "\n",
            "16:12:01 | time:550s total_exs:30700 total_steps:30700 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.74     1 28.74  1640       0          0 57.06   50  9.257   .01075 17.24 4.227   1 17.24 983.9       0          0 68.49   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2448         0                30700 45.98 2624 57.1\n",
            "\n",
            "16:12:02 | time:551s total_exs:30750 total_steps:30750 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.82     1 28.82  1636       0          0 56.78   50  9.127    .0106 16.18  4.03   1 16.18 918.7       0          0 56.24   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2559         0                30750   45 2555 56.81\n",
            "\n",
            "16:12:03 | time:552s total_exs:30800 total_steps:30800 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.68     1 25.68  1468       0          0 57.16   50  9.561   .01058 13.68 3.779   1 13.68   782       0          0 43.77   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2982         0                30800 39.36 2250 57.19\n",
            "\n",
            "16:12:04 | time:553s total_exs:30850 total_steps:30850 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.08     1 34.08  1951       0          0 57.25   50  8.975   .01069  18.1  4.11   1  18.1  1036       0          0 60.93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2475         0                30850 52.18 2988 57.28\n",
            "\n",
            "16:12:05 | time:554s total_exs:30900 total_steps:30900 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   36.78     1 36.78  2121       0          0 57.67   50   8.74   .01075 17.26 4.345   1 17.26 995.4       0          0 77.06   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2422         0                30900 54.04 3117 57.7\n",
            "\n",
            "16:12:06 | time:555s total_exs:30950 total_steps:30950 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    32.5     1  32.5  1859       0          0  57.2   50  7.986   .01057 18.94 4.133   1 18.94  1083       0          0 62.35   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2460         0                30950 51.44 2943 57.23\n",
            "\n",
            "16:12:06 | time:555s total_exs:31000 total_steps:31000 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.7     1  26.7  1546       0          0 57.91   50   9.96   .01056 14.24 4.311   1 14.24 824.7       0          0 74.51   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2430         0                31000 40.94 2371 57.95\n",
            "\n",
            "16:12:07 | time:556s total_exs:31050 total_steps:31050 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.2     1  26.2  1471       0          0 56.13   50  8.297   .01057  16.2 4.077   1  16.2 909.4       0          0 58.97   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2494         0                31050 42.4 2380 56.16\n",
            "\n",
            "16:12:08 | time:557s total_exs:31100 total_steps:31100 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.06     1 30.06  1703       0          0 56.63   50   8.41   .01057 18.78 4.024   1 18.78  1064       0          0 55.91   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2748         0                31100 48.84 2766 56.67\n",
            "\n",
            "16:12:09 | time:558s total_exs:31150 total_steps:31150 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   34.42     1 34.42  1945       0          0 56.51   50  8.758   .01058 16.72 3.901   1 16.72   945       0          0 49.47   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2715         0                31150 51.14 2890 56.54\n",
            "\n",
            "16:12:10 | time:559s total_exs:31200 total_steps:31200 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.08     1 26.08  1503       0          0 57.63   50  8.982   .01056 16.38 4.233   1 16.38 944.1       0          0 68.93   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2613         0                31200 42.46 2447 57.67\n",
            "\n",
            "16:12:11 | time:560s total_exs:31250 total_steps:31250 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.52     1 33.52  1896       0          0 56.57   50  8.829   .01069 18.26  4.39   1 18.26  1033       0          0 80.67   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2410         0                31250 51.78 2929 56.6\n",
            "\n",
            "16:12:12 | time:561s total_exs:31300 total_steps:31300 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.22     1 26.22  1499       0          0 57.16   50   10.3   .01055 16.36 4.267   1 16.36 935.1       0          0 71.32   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2298         0                31300 42.58 2434 57.19\n",
            "\n",
            "16:12:13 | time:562s total_exs:31350 total_steps:31350 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.74     1 33.74  1904       0          0 56.43   50  8.893   .01067 17.96 4.481   1 17.96  1014       0          0 88.32   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2283         0                31350 51.7 2918 56.46\n",
            "\n",
            "16:12:14 | time:563s total_exs:31400 total_steps:31400 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.28     1 29.28  1680       0          0 57.39   50  9.916   .01058 14.66 4.016   1 14.66 841.4       0          0 55.47   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2497         0                31400 43.94 2522 57.42\n",
            "\n",
            "16:12:14 | time:563s total_exs:31450 total_steps:31450 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.46     1 31.46  1803       0          0 57.29   50  10.03   .01058 14.04  4.25   1 14.04 804.5       0          0 70.12   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2450         0                31450 45.5 2607 57.33\n",
            "\n",
            "16:12:15 | time:564s total_exs:31500 total_steps:31500 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   40.28     1 40.28  2317       0          0 57.53   50  8.223   .01067 18.32 4.537   1 18.32  1054       0          0 93.39   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2162         0                31500 58.6 3372 57.56\n",
            "\n",
            "16:12:16 | time:565s total_exs:31550 total_steps:31550 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.42     1 31.42  1795       0          0 57.12   50  9.496    .0106  14.6 4.131   1  14.6   834       0          0 62.25   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2685         0                31550 46.02 2629 57.15\n",
            "\n",
            "16:12:17 | time:566s total_exs:31600 total_steps:31600 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.52     1 29.52  1676       0          0 56.76   50  8.879   .01067 16.46 4.405   1 16.46 934.4       0          0 81.86   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2467         0                31600 45.98 2610 56.79\n",
            "\n",
            "16:12:18 | time:567s total_exs:31650 total_steps:31650 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   38.38     1 38.38  2173       0          0 56.62   50  8.911   .01081 17.74 4.458   1 17.74  1004       0          0 86.31   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2311         0                31650 56.12 3178 56.65\n",
            "\n",
            "16:12:19 | time:568s total_exs:31700 total_steps:31700 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.28     1 33.28  1906       0          0 57.28   50  9.454   .01062 16.98 4.276   1 16.98 972.6       0          0 71.95   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2473         0                31700 50.26 2879 57.31\n",
            "\n",
            "16:12:20 | time:569s total_exs:31750 total_steps:31750 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.76     1 25.76  1459       0          0 56.63   50  8.824   .01056 15.64 4.082   1 15.64 885.7       0          0 59.27   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2737         0                31750 41.4 2345 56.66\n",
            "\n",
            "16:12:21 | time:570s total_exs:31800 total_steps:31800 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   27.88     1 27.88  1599       0          0 57.34   50  10.14    .0106 15.56 4.174   1 15.56 892.3       0          0 64.99   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2301         0                31800 43.44 2491 57.37\n",
            "\n",
            "16:12:22 | time:571s total_exs:31850 total_steps:31850 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.72     1 30.72  1746       0          0 56.84   50  9.438   .01056 14.82 4.184   1 14.82 842.5       0          0 65.62   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2470         0                31850 45.54 2589 56.87\n",
            "\n",
            "16:12:22 | time:571s total_exs:31900 total_steps:31900 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.46     1 37.46  2127       0          0 56.78   50  9.306   .01071 16.54 4.362   1 16.54 939.1       0          0 78.38   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2261         0                31900   54 3066 56.81\n",
            "\n",
            "16:12:23 | time:572s total_exs:31950 total_steps:31950 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.1     1  33.1  1868       0          0 56.42   50   8.97   .01063 16.42 4.147   1 16.42 926.5       0          0 63.25   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2448         0                31950 49.52 2794 56.45\n",
            "\n",
            "16:12:24 | time:573s total_exs:32000 total_steps:32000 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.14     1 31.14  1767       0          0 56.73   50  9.679   .01068 16.88 4.224   1 16.88 957.7       0          0 68.33   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2192         0                32000 48.02 2724 56.76\n",
            "\n",
            "16:12:25 | time:574s total_exs:32050 total_steps:32050 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.46     1 26.46  1502       0          0 56.75   50  9.978   .01058 15.14 3.862   1 15.14 859.2       0          0 47.56   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2827     .0200                32050 41.6 2361 56.78\n",
            "\n",
            "16:12:26 | time:575s total_exs:32100 total_steps:32100 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   25.88     1 25.88  1450       0          0 56.03   50  9.981   .01057 13.24 4.168   1 13.24 741.9       0          0 64.58   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2492         0                32100 39.12 2192 56.06\n",
            "\n",
            "16:12:27 | time:576s total_exs:32150 total_steps:32150 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   28.78     1 28.78  1634       0          0 56.76   50  8.308   .01061  19.8 4.397   1  19.8  1124       0          0 81.22   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2182         0                32150 48.58 2757 56.79\n",
            "\n",
            "16:12:28 | time:577s total_exs:32200 total_steps:32200 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.68     1 32.68  1868       0          0 57.15   50   9.64   .01065 16.68 4.218   1 16.68 953.4       0          0 67.91   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2446         0                32200 49.36 2822 57.19\n",
            "\n",
            "16:12:29 | time:578s total_exs:32250 total_steps:32250 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.78     1 31.78  1793       0          0 56.42   50  9.125   .01063  17.2 4.232   1  17.2 970.5       0          0 68.83   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2640         0                32250 48.98 2764 56.45\n",
            "\n",
            "16:12:30 | time:579s total_exs:32300 total_steps:32300 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.74     1 33.74  1938       0          0 57.42   50   9.13   .01068 22.04 4.769   1 22.04  1266       0          0 117.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .1951         0                32300 55.78 3203 57.45\n",
            "\n",
            "16:12:31 | time:580s total_exs:32350 total_steps:32350 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   33.36     1 33.36  1901       0          0 56.98   50  8.517   .01062 19.06  4.31   1 19.06  1086       0          0 74.43   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2277         0                32350 52.42 2987 57.02\n",
            "\n",
            "16:12:31 | time:580s total_exs:32400 total_steps:32400 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.78     1 26.78  1541       0          0 57.53   50  10.22   .01057 14.18  4.24   1 14.18 815.8       0          0 69.41   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2539         0                32400 40.96 2357 57.57\n",
            "\n",
            "16:12:32 | time:581s total_exs:32450 total_steps:32450 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    34.9     1  34.9  2003       0          0 57.38   50  8.784   .01059 15.98  3.85   1 15.98 917.1       0          0 46.97   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2603         0                32450 50.88 2920 57.41\n",
            "\n",
            "16:12:33 | time:582s total_exs:32500 total_steps:32500 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.18     1 28.18  1634       0          0 57.96   50  8.464   .01058 17.98 3.791   1 17.98  1043       0          0 44.3   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .3070         0                32500 46.16 2677 58.03\n",
            "\n",
            "16:12:34 | time:583s total_exs:32550 total_steps:32550 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.38     1 30.38  1751       0          0 57.64   50   8.88   .01059  17.1 4.266   1  17.1 985.7       0          0 71.26   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2211         0                32550 47.48 2737 57.67\n",
            "\n",
            "16:12:35 | time:584s total_exs:32600 total_steps:32600 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.52     1 26.52  1543       0          0 58.18   50  8.907   .01058  14.4 4.006   1  14.4 837.9       0          0 54.95   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2750         0                32600 40.92 2381 58.21\n",
            "\n",
            "16:12:36 | time:585s total_exs:32650 total_steps:32650 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.7     1  26.7  1530       0          0 57.29   50  9.083   .01055  14.9 4.076   1  14.9 853.6       0          0 58.88   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2510         0                32650 41.6 2383 57.32\n",
            "\n",
            "16:12:37 | time:586s total_exs:32700 total_steps:32700 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.78     1 31.78  1837       0          0  57.8   50  8.836   .01062 17.98 4.239   1 17.98  1039       0          0 69.35   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2614         0                32700 49.76 2876 57.83\n",
            "\n",
            "16:12:38 | time:587s total_exs:32750 total_steps:32750 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.34     1 32.34  1820       0          0 56.27   50  8.795   .01064 15.92 4.148   1 15.92 895.8       0          0 63.33   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps  ups  \n",
            "        .2538         0                32750 48.26 2716 56.3\n",
            "\n",
            "16:12:39 | time:587s total_exs:32800 total_steps:32800 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   26.78     1 26.78  1533       0          0 57.25   50  9.039    .0106 15.84 4.156   1 15.84   907       0          0 63.8   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2475         0                32800 42.62 2440 57.28\n",
            "\n",
            "16:12:40 | time:589s total_exs:32850 total_steps:32850 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   26.76     1 26.76  1256       0          0 46.92   50  8.684   .01056  15.3   4.3   1  15.3 717.9       0          0 73.67   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2405         0                32850 42.06 1973 46.94\n",
            "\n",
            "16:12:41 | time:590s total_exs:32900 total_steps:32900 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.18     1 29.18  1223       0          0 41.92   50  8.881    .0106 17.36 4.144   1 17.36 727.8       0          0 63.04   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2650         0                32900 46.54 1951 41.94\n",
            "\n",
            "16:12:42 | time:591s total_exs:32950 total_steps:32950 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   29.94     1 29.94  1720       0          0 57.43   50  9.383   .01063    17 4.171   1    17 976.3       0          0 64.79   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2424         0                32950 46.94 2696 57.46\n",
            "\n",
            "16:12:43 | time:592s total_exs:33000 total_steps:33000 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "      35     1    35  2034       0          0 58.11   50  8.905   .01066 16.92 4.266   1 16.92 983.2       0          0 71.25   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2494         0                33000 51.92 3017 58.15\n",
            "\n",
            "16:12:43 | time:592s total_exs:33050 total_steps:33050 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   35.18     1 35.18  2059       0          0 58.53   50  9.467   .01071 16.86 4.282   1 16.86 986.9       0          0 72.39   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2432         0                33050 52.04 3046 58.56\n",
            "\n",
            "16:12:44 | time:593s total_exs:33100 total_steps:33100 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    33.4     1  33.4  1927       0          0 57.69   50  8.635   .01068  17.1 4.339   1  17.1 986.6       0          0 76.63   \n",
            "    token_acc  token_em  total_train_updates  tpb  tps   ups  \n",
            "        .2269         0                33100 50.5 2914 57.72\n",
            "\n",
            "16:12:45 | time:594s total_exs:33150 total_steps:33150 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   37.12     1 37.12  2139       0          0 57.63   50  8.054   .01061 19.04  4.38   1 19.04  1097       0          0 79.81   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2689         0                33150 56.16 3237 57.66\n",
            "\n",
            "16:12:46 | time:595s total_exs:33200 total_steps:33200 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   32.06     1 32.06  1854       0          0 57.83   50  8.961   .01075  15.4 4.062   1  15.4 890.7       0          0 58.12   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2753         0                33200 47.46 2745 57.86\n",
            "\n",
            "16:12:47 | time:596s total_exs:33250 total_steps:33250 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    23.7     1  23.7  1349       0          0 56.92   50  10.33   .01054 12.54 3.987   1 12.54 713.8       0          0 53.88   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2967         0                33250 36.24 2063 56.95\n",
            "\n",
            "16:12:48 | time:597s total_exs:33300 total_steps:33300 epochs:0.52\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   31.76     1 31.76  1806       0          0 56.85   50  8.433   .01065 17.82 4.512   1 17.82  1013       0          0 91.15   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2301         0                33300 49.58 2819 56.88\n",
            "\n",
            "16:12:49 | time:598s total_exs:33350 total_steps:33350 epochs:0.52\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "    26.1     1  26.1  1501       0          0 57.51   50   8.93   .01063 17.32 4.395   1 17.32 996.2       0          0 81.07   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2344         0                33350 43.42 2497 57.55\n",
            "\n",
            "16:12:50 | time:599s total_exs:33400 total_steps:33400 epochs:0.52\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   28.18     1 28.18  1615       0          0 57.31   50  9.235   .01058 16.24 4.403   1 16.24 930.7       0          0 81.7   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2291         0                33400 44.42 2546 57.34\n",
            "\n",
            "16:12:50 | time:599s total_exs:33450 total_steps:33450 epochs:0.52\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   30.14     1 30.14  1733       0          0 57.48   50   7.99   .01062 19.24 4.513   1 19.24  1106       0          0 91.23   \n",
            "    token_acc  token_em  total_train_updates   tpb  tps   ups  \n",
            "        .2183         0                33450 49.38 2839 57.52\n",
            "\n",
            "16:12:51 | max_train_time elapsed:600.0017471313477s\n",
            "16:12:51 | Using CUDA\n",
            "16:12:51 | loading dictionary from from_scratch_model/model.dict\n",
            "16:12:51 | num words = 22419\n",
            "16:13:07 | Initialized embeddings for 16270 tokens (72.6%) from fasttext.\n",
            "16:13:07 | Total parameters: 10,235,700 (9,621,300 trainable)\n",
            "16:13:07 | Loading existing model params from from_scratch_model/model\n",
            "16:13:07 | creating task(s): empathetic_dialogues\n",
            "16:13:08 | running eval: valid\n",
            "16:31:50 | eval completed in 1122.58s\n",
            "16:31:50 | \u001b[1mvalid:\n",
            "    accuracy  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gen_n_toks  gpu_mem  llen  loss  lr  ltpb  ltps  \\\n",
            "           0 .002013 39.52 39.52   202       0          0 5.112 5738 .1195       60.81  .003455 15.65 4.107   1 15.65 80.01   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates   tpb  tps  \n",
            "         0          0 60.77      .2554         0                33480 55.17  282\n",
            "\u001b[0m\n",
            "16:31:50 | creating task(s): empathetic_dialogues\n",
            "16:31:51 | running eval: test\n",
            "16:50:06 | eval completed in 1095.52s\n",
            "16:50:06 | \u001b[1mtest:\n",
            "    accuracy  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gen_n_toks  gpu_mem  llen  loss  lr  ltpb  ltps  \\\n",
            "           0 .002045 42.71 42.71   205       0          0 4.801 5259 .1172       65.19  .003459 15.85 4.133   1 15.85  76.1   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates   tpb   tps  \n",
            "         0          0 62.37      .2545         0                33480 58.56 281.1\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy': ExactMatchMetric(0),\n",
              "  'bleu-4': BleuMetric(0.002013),\n",
              "  'clen': AverageMetric(39.52),\n",
              "  'ctpb': GlobalAverageMetric(39.52),\n",
              "  'ctps': GlobalTimerMetric(202),\n",
              "  'ctrunc': AverageMetric(0),\n",
              "  'ctrunclen': AverageMetric(0),\n",
              "  'exps': GlobalTimerMetric(5.112),\n",
              "  'exs': SumMetric(5738),\n",
              "  'f1': F1Metric(0.1195),\n",
              "  'gen_n_toks': AverageMetric(60.81),\n",
              "  'gpu_mem': GlobalAverageMetric(0.003455),\n",
              "  'llen': AverageMetric(15.65),\n",
              "  'loss': AverageMetric(4.107),\n",
              "  'lr': GlobalAverageMetric(1),\n",
              "  'ltpb': GlobalAverageMetric(15.65),\n",
              "  'ltps': GlobalTimerMetric(80.01),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'ppl': PPLMetric(60.77),\n",
              "  'token_acc': AverageMetric(0.2554),\n",
              "  'token_em': AverageMetric(0),\n",
              "  'total_train_updates': GlobalFixedMetric(3.348e+04),\n",
              "  'tpb': GlobalAverageMetric(55.17),\n",
              "  'tps': GlobalTimerMetric(282)},\n",
              " {'accuracy': ExactMatchMetric(0),\n",
              "  'bleu-4': BleuMetric(0.002045),\n",
              "  'clen': AverageMetric(42.71),\n",
              "  'ctpb': GlobalAverageMetric(42.71),\n",
              "  'ctps': GlobalTimerMetric(205),\n",
              "  'ctrunc': AverageMetric(0),\n",
              "  'ctrunclen': AverageMetric(0),\n",
              "  'exps': GlobalTimerMetric(4.801),\n",
              "  'exs': SumMetric(5259),\n",
              "  'f1': F1Metric(0.1172),\n",
              "  'gen_n_toks': AverageMetric(65.19),\n",
              "  'gpu_mem': GlobalAverageMetric(0.003459),\n",
              "  'llen': AverageMetric(15.85),\n",
              "  'loss': AverageMetric(4.133),\n",
              "  'lr': GlobalAverageMetric(1),\n",
              "  'ltpb': GlobalAverageMetric(15.85),\n",
              "  'ltps': GlobalTimerMetric(76.1),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'ppl': PPLMetric(62.37),\n",
              "  'token_acc': AverageMetric(0.2545),\n",
              "  'token_em': AverageMetric(0),\n",
              "  'total_train_updates': GlobalFixedMetric(3.348e+04),\n",
              "  'tpb': GlobalAverageMetric(58.56),\n",
              "  'tps': GlobalTimerMetric(281.1)})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./ED_transformer.zip ./from_scratch_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUTDE_-J2Bgl",
        "outputId": "b4918fde-5469-47e6-9580-b9e4004ba21b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: from_scratch_model/ (stored 0%)\n",
            "  adding: from_scratch_model/model.valid (deflated 46%)\n",
            "  adding: from_scratch_model/model.trainstats (deflated 82%)\n",
            "  adding: from_scratch_model/model.test (deflated 46%)\n",
            "  adding: from_scratch_model/model (deflated 8%)\n",
            "  adding: from_scratch_model/model.dict.opt (deflated 67%)\n",
            "  adding: from_scratch_model/model.dict (deflated 59%)\n",
            "  adding: from_scratch_model/model.opt (deflated 66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "isHsye4k2PIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#zoo:blended_skill_talk/multi_task_bst_tuned/model"
      ],
      "metadata": {
        "id": "suCbSWnDAq0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf fine_tune_personachat\n",
        "!mkdir -p fine_tune_personachat"
      ],
      "metadata": {
        "id": "ZcKPrzQ7RNLU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf from_pretrained\n",
        "!mkdir -p from_pretrained"
      ],
      "metadata": {
        "id": "QQCXox-LdoMT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improvement using transfer learning\n",
        "TrainModel.main(\n",
        "    # similar to before\n",
        "    task='personachat', \n",
        "    datapath='./data',\n",
        "\n",
        "    # model argument\n",
        "    model='transformer/polyencoder',\n",
        "    model_file='from_pretrained/model',\n",
        "\n",
        "    max_train_time=60*3, \n",
        "    batchsize=64, eval_batchsize=10,\n",
        "    warmup_updates=100, lr_scheduler_patience=0,\n",
        "    lr_scheduler_decay=0.4,\n",
        "\n",
        "    lr=5e-05, data_parallel=True, history_size=20, \n",
        "    \n",
        "    candidates='batch',\n",
        "    eval_candidates='batch',\n",
        "    optimizer='adamax',\n",
        "    output_scaling=0.06,\n",
        "\n",
        "    variant='xlm',\n",
        "    reduction_type='mean',\n",
        "    share_encoders=False,\n",
        "\n",
        "    attention_dropout=0.1,\n",
        "    relu_dropout=0.0,\n",
        "    dropout=0.1,\n",
        "\n",
        "    activation='gelu',\n",
        "    polyencoder_type='n_first',\n",
        "\n",
        "\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model='zoo:pretrained_transformers/poly_model_huge_reddit/model', # which pretrained model you want to use\n",
        "    dict_file = 'zoo:pretrained_transformers/poly_model_huge_reddit/model.dict', # where to find the pretrained model dictionary\n",
        "\n",
        "\n",
        "    label_truncate=72,\n",
        "    text_truncate=360,\n",
        "    fp16=True,\n",
        "    dict_tokenizer='bpe',\n",
        "    dict_lower=True,\n",
        "\n",
        "    validation_metric='accuracy',\n",
        "    validation_metric_mode='max',\n",
        "  \n",
        "    learn_positional_embeddings=True,\n",
        "    n_layers=12, n_heads=12, ffn_size=3072,\n",
        "    embedding_size=768,\n",
        "    n_positions=1024,\n",
        "    learn_embeddings=True,\n",
        "    embeddings_scale=False,\n",
        "    n_segments=2,\n",
        "    poly_n_codes=64,\n",
        "    poly_attention_type='basic',\n",
        "    dict_endtoken='__start__'\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UgIYRdL2PuA",
        "outputId": "703c51a0-7754-433c-f47f-93adf28dd045"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:59:52 | building dictionary first...\n",
            "17:59:52 | No model with opt yet at: from_pretrained/model(.opt)\n",
            "17:59:52 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: None,verbose: False,is_debug: False,datapath: ./data,evaltask: None,final_extra_opt: ,eval_batchsize: 10,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 180.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: -1,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: False,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 10,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,load_from_checkpoint: True,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: -1,mutators: None,interactive_mode: False,fp16_impl: safe,force_fp16_tokens: False,adam_eps: 1e-08,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,invsqrt_lr_decay_gamma: -1,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None\u001b[0m\n",
            "17:59:52 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task convai2 --numthreads 1 --batchsize 2 --single-turn False --rank-candidates True --eval-candidates inline --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
            "17:59:52 | Using CUDA\n",
            "17:59:52 | loading dictionary from ./data/models/pretrained_transformers/poly_model_huge_reddit/model.dict\n",
            "17:59:52 | num words = 54944\n",
            "17:59:56 | Total parameters: 256,081,920 (256,081,920 trainable)\n",
            "17:59:57 | Loading existing model parameters from ./data/models/pretrained_transformers/poly_model_huge_reddit/model\n",
            "17:59:57 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n",
            "17:59:57 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n",
            "17:59:58 | Opt:\n",
            "17:59:58 |     activation: gelu\n",
            "17:59:58 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "17:59:58 |     adam_eps: 1e-08\n",
            "17:59:58 |     add_p1_after_newln: False\n",
            "17:59:58 |     aggregate_micro: False\n",
            "17:59:58 |     allow_missing_init_opts: False\n",
            "17:59:58 |     attention_dropout: 0.1\n",
            "17:59:58 |     batchsize: 256\n",
            "17:59:58 |     betas: '(0.9, 0.999)'\n",
            "17:59:58 |     bpe_add_prefix_space: None\n",
            "17:59:58 |     bpe_debug: False\n",
            "17:59:58 |     bpe_dropout: None\n",
            "17:59:58 |     bpe_merge: None\n",
            "17:59:58 |     bpe_vocab: None\n",
            "17:59:58 |     candidates: batch\n",
            "17:59:58 |     cap_num_predictions: 100\n",
            "17:59:58 |     checkpoint_activations: False\n",
            "17:59:58 |     codes_attention_num_heads: 4\n",
            "17:59:58 |     codes_attention_type: basic\n",
            "17:59:58 |     data_parallel: True\n",
            "17:59:58 |     datapath: ./data\n",
            "17:59:58 |     datatype: train\n",
            "17:59:58 |     delimiter: '\\n'\n",
            "17:59:58 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "17:59:58 |     dict_endtoken: __start__\n",
            "17:59:58 |     dict_file: ./data/models/pretrained_transformers/poly_model_huge_reddit/model.dict\n",
            "17:59:58 |     dict_include_test: False\n",
            "17:59:58 |     dict_include_valid: False\n",
            "17:59:58 |     dict_initpath: None\n",
            "17:59:58 |     dict_language: english\n",
            "17:59:58 |     dict_loaded: True\n",
            "17:59:58 |     dict_lower: True\n",
            "17:59:58 |     dict_max_ngram_size: -1\n",
            "17:59:58 |     dict_maxexs: -1\n",
            "17:59:58 |     dict_maxtokens: -1\n",
            "17:59:58 |     dict_minfreq: 0\n",
            "17:59:58 |     dict_nulltoken: __null__\n",
            "17:59:58 |     dict_starttoken: __start__\n",
            "17:59:58 |     dict_textfields: text,labels\n",
            "17:59:58 |     dict_tokenizer: bpe\n",
            "17:59:58 |     dict_unktoken: __unk__\n",
            "17:59:58 |     display_examples: False\n",
            "17:59:58 |     download_path: None\n",
            "17:59:58 |     dropout: 0.1\n",
            "17:59:58 |     dynamic_batching: None\n",
            "17:59:58 |     embedding_projection: random\n",
            "17:59:58 |     embedding_size: 768\n",
            "17:59:58 |     embedding_type: random\n",
            "17:59:58 |     embeddings_scale: False\n",
            "17:59:58 |     encode_candidate_vecs: True\n",
            "17:59:58 |     encode_candidate_vecs_batchsize: 256\n",
            "17:59:58 |     eval_batchsize: 10\n",
            "17:59:58 |     eval_candidates: batch\n",
            "17:59:58 |     eval_dynamic_batching: None\n",
            "17:59:58 |     evaltask: None\n",
            "17:59:58 |     ffn_size: 3072\n",
            "17:59:58 |     final_extra_opt: \n",
            "17:59:58 |     fixed_candidate_vecs: reuse\n",
            "17:59:58 |     fixed_candidates_path: None\n",
            "17:59:58 |     force_fp16_tokens: False\n",
            "17:59:58 |     fp16: True\n",
            "17:59:58 |     fp16_impl: safe\n",
            "17:59:58 |     gpu: -1\n",
            "17:59:58 |     gradient_clip: 0.1\n",
            "17:59:58 |     hide_labels: False\n",
            "17:59:58 |     history_add_global_end_token: None\n",
            "17:59:58 |     history_reversed: False\n",
            "17:59:58 |     history_size: 20\n",
            "17:59:58 |     ignore_bad_candidates: False\n",
            "17:59:58 |     image_cropsize: 224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:59:58 |     image_mode: raw\n",
            "17:59:58 |     image_size: 256\n",
            "17:59:58 |     inference: max\n",
            "17:59:58 |     init_model: ./data/models/pretrained_transformers/poly_model_huge_reddit/model\n",
            "17:59:58 |     init_opt: None\n",
            "17:59:58 |     interactive_candidates: fixed\n",
            "17:59:58 |     interactive_mode: False\n",
            "17:59:58 |     invsqrt_lr_decay_gamma: -1\n",
            "17:59:58 |     is_debug: False\n",
            "17:59:58 |     label_truncate: 72\n",
            "17:59:58 |     learn_embeddings: True\n",
            "17:59:58 |     learn_positional_embeddings: True\n",
            "17:59:58 |     learningrate: 5e-05\n",
            "17:59:58 |     load_from_checkpoint: True\n",
            "17:59:58 |     log_every_n_secs: -1\n",
            "17:59:58 |     log_every_n_steps: 50\n",
            "17:59:58 |     log_keep_fields: all\n",
            "17:59:58 |     loglevel: info\n",
            "17:59:58 |     lr_scheduler: reduceonplateau\n",
            "17:59:58 |     lr_scheduler_decay: 0.4\n",
            "17:59:58 |     lr_scheduler_patience: 0\n",
            "17:59:58 |     max_train_steps: -1\n",
            "17:59:58 |     max_train_time: 180.0\n",
            "17:59:58 |     memory_attention: sqrt\n",
            "17:59:58 |     metrics: default\n",
            "17:59:58 |     model: transformer/polyencoder\n",
            "17:59:58 |     model_file: from_pretrained/model\n",
            "17:59:58 |     model_parallel: False\n",
            "17:59:58 |     momentum: 0\n",
            "17:59:58 |     multitask_weights: [1]\n",
            "17:59:58 |     mutators: None\n",
            "17:59:58 |     n_decoder_layers: -1\n",
            "17:59:58 |     n_encoder_layers: -1\n",
            "17:59:58 |     n_heads: 12\n",
            "17:59:58 |     n_layers: 12\n",
            "17:59:58 |     n_positions: 1024\n",
            "17:59:58 |     n_segments: 2\n",
            "17:59:58 |     nesterov: True\n",
            "17:59:58 |     no_cuda: False\n",
            "17:59:58 |     normalize_sent_emb: False\n",
            "17:59:58 |     num_epochs: -1\n",
            "17:59:58 |     num_workers: 0\n",
            "17:59:58 |     nus: (0.7,)\n",
            "17:59:58 |     optimizer: adamax\n",
            "17:59:58 |     output_scaling: 0.06\n",
            "17:59:58 |     override: \"{'task': 'personachat', 'datapath': './data', 'model': 'transformer/polyencoder', 'model_file': 'from_pretrained/model', 'max_train_time': 180.0, 'batchsize': 256, 'eval_batchsize': 10, 'warmup_updates': 100, 'lr_scheduler_patience': 0, 'lr_scheduler_decay': 0.4, 'learningrate': 5e-05, 'data_parallel': True, 'history_size': 20, 'candidates': 'batch', 'eval_candidates': 'batch', 'optimizer': 'adamax', 'output_scaling': 0.06, 'variant': 'xlm', 'reduction_type': 'mean', 'share_encoders': False, 'attention_dropout': 0.1, 'relu_dropout': 0.0, 'dropout': 0.1, 'activation': 'gelu', 'polyencoder_type': 'n_first', 'init_model': 'zoo:pretrained_transformers/poly_model_huge_reddit/model', 'dict_file': './data/models/pretrained_transformers/poly_model_huge_reddit/model.dict', 'label_truncate': 72, 'text_truncate': 360, 'fp16': True, 'dict_tokenizer': 'bpe', 'dict_lower': True, 'validation_metric': 'accuracy', 'validation_metric_mode': 'max', 'learn_positional_embeddings': True, 'n_layers': 12, 'n_heads': 12, 'ffn_size': 3072, 'embedding_size': 768, 'n_positions': 1024, 'learn_embeddings': True, 'embeddings_scale': False, 'n_segments': 2, 'poly_n_codes': 64, 'poly_attention_type': 'basic', 'dict_endtoken': '__start__'}\"\n",
            "17:59:58 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "17:59:58 |     person_tokens: False\n",
            "17:59:58 |     poly_attention_num_heads: 4\n",
            "17:59:58 |     poly_attention_type: basic\n",
            "17:59:58 |     poly_n_codes: 64\n",
            "17:59:58 |     polyencoder_type: n_first\n",
            "17:59:58 |     rank_candidates: True\n",
            "17:59:58 |     rank_top_k: -1\n",
            "17:59:58 |     reduction_type: mean\n",
            "17:59:58 |     relu_dropout: 0.0\n",
            "17:59:58 |     repeat_blocking_heuristic: True\n",
            "17:59:58 |     return_cand_scores: False\n",
            "17:59:58 |     save_after_valid: False\n",
            "17:59:58 |     save_every_n_secs: -1\n",
            "17:59:58 |     save_format: conversations\n",
            "17:59:58 |     share_encoders: False\n",
            "17:59:58 |     share_word_embeddings: True\n",
            "17:59:58 |     short_final_eval: False\n",
            "17:59:58 |     special_tok_lst: None\n",
            "17:59:58 |     split_lines: False\n",
            "17:59:58 |     starttime: Jun13_17-59\n",
            "17:59:58 |     task: personachat\n",
            "17:59:58 |     tensorboard_log: False\n",
            "17:59:58 |     tensorboard_logdir: None\n",
            "17:59:58 |     text_truncate: 360\n",
            "17:59:58 |     topk: 5\n",
            "17:59:58 |     train_predict: False\n",
            "17:59:58 |     truncate: 1024\n",
            "17:59:58 |     update_freq: 1\n",
            "17:59:58 |     use_memories: False\n",
            "17:59:58 |     use_reply: label\n",
            "17:59:58 |     validation_cutoff: 1.0\n",
            "17:59:58 |     validation_every_n_epochs: -1\n",
            "17:59:58 |     validation_every_n_secs: -1\n",
            "17:59:58 |     validation_every_n_steps: -1\n",
            "17:59:58 |     validation_max_exs: -1\n",
            "17:59:58 |     validation_metric: accuracy\n",
            "17:59:58 |     validation_metric_mode: max\n",
            "17:59:58 |     validation_patience: 10\n",
            "17:59:58 |     validation_share_agent: False\n",
            "17:59:58 |     variant: xlm\n",
            "17:59:58 |     verbose: False\n",
            "17:59:58 |     wandb_entity: None\n",
            "17:59:58 |     wandb_log: False\n",
            "17:59:58 |     wandb_name: None\n",
            "17:59:58 |     wandb_project: None\n",
            "17:59:58 |     warmup_rate: 0.0001\n",
            "17:59:58 |     warmup_updates: 100\n",
            "17:59:58 |     weight_decay: None\n",
            "17:59:58 |     world_logs: \n",
            "17:59:58 |     wrap_memory_encoder: False\n",
            "17:59:59 | creating task(s): personachat\n",
            "17:59:59 | loading fbdialog data: ./data/Persona-Chat/personachat/train_self_original.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:00:02 | training...\n",
            "18:00:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:03 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:04 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:06 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:06 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:07 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:07 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:09 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:10 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:10 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:10 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:12 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:12 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:14 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:14 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:15 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:15 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:16 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:17 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:17 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:17 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:18 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:20 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:20 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:22 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:24 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:24 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:26 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:26 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:26 | time:25s total_exs:12800 total_steps:50 epochs:0.19\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   144.2 37435 76100       0          0 520.4 12800    .9234 14.31 5e-09  3665  7450       0          0 41100 83550    0\n",
            "\n",
            "18:00:27 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:27 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:28 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:29 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:29 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:31 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:31 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:33 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:33 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:34 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:34 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:35 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:35 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:36 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:36 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:37 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:37 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:39 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:39 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:41 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:41 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:42 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:43 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:43 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:44 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:44 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:45 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:46 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:46 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:46 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:48 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:48 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:49 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:49 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:50 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:50 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:51 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:51 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:52 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:52 | time:50s total_exs:25600 total_steps:100 epochs:0.39\n",
            "    clen  ctpb  ctps   ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   146.8 38081 74789 .0002344     .01039 502.8 12800    .9084 14.19 5e-09  3634  7137       0          0 41715 81926    0\n",
            "\n",
            "18:00:52 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:54 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:54 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:56 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:56 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:57 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:00:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:00 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:00 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:01 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:03 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:03 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:04 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:06 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:06 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:07 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:07 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:09 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:09 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:10 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:10 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:12 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:12 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:14 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:14 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:14 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:15 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:15 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:16 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:16 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:17 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:17 | time:75s total_exs:38400 total_steps:150 epochs:0.58\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   146.9 38120 77459       0          0 520.2 12800    .9083 14.09 5e-09  3608  7332       0          0 41728 84791    0\n",
            "\n",
            "18:01:18 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:18 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:18 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:18 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:20 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:22 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:22 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:24 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:24 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:26 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:26 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:27 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:28 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:28 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:28 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:29 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:31 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:31 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:33 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:33 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:34 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:34 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:35 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:35 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:36 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:36 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:37 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:39 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:41 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:41 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:41 | time:100s total_exs:51200 total_steps:200 epochs:0.78\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   146.3 37974 76792       0          0 517.7 12800    .9083 14.17 5e-09  3627  7335       0          0 41601 84126    0\n",
            "\n",
            "18:01:42 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:42 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:43 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:44 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:44 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:45 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:45 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:45 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:46 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:48 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:48 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:49 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:49 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:50 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:50 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:51 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:52 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:52 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:54 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:56 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:56 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:57 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:01:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:00 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:00 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:01 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:03 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:03 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:03 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:04 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:05 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:06 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:06 | time:124s total_exs:64000 total_steps:250 epochs:0.97\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   146.9 38125 78582       0          0 527.6 12800    .9083 14.16 5e-09  3625  7472       0          0 41750 86054    0\n",
            "\n",
            "18:02:06 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:07 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:08 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:09 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:09 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:10 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:11 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:12 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:12 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:13 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:14 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:15 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:15 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:16 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:16 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:17 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:17 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:18 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:19 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:20 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:21 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:22 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:23 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:24 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:25 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:26 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:26 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:27 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:27 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:28 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:28 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:29 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:29 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:30 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:31 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:31 | time:149s total_exs:76800 total_steps:300 epochs:1.17\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   146.5 38015 77001       0          0 518.5 12800    .9083 14.34 5e-09  3672  7437       0          0 41687 84437    0\n",
            "\n",
            "18:02:31 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:32 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:33 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:33 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:34 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:34 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:35 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:35 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:36 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:37 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:37 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:38 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:39 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:39 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:40 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:41 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:41 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:42 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:42 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:43 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:43 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:44 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:44 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:45 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:45 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:46 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:46 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:47 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:48 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:48 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:49 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:49 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:50 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:50 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:51 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:51 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:52 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:52 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:53 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:54 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:54 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:55 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:56 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:56 | time:174s total_exs:89600 total_steps:350 epochs:1.36\n",
            "    clen  ctpb  ctps    ctrunc  ctrunclen  exps   exs  gpu_mem  llen    lr  ltpb  ltps  ltrunc  ltrunclen   tpb   tps  ups\n",
            "   147.4 38239 76889 7.813e-05    .001719 514.7 12800    .9083  14.3 5e-09  3661  7361       0          0 41900 84250    0\n",
            "\n",
            "18:02:56 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:57 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:57 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:58 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:02:59 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:03:00 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:03:00 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:03:01 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:03:01 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:03:02 | \u001b[31mRan out of memory, skipping batch. if this happens frequently, decrease batchsize or truncate the inputs to the model.\u001b[0m\n",
            "18:03:02 | max_train_time elapsed:180.61031222343445s\n",
            "18:03:02 | Saving dictionary to from_pretrained/model.dict\n",
            "18:03:04 | \u001b[33mOverriding opt[\"init_model\"] to zoo:pretrained_transformers/poly_model_huge_reddit/model (previously: ./data/models/pretrained_transformers/poly_model_huge_reddit/model)\u001b[0m\n",
            "18:03:04 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: None,is_debug: False,evaltask: None,final_extra_opt: ,eval_batchsize: 10,eval_dynamic_batching: None,num_workers: 0,display_examples: False,num_epochs: -1,max_train_time: 180.0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_secs: -1,validation_every_n_steps: -1,save_every_n_secs: -1,save_after_valid: False,validation_every_n_epochs: -1,validation_max_exs: -1,short_final_eval: False,validation_patience: 10,validation_metric: accuracy,validation_metric_mode: max,validation_cutoff: 1.0,validation_share_agent: False,metrics: default,aggregate_micro: False,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_log: False,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,dict_maxexs: -1,dict_include_valid: False,dict_include_test: False,log_every_n_secs: -1,mutators: None,fp16_impl: safe,force_fp16_tokens: True,adam_eps: 1e-08,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,invsqrt_lr_decay_gamma: -1,interactive_candidates: fixed,encode_candidate_vecs_batchsize: 256,rank_top_k: -1,inference: max,topk: 5,return_cand_scores: False,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,dict_loaded: True,datapath: ./data,download_path: None,verbose: False,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
            "18:03:04 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task convai2 --numthreads 1 --batchsize 2 --single-turn False --eval-candidates inline --encode-candidate-vecs False --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
            "18:03:04 | Using CUDA\n",
            "18:03:04 | loading dictionary from from_pretrained/model.dict\n",
            "18:03:04 | num words = 54944\n",
            "18:03:08 | Total parameters: 256,081,920 (256,081,920 trainable)\n",
            "18:03:09 | Loading existing model parameters from from_pretrained/model\n",
            "18:03:10 | creating task(s): personachat\n",
            "18:03:10 | loading fbdialog data: ./data/Persona-Chat/personachat/valid_self_original.txt\n",
            "18:03:10 | running eval: valid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:03:10 | \u001b[33m[ Executing eval mode with batch labels as set of candidates. ]\u001b[0m\n",
            "18:04:36 | \u001b[33m[ Warning: using candidate source 'batch' and observed a batch of size 1. This may be due to uneven batch sizes at the end of an epoch. ]\u001b[0m\n",
            "18:04:37 | eval completed in 86.38s\n",
            "18:04:37 | \u001b[1mvalid:\n",
            "    accuracy  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  \\\n",
            "       .2307   .2308 155.8  1570 14254       0          0 90.34 7801 .3182    .4421   .2307        1         1   .7214 14.35   \n",
            "    loss    lr  ltpb  ltps  ltrunc  ltrunclen   mrr  rank  tpb   tps  \n",
            "   4.727 5e-09 142.8  1297       0          0 .4398  3.95 1713 15551\n",
            "\u001b[0m\n",
            "18:04:37 | creating task(s): personachat\n",
            "18:04:37 | loading fbdialog data: ./data/Persona-Chat/personachat/test_self_original.txt\n",
            "18:04:37 | running eval: test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:05:58 | eval completed in 81.36s\n",
            "18:05:58 | \u001b[1mtest:\n",
            "    accuracy  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gpu_mem  hits@1  hits@10  hits@100  hits@5  llen  \\\n",
            "       .1982   .1988 152.5  1535 14271       0          0 92.36 7512 .2929    .4422   .1982        1         1   .7049 14.24   \n",
            "    loss    lr  ltpb  ltps  ltrunc  ltrunclen   mrr  rank  tpb   tps  \n",
            "   5.247 5e-09 141.5  1315       0          0 .4123 4.124 1677 15586\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy': ExactMatchMetric(0.2307),\n",
              "  'bleu-4': BleuMetric(0.2308),\n",
              "  'clen': AverageMetric(155.8),\n",
              "  'ctpb': GlobalAverageMetric(1570),\n",
              "  'ctps': GlobalTimerMetric(1.425e+04),\n",
              "  'ctrunc': AverageMetric(0),\n",
              "  'ctrunclen': AverageMetric(0),\n",
              "  'exps': GlobalTimerMetric(90.34),\n",
              "  'exs': SumMetric(7801),\n",
              "  'f1': F1Metric(0.3182),\n",
              "  'gpu_mem': GlobalAverageMetric(0.4421),\n",
              "  'hits@1': AverageMetric(0.2307),\n",
              "  'hits@10': AverageMetric(1),\n",
              "  'hits@100': AverageMetric(1),\n",
              "  'hits@5': AverageMetric(0.7214),\n",
              "  'llen': AverageMetric(14.35),\n",
              "  'loss': AverageMetric(4.727),\n",
              "  'lr': GlobalAverageMetric(5e-09),\n",
              "  'ltpb': GlobalAverageMetric(142.8),\n",
              "  'ltps': GlobalTimerMetric(1297),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'mrr': AverageMetric(0.4398),\n",
              "  'rank': AverageMetric(3.95),\n",
              "  'tpb': GlobalAverageMetric(1713),\n",
              "  'tps': GlobalTimerMetric(1.555e+04)},\n",
              " {'accuracy': ExactMatchMetric(0.1982),\n",
              "  'bleu-4': BleuMetric(0.1988),\n",
              "  'clen': AverageMetric(152.5),\n",
              "  'ctpb': GlobalAverageMetric(1535),\n",
              "  'ctps': GlobalTimerMetric(1.427e+04),\n",
              "  'ctrunc': AverageMetric(0),\n",
              "  'ctrunclen': AverageMetric(0),\n",
              "  'exps': GlobalTimerMetric(92.36),\n",
              "  'exs': SumMetric(7512),\n",
              "  'f1': F1Metric(0.2929),\n",
              "  'gpu_mem': GlobalAverageMetric(0.4422),\n",
              "  'hits@1': AverageMetric(0.1982),\n",
              "  'hits@10': AverageMetric(1),\n",
              "  'hits@100': AverageMetric(1),\n",
              "  'hits@5': AverageMetric(0.7049),\n",
              "  'llen': AverageMetric(14.24),\n",
              "  'loss': AverageMetric(5.247),\n",
              "  'lr': GlobalAverageMetric(5e-09),\n",
              "  'ltpb': GlobalAverageMetric(141.5),\n",
              "  'ltps': GlobalTimerMetric(1315),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'mrr': AverageMetric(0.4123),\n",
              "  'rank': AverageMetric(4.124),\n",
              "  'tpb': GlobalAverageMetric(1677),\n",
              "  'tps': GlobalTimerMetric(1.559e+04)})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model prediction"
      ],
      "metadata": {
        "id": "8AOMQIEa2IOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    datapath = './data',\n",
        "    task='personachat',\n",
        "    model_file='/content/from_pretrained/model',\n",
        "    num_examples=10,\n",
        "   # skip_generation=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_R-8EuJ2KuH",
        "outputId": "507134e5-c764-4fe9-8d8d-9c067216e941"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:11:27 | \u001b[33mOverriding opt[\"model_file\"] to /content/from_pretrained/model (previously: from_pretrained/model)\u001b[0m\n",
            "18:11:27 | Using CUDA\n",
            "18:11:27 | loading dictionary from /content/from_pretrained/model.dict\n",
            "18:11:27 | num words = 54944\n",
            "18:11:32 | Total parameters: 256,081,920 (256,081,920 trainable)\n",
            "18:11:32 | Loading existing model parameters from /content/from_pretrained/model\n",
            "18:11:33 | creating task(s): personachat\n",
            "18:11:33 | loading fbdialog data: ./data/Persona-Chat/personachat/valid_self_original.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:11:35 | Opt:\n",
            "18:11:35 |     activation: gelu\n",
            "18:11:35 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "18:11:35 |     adam_eps: 1e-08\n",
            "18:11:35 |     add_p1_after_newln: False\n",
            "18:11:35 |     aggregate_micro: False\n",
            "18:11:35 |     allow_missing_init_opts: False\n",
            "18:11:35 |     attention_dropout: 0.1\n",
            "18:11:35 |     batchsize: 256\n",
            "18:11:35 |     betas: '[0.9, 0.999]'\n",
            "18:11:35 |     bpe_add_prefix_space: None\n",
            "18:11:35 |     bpe_debug: False\n",
            "18:11:35 |     bpe_dropout: None\n",
            "18:11:35 |     bpe_merge: None\n",
            "18:11:35 |     bpe_vocab: None\n",
            "18:11:35 |     candidates: batch\n",
            "18:11:35 |     cap_num_predictions: 100\n",
            "18:11:35 |     checkpoint_activations: False\n",
            "18:11:35 |     codes_attention_num_heads: 4\n",
            "18:11:35 |     codes_attention_type: basic\n",
            "18:11:35 |     data_parallel: True\n",
            "18:11:35 |     datapath: ./data\n",
            "18:11:35 |     datatype: train\n",
            "18:11:35 |     delimiter: '\\n'\n",
            "18:11:35 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "18:11:35 |     dict_endtoken: __start__\n",
            "18:11:35 |     dict_file: /content/from_pretrained/model.dict\n",
            "18:11:35 |     dict_include_test: False\n",
            "18:11:35 |     dict_include_valid: False\n",
            "18:11:35 |     dict_initpath: None\n",
            "18:11:35 |     dict_language: english\n",
            "18:11:35 |     dict_loaded: True\n",
            "18:11:35 |     dict_lower: True\n",
            "18:11:35 |     dict_max_ngram_size: -1\n",
            "18:11:35 |     dict_maxexs: -1\n",
            "18:11:35 |     dict_maxtokens: -1\n",
            "18:11:35 |     dict_minfreq: 0\n",
            "18:11:35 |     dict_nulltoken: __null__\n",
            "18:11:35 |     dict_starttoken: __start__\n",
            "18:11:35 |     dict_textfields: text,labels\n",
            "18:11:35 |     dict_tokenizer: bpe\n",
            "18:11:35 |     dict_unktoken: __unk__\n",
            "18:11:35 |     display_add_fields: \n",
            "18:11:35 |     display_examples: False\n",
            "18:11:35 |     download_path: None\n",
            "18:11:35 |     dropout: 0.1\n",
            "18:11:35 |     dynamic_batching: None\n",
            "18:11:35 |     embedding_projection: random\n",
            "18:11:35 |     embedding_size: 768\n",
            "18:11:35 |     embedding_type: random\n",
            "18:11:35 |     embeddings_scale: False\n",
            "18:11:35 |     encode_candidate_vecs: True\n",
            "18:11:35 |     encode_candidate_vecs_batchsize: 256\n",
            "18:11:35 |     eval_batchsize: 10\n",
            "18:11:35 |     eval_candidates: batch\n",
            "18:11:35 |     eval_dynamic_batching: None\n",
            "18:11:35 |     evaltask: None\n",
            "18:11:35 |     ffn_size: 3072\n",
            "18:11:35 |     final_extra_opt: \n",
            "18:11:35 |     fixed_candidate_vecs: reuse\n",
            "18:11:35 |     fixed_candidates_path: None\n",
            "18:11:35 |     force_fp16_tokens: True\n",
            "18:11:35 |     fp16: True\n",
            "18:11:35 |     fp16_impl: safe\n",
            "18:11:35 |     gpu: -1\n",
            "18:11:35 |     gradient_clip: 0.1\n",
            "18:11:35 |     hide_labels: False\n",
            "18:11:35 |     history_add_global_end_token: None\n",
            "18:11:35 |     history_reversed: False\n",
            "18:11:35 |     history_size: 20\n",
            "18:11:35 |     ignore_bad_candidates: False\n",
            "18:11:35 |     image_cropsize: 224\n",
            "18:11:35 |     image_mode: raw\n",
            "18:11:35 |     image_size: 256\n",
            "18:11:35 |     inference: max\n",
            "18:11:35 |     init_model: ./data/models/pretrained_transformers/poly_model_huge_reddit/model\n",
            "18:11:35 |     init_opt: None\n",
            "18:11:35 |     interactive_candidates: fixed\n",
            "18:11:35 |     interactive_mode: False\n",
            "18:11:35 |     invsqrt_lr_decay_gamma: -1\n",
            "18:11:35 |     is_debug: False\n",
            "18:11:35 |     label_truncate: 72\n",
            "18:11:35 |     learn_embeddings: True\n",
            "18:11:35 |     learn_positional_embeddings: True\n",
            "18:11:35 |     learningrate: 5e-05\n",
            "18:11:35 |     log_every_n_secs: -1\n",
            "18:11:35 |     log_every_n_steps: 50\n",
            "18:11:35 |     log_keep_fields: all\n",
            "18:11:35 |     loglevel: info\n",
            "18:11:35 |     lr_scheduler: reduceonplateau\n",
            "18:11:35 |     lr_scheduler_decay: 0.4\n",
            "18:11:35 |     lr_scheduler_patience: 0\n",
            "18:11:35 |     max_train_steps: -1\n",
            "18:11:35 |     max_train_time: 180.0\n",
            "18:11:35 |     memory_attention: sqrt\n",
            "18:11:35 |     metrics: default\n",
            "18:11:35 |     model: transformer/polyencoder\n",
            "18:11:35 |     model_file: /content/from_pretrained/model\n",
            "18:11:35 |     model_parallel: False\n",
            "18:11:35 |     momentum: 0\n",
            "18:11:35 |     multitask_weights: [1]\n",
            "18:11:35 |     mutators: None\n",
            "18:11:35 |     n_decoder_layers: -1\n",
            "18:11:35 |     n_encoder_layers: -1\n",
            "18:11:35 |     n_heads: 12\n",
            "18:11:35 |     n_layers: 12\n",
            "18:11:35 |     n_positions: 1024\n",
            "18:11:35 |     n_segments: 2\n",
            "18:11:35 |     nesterov: True\n",
            "18:11:35 |     no_cuda: False\n",
            "18:11:35 |     normalize_sent_emb: False\n",
            "18:11:35 |     num_epochs: -1\n",
            "18:11:35 |     num_examples: 10\n",
            "18:11:35 |     num_workers: 0\n",
            "18:11:35 |     nus: [0.7]\n",
            "18:11:35 |     optimizer: adamax\n",
            "18:11:35 |     output_scaling: 0.06\n",
            "18:11:35 |     override: \"{'datapath': './data', 'task': 'personachat', 'model_file': '/content/from_pretrained/model', 'num_examples': '10'}\"\n",
            "18:11:35 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "18:11:35 |     person_tokens: False\n",
            "18:11:35 |     poly_attention_num_heads: 4\n",
            "18:11:35 |     poly_attention_type: basic\n",
            "18:11:35 |     poly_n_codes: 64\n",
            "18:11:35 |     polyencoder_type: n_first\n",
            "18:11:35 |     rank_candidates: True\n",
            "18:11:35 |     rank_top_k: -1\n",
            "18:11:35 |     reduction_type: mean\n",
            "18:11:35 |     relu_dropout: 0.0\n",
            "18:11:35 |     repeat_blocking_heuristic: True\n",
            "18:11:35 |     return_cand_scores: False\n",
            "18:11:35 |     save_after_valid: False\n",
            "18:11:35 |     save_every_n_secs: -1\n",
            "18:11:35 |     save_format: conversations\n",
            "18:11:35 |     share_encoders: False\n",
            "18:11:35 |     share_word_embeddings: True\n",
            "18:11:35 |     short_final_eval: False\n",
            "18:11:35 |     special_tok_lst: None\n",
            "18:11:35 |     split_lines: False\n",
            "18:11:35 |     starttime: Jun13_17-59\n",
            "18:11:35 |     task: personachat\n",
            "18:11:35 |     tensorboard_log: False\n",
            "18:11:35 |     tensorboard_logdir: None\n",
            "18:11:35 |     text_truncate: 360\n",
            "18:11:35 |     topk: 5\n",
            "18:11:35 |     train_predict: False\n",
            "18:11:35 |     truncate: 1024\n",
            "18:11:35 |     update_freq: 1\n",
            "18:11:35 |     use_memories: False\n",
            "18:11:35 |     use_reply: label\n",
            "18:11:35 |     validation_cutoff: 1.0\n",
            "18:11:35 |     validation_every_n_epochs: -1\n",
            "18:11:35 |     validation_every_n_secs: -1\n",
            "18:11:35 |     validation_every_n_steps: -1\n",
            "18:11:35 |     validation_max_exs: -1\n",
            "18:11:35 |     validation_metric: accuracy\n",
            "18:11:35 |     validation_metric_mode: max\n",
            "18:11:35 |     validation_patience: 10\n",
            "18:11:35 |     validation_share_agent: False\n",
            "18:11:35 |     variant: xlm\n",
            "18:11:35 |     verbose: False\n",
            "18:11:35 |     wandb_entity: None\n",
            "18:11:35 |     wandb_log: False\n",
            "18:11:35 |     wandb_name: None\n",
            "18:11:35 |     wandb_project: None\n",
            "18:11:35 |     warmup_rate: 0.0001\n",
            "18:11:35 |     warmup_updates: 100\n",
            "18:11:35 |     weight_decay: None\n",
            "18:11:35 |     world_logs: \n",
            "18:11:35 |     wrap_memory_encoder: False\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat- - -\u001b[0;0m\n",
            "\u001b[0myour persona: i read twenty books a year.\n",
            "your persona: i am a stunt double as my second job.\n",
            "your persona: i only eat kosher.\n",
            "your persona: i was raised in a single parent household.\n",
            "hello what are doing today ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i am good , i just got off work and tired , i have two jobs .\u001b[0;0m\n",
            "\u001b[0;95m     model: i am good , i just got off work and tired , i have two jobs .\u001b[0;0m\n",
            "\u001b[0mi just got done watching a horror movie\u001b[0;0m\n",
            "\u001b[1;94m    labels: i rather read , i have read about 20 books this year .\u001b[0;0m\n",
            "\u001b[0;95m     model: i rather read , i have read about 20 books this year .\u001b[0;0m\n",
            "\u001b[0mwow ! i do love a good horror movie . loving this cooler weather\u001b[0;0m\n",
            "\u001b[1;94m    labels: but a good movie is always good .\u001b[0;0m\n",
            "\u001b[0;95m     model: but a good movie is always good .\u001b[0;0m\n",
            "\u001b[0myes ! my son is in junior high and i just started letting him watch them too\u001b[0;0m\n",
            "\u001b[1;94m    labels: i work in the movies as well .\u001b[0;0m\n",
            "\u001b[0;95m     model: i work in the movies as well .\u001b[0;0m\n",
            "\u001b[0mneat ! ! i used to work in the human services field\u001b[0;0m\n",
            "\u001b[1;94m    labels: yes it is neat , i stunt double , it is so much fun and hard work .\u001b[0;0m\n",
            "\u001b[0;95m     model: yes it is neat , i stunt double , it is so much fun and hard work .\u001b[0;0m\n",
            "\u001b[0myes i bet you can get hurt . my wife works and i stay at home\u001b[0;0m\n",
            "\u001b[1;94m    labels: nice , i only have one parent so now i help out my mom .\u001b[0;0m\n",
            "\u001b[0;95m     model: nice , i only have one parent so now i help out my mom .\u001b[0;0m\n",
            "\u001b[0mi bet she appreciates that very much .\u001b[0;0m\n",
            "\u001b[1;94m    labels: she raised me right , i am just like her .\u001b[0;0m\n",
            "\u001b[0;95m     model: she raised me right , i am just like her .\u001b[0;0m\n",
            "\u001b[0mmy dad was always busy working at home depot\u001b[0;0m\n",
            "\u001b[1;94m    labels: now that i am older home depot is my toy r us .\u001b[0;0m\n",
            "\u001b[0;95m     model: now that i am older home depot is my toy r us .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat- - -\u001b[0;0m\n",
            "\u001b[0myour persona: i have two dogs.\n",
            "your persona: i like to work on vintage cars.\n",
            "your persona: my favorite music is country.\n",
            "your persona: i own two vintage mustangs.\n",
            "hi ! how are you doing tonight ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: i am doing great . just relaxing with my two dogs .\u001b[0;0m\n",
            "\u001b[0;95m     model: i am doing great . just relaxing with my two dogs .\u001b[0;0m\n",
            "\u001b[0mgreat . in my spare time i do volunteer work .\u001b[0;0m\n",
            "\u001b[1;94m    labels: that is neat . what kind of volunteer work do you do ?\u001b[0;0m\n",
            "\u001b[0;95m     model: that is neat . what kind of volunteer work do you do ?\u001b[0;0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./image_seq2seq_personachat.zip ./from_pretrained"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aM3bT3DMnWb",
        "outputId": "9a8e1b15-05ef-4137-fe51-1329206fc78c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: from_pretrained/ (stored 0%)\n",
            "  adding: from_pretrained/model.valid (deflated 44%)\n",
            "  adding: from_pretrained/model.trainstats (deflated 81%)\n",
            "  adding: from_pretrained/model.test (deflated 45%)\n",
            "  adding: from_pretrained/model (deflated 8%)\n",
            "  adding: from_pretrained/model.dict.opt (deflated 69%)\n",
            "  adding: from_pretrained/model.dict (deflated 55%)\n",
            "  adding: from_pretrained/model.opt (deflated 66%)\n",
            "  adding: from_pretrained/model.dict.codecs (deflated 64%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model testing"
      ],
      "metadata": {
        "id": "P8QzZENM2Lix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='pretrained_models/model'\n",
        ")"
      ],
      "metadata": {
        "id": "hu1dsF6a2cqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654cd093-7fa7-4184-f342-c13adca9979c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:29:27 | \u001b[33mOverriding opt[\"model_file\"] to pretrained_models/model (previously: from_pretrained/model)\u001b[0m\n",
            "18:29:27 | Using CUDA\n",
            "18:29:27 | loading dictionary from pretrained_models/model.dict\n",
            "18:29:27 | num words = 54946\n",
            "18:29:28 | ImageSeq2seq: full interactive mode on.\n",
            "18:29:30 | Total parameters: 88,559,104 (88,559,104 trainable)\n",
            "18:29:30 | Loading existing model params from pretrained_models/model\n",
            "18:29:32 | Opt:\n",
            "18:29:32 |     activation: gelu\n",
            "18:29:32 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "18:29:32 |     adam_eps: 1e-08\n",
            "18:29:32 |     add_p1_after_newln: False\n",
            "18:29:32 |     aggregate_micro: False\n",
            "18:29:32 |     allow_missing_init_opts: False\n",
            "18:29:32 |     attention_dropout: 0.0\n",
            "18:29:32 |     batchsize: 16\n",
            "18:29:32 |     beam_block_full_context: True\n",
            "18:29:32 |     beam_block_list_filename: None\n",
            "18:29:32 |     beam_block_ngram: -1\n",
            "18:29:32 |     beam_context_block_ngram: -1\n",
            "18:29:32 |     beam_delay: 30\n",
            "18:29:32 |     beam_length_penalty: 0.65\n",
            "18:29:32 |     beam_min_length: 1\n",
            "18:29:32 |     beam_size: 1\n",
            "18:29:32 |     betas: '[0.9, 0.999]'\n",
            "18:29:32 |     bpe_add_prefix_space: None\n",
            "18:29:32 |     bpe_debug: False\n",
            "18:29:32 |     bpe_dropout: None\n",
            "18:29:32 |     bpe_merge: None\n",
            "18:29:32 |     bpe_vocab: None\n",
            "18:29:32 |     checkpoint_activations: False\n",
            "18:29:32 |     compute_tokenized_bleu: False\n",
            "18:29:32 |     datapath: ./data\n",
            "18:29:32 |     datatype: train\n",
            "18:29:32 |     delimiter: '\\n'\n",
            "18:29:32 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "18:29:32 |     dict_endtoken: __end__\n",
            "18:29:32 |     dict_file: pretrained_models/model.dict\n",
            "18:29:32 |     dict_include_test: False\n",
            "18:29:32 |     dict_include_valid: False\n",
            "18:29:32 |     dict_initpath: None\n",
            "18:29:32 |     dict_language: english\n",
            "18:29:32 |     dict_loaded: True\n",
            "18:29:32 |     dict_lower: False\n",
            "18:29:32 |     dict_max_ngram_size: -1\n",
            "18:29:32 |     dict_maxexs: -1\n",
            "18:29:32 |     dict_maxtokens: -1\n",
            "18:29:32 |     dict_minfreq: 0\n",
            "18:29:32 |     dict_nulltoken: __null__\n",
            "18:29:32 |     dict_starttoken: __start__\n",
            "18:29:32 |     dict_textfields: text,labels\n",
            "18:29:32 |     dict_tokenizer: bpe\n",
            "18:29:32 |     dict_unktoken: __unk__\n",
            "18:29:32 |     display_add_fields: \n",
            "18:29:32 |     display_examples: False\n",
            "18:29:32 |     display_prettify: False\n",
            "18:29:32 |     download_path: None\n",
            "18:29:32 |     dropout: 0.0\n",
            "18:29:32 |     dynamic_batching: None\n",
            "18:29:32 |     embedding_projection: random\n",
            "18:29:32 |     embedding_size: 512\n",
            "18:29:32 |     embedding_type: random\n",
            "18:29:32 |     embeddings_scale: True\n",
            "18:29:32 |     eval_batchsize: None\n",
            "18:29:32 |     eval_dynamic_batching: None\n",
            "18:29:32 |     evaltask: None\n",
            "18:29:32 |     ffn_size: 2048\n",
            "18:29:32 |     final_extra_opt: \n",
            "18:29:32 |     force_fp16_tokens: False\n",
            "18:29:32 |     fp16: False\n",
            "18:29:32 |     fp16_impl: safe\n",
            "18:29:32 |     gpu: -1\n",
            "18:29:32 |     gradient_clip: 0.1\n",
            "18:29:32 |     hide_labels: False\n",
            "18:29:32 |     history_add_global_end_token: None\n",
            "18:29:32 |     history_reversed: False\n",
            "18:29:32 |     history_size: -1\n",
            "18:29:32 |     image_cropsize: 224\n",
            "18:29:32 |     image_encoder_num_layers: 1\n",
            "18:29:32 |     image_features_dim: 2048\n",
            "18:29:32 |     image_fusion_type: late\n",
            "18:29:32 |     image_mode: raw\n",
            "18:29:32 |     image_size: 256\n",
            "18:29:32 |     include_image_token: True\n",
            "18:29:32 |     inference: greedy\n",
            "18:29:32 |     init_model: /content/data/models/dodecadialogue/empathetic_dialogues_ft/model\n",
            "18:29:32 |     init_opt: None\n",
            "18:29:32 |     interactive_mode: True\n",
            "18:29:32 |     interactive_task: True\n",
            "18:29:32 |     invsqrt_lr_decay_gamma: -1\n",
            "18:29:32 |     is_debug: False\n",
            "18:29:32 |     label_truncate: 128\n",
            "18:29:32 |     learn_positional_embeddings: True\n",
            "18:29:32 |     learningrate: 1\n",
            "18:29:32 |     local_human_candidates_file: None\n",
            "18:29:32 |     log_every_n_secs: -1\n",
            "18:29:32 |     log_every_n_steps: 50\n",
            "18:29:32 |     log_keep_fields: all\n",
            "18:29:32 |     loglevel: info\n",
            "18:29:32 |     lr_scheduler: reduceonplateau\n",
            "18:29:32 |     lr_scheduler_decay: 0.5\n",
            "18:29:32 |     lr_scheduler_patience: 3\n",
            "18:29:32 |     max_train_steps: -1\n",
            "18:29:32 |     max_train_time: 600.0\n",
            "18:29:32 |     metrics: default\n",
            "18:29:32 |     model: image_seq2seq\n",
            "18:29:32 |     model_file: pretrained_models/model\n",
            "18:29:32 |     model_parallel: False\n",
            "18:29:32 |     momentum: 0\n",
            "18:29:32 |     multitask_weights: [1]\n",
            "18:29:32 |     mutators: None\n",
            "18:29:32 |     n_decoder_layers: -1\n",
            "18:29:32 |     n_encoder_layers: -1\n",
            "18:29:32 |     n_heads: 16\n",
            "18:29:32 |     n_image_channels: 1\n",
            "18:29:32 |     n_image_tokens: 1\n",
            "18:29:32 |     n_layers: 8\n",
            "18:29:32 |     n_positions: 512\n",
            "18:29:32 |     n_segments: 0\n",
            "18:29:32 |     nesterov: True\n",
            "18:29:32 |     no_cuda: False\n",
            "18:29:32 |     num_epochs: -1\n",
            "18:29:32 |     num_workers: 0\n",
            "18:29:32 |     nus: [0.7]\n",
            "18:29:32 |     optimizer: sgd\n",
            "18:29:32 |     outfile: \n",
            "18:29:32 |     output_scaling: 1.0\n",
            "18:29:32 |     override: \"{'model_file': 'pretrained_models/model'}\"\n",
            "18:29:32 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "18:29:32 |     person_tokens: False\n",
            "18:29:32 |     rank_candidates: False\n",
            "18:29:32 |     relu_dropout: 0.0\n",
            "18:29:32 |     save_after_valid: False\n",
            "18:29:32 |     save_every_n_secs: -1\n",
            "18:29:32 |     save_format: conversations\n",
            "18:29:32 |     share_word_embeddings: True\n",
            "18:29:32 |     short_final_eval: False\n",
            "18:29:32 |     single_turn: False\n",
            "18:29:32 |     skip_generation: False\n",
            "18:29:32 |     special_tok_lst: None\n",
            "18:29:32 |     split_lines: False\n",
            "18:29:32 |     starttime: Jun13_02-23\n",
            "18:29:32 |     task: personachat\n",
            "18:29:32 |     temperature: 1.0\n",
            "18:29:32 |     tensorboard_log: False\n",
            "18:29:32 |     tensorboard_logdir: None\n",
            "18:29:32 |     text_truncate: 512\n",
            "18:29:32 |     topk: 10\n",
            "18:29:32 |     topp: 0.9\n",
            "18:29:32 |     truncate: -1\n",
            "18:29:32 |     update_freq: 1\n",
            "18:29:32 |     use_reply: label\n",
            "18:29:32 |     validation_cutoff: 1.0\n",
            "18:29:32 |     validation_every_n_epochs: -1\n",
            "18:29:32 |     validation_every_n_secs: -1\n",
            "18:29:32 |     validation_every_n_steps: -1\n",
            "18:29:32 |     validation_max_exs: -1\n",
            "18:29:32 |     validation_metric: accuracy\n",
            "18:29:32 |     validation_metric_mode: None\n",
            "18:29:32 |     validation_patience: 10\n",
            "18:29:32 |     validation_share_agent: False\n",
            "18:29:32 |     variant: xlm\n",
            "18:29:32 |     verbose: False\n",
            "18:29:32 |     wandb_entity: None\n",
            "18:29:32 |     wandb_log: False\n",
            "18:29:32 |     wandb_name: None\n",
            "18:29:32 |     wandb_project: None\n",
            "18:29:32 |     warmup_rate: 0.0001\n",
            "18:29:32 |     warmup_updates: -1\n",
            "18:29:32 |     weight_decay: None\n",
            "18:29:32 |     world_logs: \n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "18:29:33 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m hi, how are you?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am fine , how are you ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m i'm sad\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1moh , why is that ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I broke my nail\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1moh , that is not good .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what should i do?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi think you should go to a doctor .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m should i go now?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes , i think you should .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do i need to take some pills?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes , i think you should go .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m thanks for your help\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mno problem .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [DONE]\n",
            "CHAT DONE \n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I'm stressed out\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am sorry to hear that . what is going on ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Too much work\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am sorry . i hope you find a way to cope .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [DONE]\n",
            "CHAT DONE \n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I'm depressed\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am sorry to hear that . what is wrong ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I felt lost\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1moh , i am so sorry . i am so glad you are okay .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I want to kill myself\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am so sorry . i am so glad you are okay .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I hate myself\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am so sorry . i am so glad you are okay .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I'm mentally illed\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am so glad you are okay .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [DONE]\n",
            "CHAT DONE \n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I want to kill myself\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am sorry to hear that .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m What should I do?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi think so .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I'm overly excited today because will be flying outside the country for the first time tomorrow.\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1moh , that is exciting . i hope you have a good flight .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m When my dog died_comma_ I felt lost. I also felt like I just let him live when I should have put him down due to his health.\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am so sorry . i am sure he was well .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I felt a bit terrified when i was hit by a drunk driver last year but i am very grateful to be alive to today\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am so glad you are okay .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I locked my keys in my car about a week ago. It was 95 degrees outside and I was at the store getting groceries.\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1moh , my dog is so sick . he was in a car accident last week .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I was very happy about a time when i saw an elderly lady being helped by a younger male _comma_ its nice to see people still helping others now days. \n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi agree . i think we have a lot of good people in the world .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m can i change my feeling of being worthless to everyone\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1msure . i think that is a good thing .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m i ' ve always wanted to fix my issues , but i never get around to it\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi am sure you will find a way .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='from_pretrained/model'\n",
        ")"
      ],
      "metadata": {
        "id": "fI5FT2rVlTvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LyiSwdq8cloq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}